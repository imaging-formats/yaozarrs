{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Get Started","text":"<p>yaozarrs!!</p>"},{"location":"#get-started-with-yaozarrs","title":"Get Started with <code>yaozarrs</code>","text":"<p>Yaozarrs is a bottom-up library for working with OME-Zarr metadata and stores in Python. It is lightweight, with only a single required dependency (on Pydantic), but feature-rich, with structural validation and writing functions added via optional extras.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> See installation guide for instructions on how to install   <code>yaozarrs</code>.</li> <li> For a quick overview of the API, see the API Quick Reference   below, or the full API Reference.</li> <li> If you're new to OME-Zarr or don't know how to express your data in OME-Zarr   format, see the yaozarrs guide to OME-Zarr.</li> <li> If you learn best with examples, check out the interactive   OME-Zarr explorer app.</li> <li> To understand why yaozarrs exists, see the   Principles section below.</li> </ul>"},{"location":"#api-quick-reference","title":"API Quick Reference","text":""},{"location":"#metadata-creation","title":"Metadata Creation","text":"<p>You can create OME-Zarr metadata objects using the pydantic models in <code>yaozarrs.v04</code> and <code>yaozarrs.v05</code> modules.  Pick a top-level object (e.g. <code>Image</code>, <code>Plate</code>, etc..) and create it using standard pydantic model syntax:</p> From <code>yaozarrs</code> modelsFrom dictionaries<code>DimSpec</code> Convenience <p>For full IDE autocompletion and type checking, you can create OME-Zarr metadata using the yaozarrs models:</p> <pre><code>from yaozarrs import v04, v05  # import from appropriate version module\n\nimage = v05.Image(\n    multiscales=[\n        v05.Multiscale(\n            name=None,\n            axes=[\n                v05.TimeAxis(name='t', unit='second'),\n                v05.ChannelAxis(name='c'),\n                v05.SpaceAxis(name='z', unit='micrometer'),\n                v05.SpaceAxis(name='y', unit='micrometer'),\n                v05.SpaceAxis(name='x', unit='micrometer')\n            ],\n            datasets=[\n                v05.Dataset(\n                    path='0',\n                    coordinateTransformations=[\n                        v05.ScaleTransformation(\n                            scale=[1.0, 1.0, 0.3, 0.1, 0.1]\n                        )\n                    ]\n                )\n            ],\n        )\n    ],\n)\n\n# Export\nimage.model_dump_json(exclude_unset=True, indent=2)  # (1)!\n</code></pre> <ol> <li><code>model_dump_json</code> is part of the standard pydantic API for exporting models to JSON.  Just an example of exporting metadata back to JSON format.</li> </ol> <p>If you prefer avoiding explicit model classes, you can create OME-Zarr metadata using standard python dictionaries (standard pydantic model parsing):</p> <pre><code>import yaozarrs\nfrom yaozarrs import v05\n\nimage = v05.Image.model_validate(  # (1)!\n    {\n        'multiscales': [\n            {\n                'axes': [\n                    {'name': 't', 'type': 'time', 'unit': 'second'},\n                    {'name': 'c', 'type': 'channel'},\n                    {'name': 'z', 'type': 'space', 'unit': 'micrometer'},\n                    {'name': 'y', 'type': 'space', 'unit': 'micrometer'},\n                    {'name': 'x', 'type': 'space', 'unit': 'micrometer'}\n                ],\n                'datasets': [\n                    {\n                        'path': '0',\n                        'coordinateTransformations': [\n                            {'type': 'scale', 'scale': [1.0, 1.0, 0.3, 0.1, 0.1]}\n                        ]\n                    }\n                ]\n            }\n        ]\n    }\n)\n\n# Export\nimage.model_dump_json(exclude_unset=True, indent=2) # (2)!\n</code></pre> <ol> <li><code>model_validate</code> is part of the    standard pydantic API for creating models from any object, like dictionaries.</li> <li><code>model_dump_json</code> is part of the standard pydantic API for exporting models to JSON.  Just an example of exporting metadata back to JSON format.</li> </ol> <p>For the common case of creating multiscale images, you can use the <code>yaozarrs.DimSpec</code> convenience class to simplify axis and transformation creation:</p> <pre><code>import yaozarrs\nfrom yaozarrs import v04, v05, DimSpec\n\nimage = v05.Image(\n    multiscales=[\n        v05.Multiscale.from_dims(\n            dims=[\n                DimSpec(name=\"t\", unit=\"second\"),  # (1)!\n                DimSpec(name=\"c\"),\n                DimSpec(name=\"z\", scale=0.3, unit=\"micrometer\"),\n                DimSpec(name=\"y\", scale=0.1, unit=\"micrometer\"),\n                DimSpec(name=\"x\", scale=0.1, unit=\"micrometer\"),\n            ]\n        )\n    ]\n)\n\n# Export\nimage.model_dump_json(exclude_unset=True, indent=2)  # (2)!\n</code></pre> <ol> <li> <code>yaozarrs.DimSpec</code> is a convenience class for use with     <code>Multiscale.from_dims</code>.  It's     not part of the OME-Zarr spec.</li> <li><code>model_dump_json</code> is part of the standard pydantic API for exporting models to JSON.  Just an example of exporting metadata back to JSON format.</li> </ol>"},{"location":"#validation-of-existing-objects","title":"Validation of existing objects","text":"<p>If you have an existing JSON file, string, or python object, you can validate it and cast it to the appropriate typed <code>yaozarrs</code> model:</p> <pre><code>import yaozarrs\n\n# validate a JSON string/bytes literal\nyaozarrs.validate_ome_json(json_str)  # (1)!\n\n# validate any python object (e.g. dict)\nyaozarrs.validate_ome_object(dict_obj) # (2)!\n\n# validate entire Zarr hierarchy (both metadata and structure) at any URI\nyaozarrs.validate_zarr_store(uri) # (3)!\n</code></pre> <ol> <li><code>yaozarrs.validate_ome_json</code></li> <li><code>yaozarrs.validate_ome_object</code></li> <li><code>yaozarrs.validate_zarr_store</code>. Requires the <code>yaozarrs[io]</code>    extra to support remote URIs.</li> </ol> Storage Validation Errors <p>Validation errors that relate to the structure of the OME-Zarr itself (as opposed to metadata) are collected and presented similarly to pydantic validation errors for the metadata:</p> <pre><code>location\ndescription [context]\n</code></pre> <p>An example validation error (for a file that has many problems):</p> <pre><code>uvx \"yaozarrs[io]\" validate https://raw.githubusercontent.com/tlambert03/yaozarrs/refs/heads/main/tests/data/broken/broken_v05.ome.zarr/\n</code></pre> <pre><code>yaozarrs._storage.StorageValidationError: 14 validation error(s) for StorageValidationError\nome.plate.wells.0.well.images.0.multiscales.0.datasets.0.path\nDataset path '0' not found in zarr group [type=dataset_path_not_found, fs_path='broken_v05.ome.zarr/A/1/0/0', expected='zarr array']\n\nome.plate.wells.0.well.images.0.labels.labels.0\nLabel path 'annotations' not found in labels group [type=label_path_not_found, fs_path='broken_v05.ome.zarr/A/1/0/labels/annotations', expected='zarr group']\n\nome.plate.wells.0.well.images.1.labels.labels.0\nLabel path 'annotations' is not a zarr group [type=label_path_not_group, fs_path='broken_v05.ome.zarr/A/1/1/labels/annotations', expected='group', found='array']\n\nome.plate.wells.1.path\nWell path 'A/2' is not a zarr group [type=well_path_not_group, fs_path='broken_v05.ome.zarr/A/2', expected='group', found='array']\n\nome.plate.wells.2.well.images.0.labels.labels.0\nLabel path 'annotations' does not contain valid Image ('multiscales') metadata [type=label_image_invalid, path='annotations']\n1 validation error for tagged-union[LabelImage,Image,Plate,Bf2Raw,Well,LabelsGroup,Series]\n    Unable to extract tag using discriminator _discriminate_ome_v05_metadata() [type=union_tag_not_found, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/union_tag_not_found\n\nome.plate.wells.3.well.images.0.multiscales.0.datasets.0.path\nDataset '0' has 5 dimensions but axes specify 3 [type=dataset_dimension_mismatch, fs_path='broken_v05.ome.zarr/B/1/0/0', actual_ndim=5, expected_ndim=3, axes=['c', 'y', 'x']]\n\nome.plate.wells.3.well.images.0.labels.labels.0.multiscales.0.datasets.0.path\nLabel array '0' has non-integer dtype 'float32'. Labels must use integer types. [type=label_non_integer_dtype, path='0', dtype='float32']\n\nome.plate.wells.4.well.images.0.multiscales.0.datasets.0.path\nDataset path '0' exists but is not a zarr array [type=dataset_not_array, fs_path='broken_v05.ome.zarr/B/2/0/0', expected='array', found='group']\n\nome.plate.wells.4.well.images.1.multiscales.0.datasets.0.path.dimension_names\nArray dimension_names ['wrong', 'names', 'here'] don't match axes names ['c', 'y', 'x'] [type=dimension_names_mismatch, expected=['c', 'y', 'x'], actual=['wrong', 'names', 'here']]\n\nome.plate.wells.5.well.images.0.labels\nFound 'labels' path but it is a &lt;class 'yaozarrs._zarr.ZarrArray'&gt;, not a zarr group [type=labels_not_group, expected='group', found='ZarrArray']\n\nome.plate.wells.5.well.images.1.path\nField path '1' is not a zarr group [type=field_path_not_group, fs_path='broken_v05.ome.zarr/B/3/1', expected='group', found='array']\n\nome.plate.wells.6.well.images.1.path\nField path '1' not found in well group [type=field_path_not_found, fs_path='broken_v05.ome.zarr/C/1/1', expected='zarr group']\n\nome.plate.wells.7.well.images.0\nField path '0' does not contain valid Image metadata [type=field_image_invalid, fs_path='broken_v05.ome.zarr/C/2/0']\n1 validation error for tagged-union[LabelImage,Image,Plate,Bf2Raw,Well,LabelsGroup,Series]\nimage.multiscales\n    Value should have at least 1 item after validation, not 0 [type=too_short, input_value=[], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.12/v/too_short\n\nome.plate.wells.8\nWell path 'C/3' does not contain valid Well metadata [type=well_invalid, path='C/3']\n1 validation error for tagged-union[LabelImage,Image,Plate,Bf2Raw,Well,LabelsGroup,Series]\n    Unable to extract tag using discriminator _discriminate_ome_v05_metadata() [type=union_tag_not_found, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/union_tag_not_found\n</code></pre>"},{"location":"#writing-ome-zarr-stores","title":"Writing OME-Zarr Stores","text":"<p>See <code>yaozarrs.write.v05</code> for convenience functions to write OME-Zarr v0.5 stores using your metadata objects, with either <code>zarr-python</code>, <code>tensorstore</code>, or custom backends.</p> <pre><code>import numpy as np\n\nfrom yaozarrs import write\n\n# write a 5D image with single pyramid level\ndata = np.zeros((10, 3, 9, 64, 64), dtype=np.uint16)\nroot_path = write.v05.write_image(\"example.ome.zarr\", image, data)\n\n# other high level write functions\nwrite.v05.write_plate(...)\nwrite.v05.write_bioformats2raw(...)\n\n# low-level prepare/builder functions\nwrite.v05.prepare_image(...)\nwrite.v05.LabelsBuilder(...)\nwrite.v05.PlateBuilder(...)\nwrite.v05.Bf2RawBuilder(...)\n</code></pre>"},{"location":"#cli-validation","title":"CLI validation","text":"<p>The CLI command provides a quick way to validate any zarr store as an OME-Zarr store.  Here, \"store\" here refers to any URI (local path, http(s) url, or s3 url.</p> <p>Important</p> <p>Requires <code>fsspec</code>. install with <code>pip install yaozarrs[io]</code></p> with uvxfrom installed package <pre><code>uvx \"yaozarrs[io]\" validate https://raw.githubusercontent.com/tlambert03/yaozarrs/refs/heads/main/tests/data/broken/broken_v05.ome.zarr/\n</code></pre> <pre><code>yaozarrs validate https://raw.githubusercontent.com/tlambert03/yaozarrs/refs/heads/main/tests/data/broken/broken_v05.ome.zarr/\n</code></pre> <pre><code>\u2713 Valid OME-Zarr store\n  Version: 0.5\n  Type: Image\n</code></pre>"},{"location":"#loading-ome-zarr-stores","title":"Loading OME-Zarr Stores","text":"<p><code>yaozarrs.open_group</code> teturns a small wrapper around a zarr group with minimal functionality: <code>yaozarrs.ZarrGroup</code>.  Requires the <code>yaozarrs[io]</code> extra to support remote URIs.  This class is used behind the scenes for structural validation, but can also be used directly.</p> <pre><code>import yaozarrs\n\n# Open a Zarr group at any URI\nyaozarrs.open_group(uri) # (1)!\n</code></pre>"},{"location":"#principles","title":"Principles","text":"<p>The core philosophy is that NGFF metadata and Zarr array I/O are separate concerns.</p> <p>Yaozarrs focuses on OME-Zarr metadata creation, manipulation, and validation, and all other functionality (writing and structural validation) is optional, with flexible backend.</p> <p>Zarr itself is a specification with multiple implementations:  There are many ways to read and write Zarr stores (e.g. <code>zarr-python</code>, <code>tensorstore</code>, <code>acquire-zarr</code>, <code>zarrs</code>, etc..) and yaozarrs makes no assumptions about which implementation you may want to use.  Similarly, OME NGFF is a metadata sepcification, defining what JSON documents and hierarchy structure must look like.</p> <ol> <li> <p>At its core, yaozarrs provides pydantic models for OME-Zarr metadata   specifications. You should be able to create/manipulate/validate OME-Zarr   metadata without any specific zarr array library, or anything beyond   <code>yaozarrs</code>, <code>pydantic</code>, and the standard library.</p> Why pydantic? <p>It's true that one can define dataclasses that mirror the OME-Zarr schema; but reinventing validation and ser/deserialization is beyond the scope of this project, and pydantic is a battle-tested library for exactly these tasks. It's lightweight in terms of transitive dependencies, ~7MB in size, and is broadly compatible. We test against a broad range of pydantic versions (v2+) on a broad range of python versions and OS, to ensure that yaozarrs is an easy/robust dependency to add.</p> </li> <li> <p>Because reading/writing zarr groups is far simpler than arrays, you   shouldn't need to depend on a specific complete zarr library just to validate   that a given hierarchy is structurally correct. For example: a library implementing a new low-level zarr array backend   should be able to use yaozarrs to validate that its group structure and   metadata are correct, without needing to depend on zarr-python or   tensorstore.</p> <code>pip install 'yaozarrs[io]'</code> <p>If you want to perform structural validation of possibly remote zarr stores, then you will need to install the <code>io</code> extra, which adds dependencies on <code>fsspec</code>.</p> </li> <li> <p>Even in the case of writing complete OME-Zarr stores, the \"array\" part is    relatively stereotyped, and the metadata is the more user-customized part.    With yaozarrs, you can create the metadata using the pydantic models, and    then use convenience functions to write the zarr stores using any zarr    array creation method you want, with built-in (optional) implementations for    <code>zarr-python</code> and <code>tensorstore</code>.</p> <code>pip install 'yaozarrs[write-zarr]'</code> or <code>[write-tensorstore]</code> <p>The builtin backends in the <code>yaozarrs.write</code> module require an array-writing backend, currently either <code>zarr</code> (zarr-python) or <code>tensorstore</code>.  Install the appropriate extra to enable these features.</p> </li> </ol>"},{"location":"#see-also","title":"See Also","text":"<p>ome-zarr-models-py is another set of Pydantic models for OME-Zarr. It has garnered broad community support, and aligns well with many use cases.  It should also be considered for OME-Zarr metadata validation and manipulation in Python!</p> <p>The primary difference is that it depends on <code>zarr-python</code>, and is more directly tied to the zarr-python implementation.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installing-yaozarrs","title":"Installing <code>yaozarrs</code>","text":"<p>The basic package (with no extras) supports metadata creation &amp; validation, but lacks structural validation and writing capabilities.</p> from PyPI, with pipfrom PyPI, with uvfrom githubfrom conda <pre><code>pip install yaozarrs\n</code></pre> <pre><code>uv add yaozarrs\n</code></pre> <p>To install the bleeding-edge development version from GitHub, (shown here using the <code>io</code> extra as an example):</p> <pre><code>pip install \"yaozarrs[io] @ git+https://github.com/tlambert03/yaozarrs.git\"\n</code></pre> <p>Conda install is not yet supported. Please open an issue if you want this package on conda.</p>"},{"location":"installation/#structural-validation","title":"Structural validation","text":"<p>To enable validation of Zarr hierarchies, include the <code>io</code> extra when installing. This brings in <code>fsspec</code> (but not zarr-python):</p> with pipwith uv <pre><code>pip install \"yaozarrs[io]\"\n</code></pre> <pre><code>uv add \"yaozarrs[io]\"\n</code></pre>"},{"location":"installation/#writing-support","title":"Writing support","text":"<p>If you want to use the convenience functions in <code>yaozarrs.write</code>, to create complete OME-Zarr stores with array data, you will need to pick a zarr-array library:</p>"},{"location":"installation/#zarr-python","title":"<code>zarr-python</code>","text":"<p><code>zarr-python</code> is the reference implementation of the Zarr specification for Python.</p> with pipwith uv <pre><code>pip install \"yaozarrs[write-zarr]\"\n</code></pre> <pre><code>uv add \"yaozarrs[write-zarr]\"\n</code></pre> <p>Then use <code>writer=\"zarr\"</code> in the <code>yaozarrs.write</code> functions.</p>"},{"location":"installation/#tensorstore","title":"<code>tensorstore</code>","text":"<p>Tensorstore is an alternative zarr-array library developed by Google, which can offer better I/O performance in most cases.</p> with pipwith uv <pre><code>pip install \"yaozarrs[write-tensorstore]\"\n</code></pre> <pre><code>uv add \"yaozarrs[write-tensorstore]\"\n</code></pre> <p>Then use <code>writer=\"tensorstore\"</code> in the <code>yaozarrs.write</code> functions.</p>"},{"location":"installation/#custom-backend","title":"Custom backend","text":"<p>If you don't want to use either of the provided backends, you can implement your own array-writing functionality</p>"},{"location":"ome_zarr_explorer/","title":"OME-Zarr Explorer","text":"What is this? <p>This educational app demonstrates how various OME-NGFF zarr hierarchies are structured, along with associated metadata.</p> <ul> <li>Define your image dimensions and view the generated hierarchy and metadata in real-time.</li> <li>The file tree on the left demonstrates what the OME-Zarr hierarchy would look like when saved to disk</li> <li>The <code>Spec JSON</code> tab shows the metadata associated with each group or array</li> <li>The <code>Python</code> tab shows how you would create the metadata programmatically using the <code>yaozarrs</code> library.</li> </ul> <p>This is meant for educational purposes only and is not intended for production use.</p> <p></p>"},{"location":"ome_zarr_guide/","title":"Yaozzars Guide to OME-Zarr","text":"<p>What you'll learn</p> <p>This guide attempts to demystify the OME-Zarr (OME-Zarr) specification and shows you how to work with it using yaozarrs.  It is designed to answer common questions and confusions encountered in the community.</p>"},{"location":"ome_zarr_guide/#quicklinks","title":"Quicklinks","text":"<ul> <li> <p> I have images</p> <p>Any data with 5 or less dimensions, typically <code>[T][C][Z]YX</code>.</p> <p> Go to Images</p> </li> <li> <p> I have plate data</p> <p>Multi-well plates and high-content screening (HCS) experiments</p> <p> Go to Plates</p> </li> <li> <p> I have image annotations</p> <p>Segmentation masks, annotation labels, and regions of interest (ROIs)</p> <p> Go to Labels</p> </li> <li> <p> I have multiple images</p> <p>Collections of related images (multi-FOV, stage positions, split files)</p> <p> Go to Collections</p> </li> </ul>"},{"location":"ome_zarr_guide/#what-is-ome-zarr","title":"What is OME-Zarr?","text":"<p>The official OME-Zarr specification can be found at https://ngff.openmicroscopy.org/.  In case of any discrepancies between this guide and the official spec, the official spec takes precedence!</p> <p>OME-Zarr is a file format specification used by the bioimaging community for storing multi-dimensional data. It is a \"meta-specication\", based on the pre-existing Zarr format, which is designed for the storage of chunked, compressed, N-dimensional arrays. OME-Zarr extends Zarr by adding metadata conventions specific to bioimaging, making it easier to store and share complex imaging datasets.</p> <p>But what is it?</p> <p>To resolve a somewhat common confusion...</p> <p>OME-Zarr is \"just\" Zarr (A file format used in many domains). The \"OME\" part is a specification on top of the zarr format that additionally defines:</p> <ol> <li> <p>How domain specific metadata should be stored.    The details are version-specific, but this generally defines the exact   form of the data inside of the <code>.zattrs</code> or <code>zarr.json</code> files that   accompany the zarr groups.</p> </li> <li> <p>How datasets are organized.   Beyond metadata, the OME-Zarr specification also defines how datasets   should be organized. For example: it defines how the images collected   across a multi-well plate experiment should be organized in a single   Zarr directory, or how the different resolutions of a multi-scale   (pyramidal) image should be stored.</p> </li> </ol>"},{"location":"ome_zarr_guide/#working-with-images","title":"Working with Images","text":"<p>An Image is the fundamental building block of OME-Zarr.</p> <p>As of v0.5, a single image may have no less than 2 and no more than 5 dimensions, and may store multiple resolution levels.</p> <ul> <li>Spatial dimensions: X, Y, optionally Z</li> <li>Time: T (temporal axis)</li> <li>Channels: C (fluorescence channels, RGB, etc.)</li> </ul> What if I have more than 5 dimensions? <p>While it is common to have datasets with more than 5 dimensions (e.g., different stage positions in a shared coordinate space, angles in light sheet microscopy, etc.), there is currently no formal specification for more than 5 dimensions in OME-Zarr.  You may use the transitional <code>bioformats2raw.layout</code> to store multiple images in a single zarr group. See Working with Collections</p> <p>See also: an RFC (\"request for comments\") proposing a relaxation of this restriction: RFC-3</p> What if I have both RGB and optical channels? <p>As of v0.5, there is no formal specification for mixing the concepts of RGB image components and conventional \"channels\" (like optical configurations).  You will need to either create a custom group layout or flatten them all into a single channel dimension.</p>"},{"location":"ome_zarr_guide/#directory-structure","title":"Directory Structure","text":"OME-Zarr v0.5 (Zarr v3)OME-Zarr v0.4 (Zarr v2) <pre><code>image.zarr/\n\u251c\u2500\u2500 zarr.json            # {\"zarr_format\": 3} group, with attributes.ome.multiscales\n\u251c\u2500\u2500 0/                   # Full resolution array  \n\u2502   \u251c\u2500\u2500 zarr.json        # Array metadata (standard zarr schema)\n\u2502   \u2514\u2500\u2500 c/0/1/2/3        # Chunk files\n\u251c\u2500\u2500 1/                   # downsampled level 1\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 2/                   # downsampled level 2 \n    \u2514\u2500\u2500 ...\n</code></pre> <pre><code>image.zarr/\n\u251c\u2500\u2500 .zgroup              # {\"zarr_format\": 2} group\n\u251c\u2500\u2500 .zattrs              # Contains \"multiscales\"\n\u251c\u2500\u2500 0/                   # Full resolution array\n\u2502   \u251c\u2500\u2500 .zarray          # Array metadata (standard zarr schema)\n\u2502   \u2514\u2500\u2500 t/c/z/y/x        # Chunk files with \"/\" separator\n\u251c\u2500\u2500 1/                   # downsampled level 1\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 2/                   # downsampled level 2 \n    \u2514\u2500\u2500 ...\n</code></pre> <p>Key difference</p> <p>Most of the structural changes between v0.4 and v0.5 relate to the transition from Zarr v2 to Zarr v3.</p> <ul> <li>&lt;=v0.4: \"multiscales\" metadata directly in root of <code>.zattrs</code> files</li> <li>&gt;=v0.5: \"multiscales\" metadata in <code>zarr.json</code> under <code>attributes.ome</code> namespace</li> </ul>"},{"location":"ome_zarr_guide/#axes","title":"Axes","text":"<p>Axes define the dimensions of your image data. As of v0.4, axes are objects with <code>name</code>, and optional <code>type</code> and/or <code>unit</code>:</p> <p>Axis Constraints</p> <p>Constraints for image axes in OME-Zarr are the same in v0.4 and v0.5:</p> <ul> <li>MUST have 2-5 dimensions total</li> <li>MUST have 2-3 spatial axes</li> <li>MAY have 0-1 time axis</li> <li>MAY have 0-1 channel axis</li> <li>Ordering enforced: time \u2192 channel/custom \u2192 space</li> </ul> <p>In practice, this limits valid axis combinations to: <code>[T][C][Z] Y X</code> (though no explicit restriction is placed on naming conventions)</p> v0.4v0.5 <p>Spec JSON:</p> <pre><code>{\n  // found in a \"multiscales\" object\n  \"axes\": [\n    {\"name\": \"c\", \"type\": \"channel\"},\n    {\"name\": \"z\", \"type\": \"space\", \"unit\": \"micrometer\"},\n    {\"name\": \"y\", \"type\": \"space\", \"unit\": \"micrometer\"},\n    {\"name\": \"x\", \"type\": \"space\", \"unit\": \"micrometer\"}\n  ]\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v04\n\naxes = [\n    v04.ChannelAxis(name=\"c\"),\n    v04.SpaceAxis(name=\"z\", unit=\"micrometer\"),\n    v04.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    v04.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n]\n</code></pre> <p>Breaking change from v0.3</p> <p>In v0.3, axes were simple strings: <code>[\"c\", \"z\", \"y\", \"x\"]</code>. In v0.4+, they must be objects with explicit types.</p> <p>Spec JSON:</p> <pre><code>{\n  // found in a \"multiscales\" object\n  \"axes\": [\n    {\"name\": \"c\", \"type\": \"channel\"},\n    {\"name\": \"z\", \"type\": \"space\", \"unit\": \"micrometer\"},\n    {\"name\": \"y\", \"type\": \"space\", \"unit\": \"micrometer\"},\n    {\"name\": \"x\", \"type\": \"space\", \"unit\": \"micrometer\"}\n  ]\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v05\n\naxes = [\n    v05.ChannelAxis(name=\"c\"),\n    v05.SpaceAxis(name=\"z\", unit=\"micrometer\"),\n    v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n]\n</code></pre>"},{"location":"ome_zarr_guide/#coordinate-transformations","title":"Coordinate Transformations","text":"<p>Starting in v0.4, every dataset MUST include coordinate transformations that map data coordinates to physical coordinates.  Coordinate transforms are where you would specify physical units (micrometers, seconds), multi-resolution scales, as well as stage positions and spatial offsets for registration.</p> v0.4v0.5 <p>Scale Transformation (REQUIRED):</p> <p>Maps array indices to physical coordinates. Scale values represent the physical size per pixel for each dimension.</p> <p>Spec JSON:</p> <pre><code>{\n  \"datasets\": [{\n    \"path\": \"0\",\n    \"coordinateTransformations\": [\n      {\"type\": \"scale\", \"scale\": [1.0, 0.5, 0.1, 0.1]}\n    ]\n  }]\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v04\n\ndataset = v04.Dataset(\n    path=\"0\",\n    coordinateTransformations=[\n        v04.ScaleTransformation(scale=[1.0, 0.5, 0.1, 0.1])\n    ]\n)\n</code></pre> <p>Translation Transformation (OPTIONAL):</p> <p>Adds a spatial offset. Must come after scale.</p> <p>Spec JSON:</p> <pre><code>{\n  \"coordinateTransformations\": [\n    {\"type\": \"scale\", \"scale\": [1.0, 0.5, 0.1, 0.1]},\n    {\"type\": \"translation\", \"translation\": [0.0, 0.0, 100.0, 200.0]}\n  ]\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>dataset = v04.Dataset(\n    path=\"0\",\n    coordinateTransformations=[\n        v04.ScaleTransformation(scale=[1.0, 0.5, 0.1, 0.1]),\n        v04.TranslationTransformation(translation=[0.0, 0.0, 100.0, 200.0])\n    ]\n)\n</code></pre> <p>Transformation Rules</p> <ul> <li>MUST have exactly one scale transformation per dataset</li> <li>MAY have at most one translation transformation</li> <li>If translation exists, it MUST come after scale</li> <li>Transformation length MUST match number of axes</li> </ul> <p>Identical to v0.4, just stored under <code>attributes.ome</code> namespace.</p> <p>yaozarrs Code (same as v0.4):</p> <pre><code>from yaozarrs import v05\n\ndataset = v05.Dataset(\n    path=\"0\",\n    coordinateTransformations=[\n        v05.ScaleTransformation(scale=[1.0, 0.5, 0.1, 0.1]),\n        v05.TranslationTransformation(translation=[0.0, 0.0, 100.0, 200.0])\n    ]\n)\n</code></pre> <p>v0.5 Additional Requirement</p> <p>In v0.5, each array's <code>zarr.json</code> MUST include <code>dimension_names</code> matching the axes:</p> <pre><code>{\n  \"dimension_names\": [\"c\", \"z\", \"y\", \"x\"]\n}\n</code></pre>"},{"location":"ome_zarr_guide/#interactive-example","title":"Interactive Example","text":"<p>Modify the parameters below to see how different image configurations are represented in OME-Zarr:</p> <p></p>"},{"location":"ome_zarr_guide/#labels-segmentation-masks","title":"Labels (Segmentation Masks)","text":"<p>Labels are specialized images with integer dtype representing segmentation masks (nuclei, cells, regions of interest, etc.).</p> Label Structure and Code <p>Directory Structure: <pre><code>image.zarr/\n\u251c\u2500\u2500 0/, 1/, 2/           # Image pyramid\n\u2514\u2500\u2500 labels/\n    \u251c\u2500\u2500 nuclei/          # Label image (integer dtype)\n    \u2502   \u251c\u2500\u2500 .zattrs      # Label metadata\n    \u2502   \u251c\u2500\u2500 0/           # Full resolution labels\n    \u2502   \u2514\u2500\u2500 1/           # Downsampled labels\n    \u2514\u2500\u2500 cells/\n        \u2514\u2500\u2500 ...\n</code></pre></p> <p>Labels Group Metadata: <pre><code>{\n  \"labels\": [\"nuclei\", \"cells\"]\n}\n</code></pre></p> <p>Label Image Metadata (<code>.zattrs</code> in labels/nuclei/): <pre><code>{\n  \"multiscales\": [...],\n  \"image-label\": {\n    \"version\": \"0.4\",\n    \"colors\": [\n      {\"label-value\": 1, \"rgba\": [255, 0, 0, 255]},\n      {\"label-value\": 2, \"rgba\": [0, 255, 0, 255]}\n    ],\n    \"source\": {\n      \"image\": \"../../\"\n    }\n  }\n}\n</code></pre></p> <p>yaozarrs Code: <pre><code>from yaozarrs import v04\n\n# Label metadata stored at labels/nuclei/.zattrs\nlabel_image = v04.LabelImage(\n    multiscales=[...],  # Same structure as regular image\n    image_label=v04.ImageLabel(\n        colors=[\n            v04.LabelColor(label_value=1, rgba=[255, 0, 0, 255]),\n            v04.LabelColor(label_value=2, rgba=[0, 255, 0, 255])\n        ],\n        source=v04.LabelSource(image=\"../../\")\n    )\n)\n</code></pre></p> <p>Labels must use integer dtype</p> <p>Validation will fail if label arrays use float dtypes. Use <code>uint8</code>, <code>uint16</code>, <code>uint32</code>, or <code>int32</code>.</p>"},{"location":"ome_zarr_guide/#working-with-plates","title":"Working with Plates","text":"<p>A Plate represents multi-well plate data from high-content screening (HCS) experiments. The hierarchy is:</p> <p>Plate \u2192 Rows/Columns \u2192 Wells \u2192 Fields of View (Images)</p> <p>Each well can contain multiple fields of view (FOVs) across multiple acquisitions (timepoints).</p>"},{"location":"ome_zarr_guide/#directory-structure_1","title":"Directory Structure","text":"<pre><code>plate.zarr/\n\u251c\u2500\u2500 .zattrs              # Plate metadata\n\u251c\u2500\u2500 A/                   # Row A\n\u2502   \u251c\u2500\u2500 1/               # Well A1\n\u2502   \u2502   \u251c\u2500\u2500 .zattrs      # Well metadata\n\u2502   \u2502   \u251c\u2500\u2500 0/           # Field 0 (Image with multiscales)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 .zattrs  # Image metadata\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 0/       # Full resolution\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 1/       # Downsampled\n\u2502   \u2502   \u251c\u2500\u2500 1/           # Field 1\n\u2502   \u2502   \u2514\u2500\u2500 labels/      # Optional segmentation\n\u2502   \u2514\u2500\u2500 2/               # Well A2\n\u2514\u2500\u2500 B/                   # Row B\n    \u2514\u2500\u2500 1/\n</code></pre> <p>Three-level hierarchy</p> <p>Three groups MUST exist above images: plate \u2192 row \u2192 well</p>"},{"location":"ome_zarr_guide/#plate-metadata","title":"Plate Metadata","text":"v0.4v0.5 <p>Spec JSON (<code>.zattrs</code> at plate root):</p> <pre><code>{\n  \"plate\": {\n    \"version\": \"0.4\",\n    \"name\": \"HCS Experiment\",\n    \"columns\": [\n      {\"name\": \"1\"},\n      {\"name\": \"2\"},\n      {\"name\": \"3\"}\n    ],\n    \"rows\": [\n      {\"name\": \"A\"},\n      {\"name\": \"B\"}\n    ],\n    \"wells\": [\n      {\"path\": \"A/1\", \"rowIndex\": 0, \"columnIndex\": 0},\n      {\"path\": \"A/2\", \"rowIndex\": 0, \"columnIndex\": 1},\n      {\"path\": \"B/1\", \"rowIndex\": 1, \"columnIndex\": 0}\n    ],\n    \"acquisitions\": [\n      {\"id\": 0, \"name\": \"Initial\", \"maximumfieldcount\": 4},\n      {\"id\": 1, \"name\": \"24h\", \"maximumfieldcount\": 4}\n    ],\n  }\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v04\n\nplate_def = v04.PlateDef(\n    name=\"HCS Experiment\",\n    columns=[\n        v04.Column(name=\"1\"),\n        v04.Column(name=\"2\"),\n        v04.Column(name=\"3\")\n    ],\n    rows=[\n        v04.Row(name=\"A\"),\n        v04.Row(name=\"B\")\n    ],\n    wells=[\n        v04.PlateWell(path=\"A/1\", rowIndex=0, columnIndex=0),\n        v04.PlateWell(path=\"A/2\", rowIndex=0, columnIndex=1),\n        v04.PlateWell(path=\"B/1\", rowIndex=1, columnIndex=0),\n    ],\n    acquisitions=[\n        v04.Acquisition(id=0, name=\"Initial\", maximumfieldcount=4),\n        v04.Acquisition(id=1, name=\"24h\", maximumfieldcount=4),\n    ]\n)\n\nplate = v04.Plate(plate=plate_def)\n</code></pre> <p>Breaking change from v0.3</p> <p>In v0.4, <code>rowIndex</code> and <code>columnIndex</code> became required for all wells. This enables efficient sparse plate handling without path parsing.</p> <p>Same structure as v0.4, stored under <code>attributes.ome</code> in <code>zarr.json</code>:</p> <p>Spec JSON (<code>zarr.json</code> at plate root):</p> <p><pre><code>{\n  \"attributes\": {\n    \"ome\": {\n      \"plate\": {\n        \"columns\": [\n          { \"name\": \"1\" },\n          { \"name\": \"2\" },\n          { \"name\": \"3\" }\n        ],\n        \"rows\": [\n          { \"name\": \"A\" },\n          { \"name\": \"B\" }\n        ],\n        \"wells\": [\n          { \"path\": \"A/1\", \"rowIndex\": 0, \"columnIndex\": 0 },\n          { \"path\": \"A/2\", \"rowIndex\": 0, \"columnIndex\": 1 },\n          { \"path\": \"B/1\", \"rowIndex\": 1, \"columnIndex\": 0 }\n        ],\n        \"acquisitions\": [\n          { \"id\": 0, \"maximumfieldcount\": 4, \"name\": \"Initial\" },\n          { \"id\": 1, \"maximumfieldcount\": 4, \"name\": \"24h\" }\n        ],\n        \"field_count\": 4,\n        \"name\": \"HCS Experiment\"\n      }\n    }\n  }\n}\n</code></pre> yaozarrs Code:</p> <pre><code>from yaozarrs import v05\n\nplate_def = v05.PlateDef(\n    name=\"HCS Experiment\",\n    columns=[  # must have at least 1 column\n        v05.Column(name=\"1\"),\n        v05.Column(name=\"2\"),\n        v05.Column(name=\"3\")\n    ],\n    rows=[  # must have at least 1 row\n        v05.Row(name=\"A\"),\n        v05.Row(name=\"B\")\n    ],\n    wells=[  # must have at least 1 well, paths match tree structure\n        v05.PlateWell(path=\"A/1\", rowIndex=0, columnIndex=0),\n        v05.PlateWell(path=\"A/2\", rowIndex=0, columnIndex=1),\n        v05.PlateWell(path=\"B/1\", rowIndex=1, columnIndex=0),\n    ],\n    acquisitions=[  # optional \n        v05.Acquisition(id=0, name=\"Initial\", maximumfieldcount=4),\n        v05.Acquisition(id=1, name=\"24h\", maximumfieldcount=4),\n    ],\n    field_count=4  # max FOV per well\n)\n\nplate = v05.Plate(plate=plate_def)\n\n# Create full zarr.json\nzarr_json = v05.OMEZarrGroupJSON(attributes={\"ome\": plate})\njson_str = zarr_json.model_dump_json(indent=2, exclude_unset=True)\n</code></pre>"},{"location":"ome_zarr_guide/#well-metadata","title":"Well Metadata","text":"<p>Wells list the fields of view (images) they contain:</p> <p>Spec JSON (<code>.zattrs</code> in well directory):</p> <pre><code>{\n  \"well\": {\n    \"version\": \"0.4\",\n    \"images\": [\n      {\"path\": \"0\", \"acquisition\": 0},\n      {\"path\": \"1\", \"acquisition\": 0},\n      {\"path\": \"2\", \"acquisition\": 1}\n    ]\n  }\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v04\n\nwell_def = v04.WellDef(\n    images=[\n        v04.FieldOfView(path=\"0\", acquisition=0),\n        v04.FieldOfView(path=\"1\", acquisition=0),\n        v04.FieldOfView(path=\"2\", acquisition=1),\n    ]\n)\n\nwell = v04.Well(well=well_def)\n</code></pre> Field Requirement Description <code>images</code> MUST List of field of view objects <code>images[].path</code> MUST Path to image group <code>images[].acquisition</code> MUST (if multiple acquisitions exist) Links to plate acquisition ID"},{"location":"ome_zarr_guide/#interactive-example_1","title":"Interactive Example","text":"<p>Modify the parameters below to see how different image configurations are represented in OME-Zarr:</p> <p></p>"},{"location":"ome_zarr_guide/#working-with-collections","title":"Working with Collections","text":"<p>OME-Zarr does not currently have an official specification for collections of images.</p> <p>By Collections of images, we mean groups of related images, usually sharing a coordinate space, that do not fit into the plate model.  Examples include:</p> <ul> <li>Multiple stage positions on single coverslip</li> <li>Multiple angles in light sheet microscopy</li> <li>Tomographic tilt series</li> <li>Jagged or otherwise irregular sets of related images that don't fit the multiscales model</li> </ul> <p>Status</p> <p>There is a long-standing github issue that discusses potential future standards for collections, and a (currently pending) pull request for RFC-8, which covers this topic. But as of v0.5 and January 2026, there is no official spec.</p> <p>The <code>\"bioformats2raw\"</code> layout is a transitional solution, internally employed by the bioformats2raw tool when dumping multiple series (commonly found in image formats supported by bioformats) into a single zarr hierarchy.</p> <p>This bioformats2raw layout described in the NGFF spec, is described below:</p>"},{"location":"ome_zarr_guide/#directory-structure_2","title":"Directory Structure","text":"v0.4v0.5 <pre><code>series.ome.zarr               # One converted fileset from bioformats2raw\n    \u251c\u2500\u2500 .zgroup\n    \u251c\u2500\u2500 .zattrs               # Contains \"bioformats2raw.layout\" metadata\n    \u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n    \u2502   \u251c\u2500\u2500 .zgroup\n    \u2502   \u251c\u2500\u2500 .zattrs           # Contains \"series\" metadata\n    \u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n    \u251c\u2500\u2500 0                     # First image in the collection\n    \u251c\u2500\u2500 1                     # Second image in the collection\n    \u2514\u2500\u2500 ...\n</code></pre> <pre><code>series.ome.zarr               # One converted fileset from bioformats2raw\n    \u251c\u2500\u2500 zarr.json             # Contains \"bioformats2raw.layout\" metadata\n    \u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n    \u2502   \u251c\u2500\u2500 zarr.json         # Contains \"series\" metadata\n    \u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n    \u251c\u2500\u2500 0                     # First image in the collection\n    \u251c\u2500\u2500 1                     # Second image in the collection\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"ome_zarr_guide/#metadata","title":"Metadata","text":"v0.4v0.5 <p>Spec JSON (<code>.zattrs</code> at root):</p> <pre><code>{\n  \"bioformats2raw.layout\": 3\n}\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v04\n\n# Root .zattrs\nbf2raw = v04.Bf2Raw()  # layout defaults to 3\n\n# OME/.zattrs\nseries = v04.Series(series=[\"0\", \"1\", \"2\", \"3\"])\n</code></pre> <p>yaozarrs Code:</p> <pre><code>from yaozarrs import v05\n\n# Root zarr.json\nroot_zarr_json = v05.OMEZarrGroupJSON(\n  attributes={\"ome\": v05.Bf2Raw()}\n)\n\n# OME/zarr.json\nome_zarr_json = v05.OMEZarrGroupJSON(\n    attributes={\"ome\": v05.Series(series=[\"0\", \"1\", \"2\", \"3\"])}\n)\n</code></pre> <p>Image Location Rules</p> <ol> <li>If <code>plate</code> metadata exists \u2192 use plate structure</li> <li>If <code>series</code> attribute exists in <code>OME/.zattrs</code> \u2192 paths must match OME-XML Image element order</li> <li>Otherwise \u2192 consecutively numbered groups: <code>0/</code>, <code>1/</code>, <code>2/</code>...</li> </ol>"},{"location":"ome_zarr_guide/#when-to-use-collections-vs-plates","title":"When to Use Collections vs. Plates","text":"Scenario Use Collection Use Plate Multiple FOVs on coverslip Irregular stage positions Time-lapse split across files Multi-well HCS experiment Regular grid with well labels <p>Rule of thumb</p> <p>If your data has rows and columns (like A1, B2, etc.), use a Plate. If it's just multiple related images, use a Collection.</p>"},{"location":"ome_zarr_guide/#reference","title":"Reference","text":""},{"location":"ome_zarr_guide/#version-comparison-matrix","title":"Version Comparison Matrix","text":"Feature v0.2 v0.3 v0.4 v0.5 Zarr version v2 v2 v2 v3 Axes format Implicit TCZYX Strings Objects Objects Axis type field N/A N/A SHOULD SHOULD Axis unit field N/A N/A SHOULD SHOULD Coordinate transforms N/A N/A MUST MUST Metadata location <code>.zattrs</code> <code>.zattrs</code> <code>.zattrs</code> <code>zarr.json</code> OME namespace N/A N/A N/A <code>attributes.ome</code> <code>dimension_names</code> N/A N/A N/A MUST Plate indices Optional Optional MUST MUST"},{"location":"ome_zarr_guide/#breaking-changes-quick-reference","title":"Breaking Changes Quick Reference","text":"Migration Key Breaking Change Impact v0.2 \u2192 v0.3 Axes must be explicit strings  Moderate - add <code>axes</code> field v0.3 \u2192 v0.4 Axes become objects + coordinate transforms required  Major - restructure metadata v0.4 \u2192 v0.5 Zarr v3 file structure + OME namespace  Critical - completely different storage"},{"location":"ome_zarr_guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>OME-Zarr Specification - Official specification</li> <li>yaozarrs API Documentation - Complete API reference</li> <li>Zarr Format Specification - Zarr v2 and v3 specs</li> <li>OME Data Model - Full OME-XML specification</li> <li>GitHub Repository - Source code and issues</li> </ul> <p>You're ready!</p> <p>You now understand the OME-Zarr specification and how to work with it using yaozarrs. Happy imaging!</p>"},{"location":"API_Reference/yaozarrs/","title":"yaozarrs","text":""},{"location":"API_Reference/yaozarrs/#yaozarrs","title":"<code>yaozarrs</code>","text":"<p>Yet another ome-zarr model.</p> <p>Modules:</p> Name Description <code>v04</code> <p>OME-NGFF v0.4 metadata models.</p> <code>v05</code> <p>OME-NGFF v0.5 metadata models.</p> <code>write</code> <p>Write utilities for yaozarrs.</p> <p>Classes:</p> Name Description <code>DimSpec</code> <p>Specification for a single dimension of an OME-Zarr image.</p> <code>ZarrGroup</code> <p>Minimal wrapper around a zarr v2/v3 group.</p> <p>Functions:</p> Name Description <code>open_group</code> <p>Open a zarr v2/v3 group from a URI.</p> <code>validate_ome_json</code> <p>Validate any ome-zarr JSON string or bytes literal.</p> <code>validate_ome_object</code> <p>Validate any python object representing an OME-Zarr document or node.</p> <code>validate_ome_uri</code> <p>Load and validate root metadata in a OME-Zarr group from a URI or local path.</p> <code>validate_zarr_store</code> <p>Validate both structure and metadata of an OME-Zarr hierarchy.</p>"},{"location":"API_Reference/yaozarrs/#yaozarrs.DimSpec","title":"<code>DimSpec</code>","text":"<p>Specification for a single dimension of an OME-Zarr image.</p> <p>Warning</p> <p>This is a convenience class and is not a part of the OME-Zarr specification.</p> <p>There are some places in the OME Zarr spec where information about a given axis must be entered in multiple different places (e.g., <code>Multiscale.axes</code> must agree with <code>Multiscale.datasets.CoordinateTransformation</code>, etc). <code>DimSpec</code> is a convenience class that encapsulates all the relevant information about a single dimension in one place, and may be used in specialized constructors (e.g. <code>v05.Multiscale.from_dims</code>)</p> <p>Examples:</p> <p>5D timelapse with channels:</p> <pre><code>from yaozarrs import DimSpec, v05\n\ndims = [\n    DimSpec(name=\"t\", size=100, scale=1.0, unit=\"second\"),\n    DimSpec(name=\"c\", size=3),\n    DimSpec(name=\"z\", size=50, scale=2.0, unit=\"micrometer\"),\n    DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n    DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n]\nmultiscale = v05.Multiscale.from_dims(dims, name=\"my_image\", n_levels=3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dimension. Common names like 'x', 'y', 'z' will be inferred as spatial dimensions; 't' as time; 'c' as channel.</p> required <code>size</code> <code>int | None</code> <p>The size of the dimension (number of elements along this axis). This is not used anywhere by the OME-Zarr spec, but is useful when creating new empty datasets.</p> <code>None</code> <code>scale</code> <code>float</code> <p>The scale factor for this dimension in physical units.</p> <code>1.0</code> <code>unit</code> <code>str | None</code> <p>The physical unit for this dimension (e.g., 'micrometer', 'second'). If not provided, no unit will be set on the axis.</p> <code>None</code> <code>type</code> <code>Literal['space', 'time', 'channel'] | str | None</code> <p>The type of axis ('space', 'time', 'channel', or custom). If not provided, will be inferred from the name: x/y/z -&gt; 'space', t -&gt; 'time', c -&gt; 'channel'.</p> <code>None</code> <code>scale_factor</code> <code>float | None</code> <p>The scale factor for downsampling along this dimension at each multiscale level. If not provided, defaults to 2.0 for spatial dimensions (x/y/z) and 1.0 for others. To avoid downsampling along the z dimension (which is inferred to be a spatial dimension), set this explicitly to 1.0.</p> <code>None</code> <code>translation</code> <code>float | None</code> <p>The translation offset for this dimension in physical units. If not provided, no translation transform will be applied. If only some dimensions have translation specified, all others will default to 0.0.</p> <code>None</code> <p>Methods:</p> Name Description <code>infer_scale_factor</code> <p>Infer the scale factor for downsampling based on dimension type.</p> <code>infer_type</code> <p>Infer the axis type from the dimension name.</p> Source code in <code>src/yaozarrs/_dim_spec.py</code> <pre><code>class DimSpec(_BaseModel):\n    \"\"\"Specification for a single dimension of an OME-Zarr image.\n\n    !!! warning\n\n        This is a convenience class and is **not** a part of the OME-Zarr specification.\n\n    There are some places in the OME Zarr spec where information about a given axis must\n    be entered in multiple different places (e.g., `Multiscale.axes` must agree with\n    `Multiscale.datasets.CoordinateTransformation`, etc). `DimSpec` is a convenience\n    class that encapsulates all the relevant information about a single dimension in one\n    place, and may be used in specialized constructors (e.g. `v05.Multiscale.from_dims`)\n\n    Examples\n    --------\n    5D timelapse with channels:\n\n    ```python\n    from yaozarrs import DimSpec, v05\n\n    dims = [\n        DimSpec(name=\"t\", size=100, scale=1.0, unit=\"second\"),\n        DimSpec(name=\"c\", size=3),\n        DimSpec(name=\"z\", size=50, scale=2.0, unit=\"micrometer\"),\n        DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n        DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n    ]\n    multiscale = v05.Multiscale.from_dims(dims, name=\"my_image\", n_levels=3)\n    ```\n    \"\"\"\n\n    name: str = Field(\n        description=(\n            \"The name of the dimension. Common names like 'x', 'y', 'z' will be \"\n            \"inferred as spatial dimensions; 't' as time; 'c' as channel.\"\n        )\n    )\n    size: int | None = Field(\n        default=None,\n        description=(\n            \"The size of the dimension (number of elements along this axis). \"\n            \"This is not used anywhere by the OME-Zarr spec, but is useful when \"\n            \"creating new empty datasets.\"\n        ),\n    )\n    scale: float = Field(\n        default=1.0,\n        description=\"The scale factor for this dimension in physical units.\",\n    )\n    unit: str | None = Field(\n        default=None,\n        description=(\n            \"The physical unit for this dimension (e.g., 'micrometer', 'second'). \"\n            \"If not provided, no unit will be set on the axis.\"\n        ),\n    )\n    type: Literal[\"space\", \"time\", \"channel\"] | str | None = Field(\n        default=None,\n        description=(\n            \"The type of axis ('space', 'time', 'channel', or custom). If not \"\n            \"provided, will be inferred from the name: x/y/z -&gt; 'space', \"\n            \"t -&gt; 'time', c -&gt; 'channel'.\"\n        ),\n    )\n    scale_factor: float | None = Field(\n        default=None,\n        description=(\n            \"The scale factor for downsampling along this dimension at each \"\n            \"multiscale level. If not provided, defaults to 2.0 for spatial \"\n            \"dimensions (x/y/z) and 1.0 for others. To *avoid* downsampling along \"\n            \"the z dimension (which is inferred to be a spatial dimension), \"\n            \"set this explicitly to 1.0.\"\n        ),\n    )\n    translation: float | None = Field(\n        default=None,\n        description=(\n            \"The translation offset for this dimension in physical units. If not \"\n            \"provided, no translation transform will be applied. If only some \"\n            \"dimensions have translation specified, all others will default to 0.0.\"\n        ),\n    )\n\n    def infer_scale_factor(self) -&gt; float:\n        \"\"\"Infer the scale factor for downsampling based on dimension type.\n\n        !!! warning \":sparkles:{ .pulse } **Magic Alert** \"\n            *By default, this downscales all spatial dimensions by 2 when creating\n            pyramid levels.  Explicitly set `scale_factor` to override.*\n\n        \"\"\"\n        if self.scale_factor is not None:\n            return self.scale_factor\n        return 2.0 if self.infer_type() == \"space\" else 1.0\n\n    def infer_type(self) -&gt; str | None:\n        \"\"\"Infer the axis type from the dimension name.\n\n        !!! warning \":sparkles:{ .pulse } **Magic Alert** \"\n            *This treats names of \"x\", \"y\", \"z\", \"t\", \"time\", \"c\", and \"channel\"\n            specially!*\n\n        Returns\n        -------\n        str | None\n            The inferred type: 'space' for x/y/z, 'time' for t, 'channel' for c,\n            or the explicitly set type if provided.\n        \"\"\"\n        if self.type is not None:\n            return self.type\n        name_lower = self.name.lower()\n        if name_lower in (\"x\", \"y\", \"z\"):\n            return \"space\"\n        if name_lower in {\"t\", \"time\"}:\n            return \"time\"\n        if name_lower in {\"c\", \"channel\"}:\n            return \"channel\"\n        return None\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.DimSpec.infer_scale_factor","title":"<code>infer_scale_factor()</code>","text":"<p>Infer the scale factor for downsampling based on dimension type.</p> <p> Magic Alert </p> <p>By default, this downscales all spatial dimensions by 2 when creating pyramid levels.  Explicitly set <code>scale_factor</code> to override.</p> Source code in <code>src/yaozarrs/_dim_spec.py</code> <pre><code>def infer_scale_factor(self) -&gt; float:\n    \"\"\"Infer the scale factor for downsampling based on dimension type.\n\n    !!! warning \":sparkles:{ .pulse } **Magic Alert** \"\n        *By default, this downscales all spatial dimensions by 2 when creating\n        pyramid levels.  Explicitly set `scale_factor` to override.*\n\n    \"\"\"\n    if self.scale_factor is not None:\n        return self.scale_factor\n    return 2.0 if self.infer_type() == \"space\" else 1.0\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.DimSpec.infer_type","title":"<code>infer_type()</code>","text":"<p>Infer the axis type from the dimension name.</p> <p> Magic Alert </p> <p>This treats names of \"x\", \"y\", \"z\", \"t\", \"time\", \"c\", and \"channel\" specially!</p> <p>Returns:</p> Type Description <code>str | None</code> <p>The inferred type: 'space' for x/y/z, 'time' for t, 'channel' for c, or the explicitly set type if provided.</p> Source code in <code>src/yaozarrs/_dim_spec.py</code> <pre><code>def infer_type(self) -&gt; str | None:\n    \"\"\"Infer the axis type from the dimension name.\n\n    !!! warning \":sparkles:{ .pulse } **Magic Alert** \"\n        *This treats names of \"x\", \"y\", \"z\", \"t\", \"time\", \"c\", and \"channel\"\n        specially!*\n\n    Returns\n    -------\n    str | None\n        The inferred type: 'space' for x/y/z, 'time' for t, 'channel' for c,\n        or the explicitly set type if provided.\n    \"\"\"\n    if self.type is not None:\n        return self.type\n    name_lower = self.name.lower()\n    if name_lower in (\"x\", \"y\", \"z\"):\n        return \"space\"\n    if name_lower in {\"t\", \"time\"}:\n        return \"time\"\n    if name_lower in {\"c\", \"channel\"}:\n        return \"channel\"\n    return None\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup","title":"<code>ZarrGroup</code>","text":"<p>Minimal wrapper around a zarr v2/v3 group.</p> <p>Important</p> <p>Requires <code>yaozarrs[io]</code> or <code>fsspec</code> to be installed.</p> <p>This class exists to provide minimal zarr group functionality, needed for hierarchy traversal and structural validation, without requiring a dependency on a full blown zarr array-writing library (which come with heavier dependencies, and python version limitations).</p> <p>Matches <code>zarr-python</code> behavior: expects all children to be the same zarr_format version as the parent. Does not support mixed hierarchies.</p> <p>Methods:</p> Name Description <code>ome_version</code> <p>Return ome_version if present, else None.</p> <code>validate</code> <p>Validate the zarr group structure.</p> <code>ome_metadata</code> <p>Return the OME metadata (as a yaozarrs object) if present, else None.</p> <code>node_type</code> <p>Return the node type (group or array).</p> <code>prefetch_children</code> <p>Prefetch metadata for multiple children using async batch fetching.</p> <code>__contains__</code> <p>Check if a child node exists.</p> <code>get</code> <p>Get a child node (group or array), or return default if not found.</p> <code>__getitem__</code> <p>Get a child node (group or array).</p> <code>to_zarr_python</code> <p>Convert to a zarr-python Group object (requires <code>zarr-python</code>).</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>class ZarrGroup(ZarrNode):\n    \"\"\"Minimal wrapper around a zarr v2/v3 group.\n\n    !!!important\n        Requires `yaozarrs[io]` or `fsspec` to be installed.\n\n    This class exists to provide minimal zarr group functionality, needed for hierarchy\n    traversal and structural validation, without requiring a dependency on a full blown\n    zarr array-writing library (which come with heavier dependencies, and python version\n    limitations).\n\n    Matches `zarr-python` behavior: expects all children to be the same\n    zarr_format version as the parent. Does not support mixed hierarchies.\n    \"\"\"\n\n    __slots__ = (\"_ome_metadata\",)\n\n    def ome_version(self) -&gt; str | None:\n        \"\"\"Return ome_version if present, else None.\n\n        Attempt to determine version as minimally as possible without\n        parsing full models.\n        \"\"\"\n        attrs = self._metadata.attributes\n        if \"ome\" in attrs:\n            if \"version\" in attrs[\"ome\"]:\n                return attrs[\"ome\"][\"version\"]\n        # TODO: this is probably flaky\n        if ms := attrs.get(\"multiscales\"):\n            return ms[0][\"version\"]\n        if plate := attrs.get(\"plate\"):\n            return plate[\"version\"]\n        if \"bioformats2raw.layout\" in attrs:\n            if \"0\" in self and isinstance(group := self[\"0\"], ZarrGroup):\n                return group.ome_version()\n        return None\n\n    def validate(self) -&gt; Self:\n        \"\"\"Validate the zarr group structure.\n\n        This is a convenience method that calls [`yaozarrs.validate_zarr_store`][]\n        on this group.\n\n        Raises\n        ------\n        StorageValidationError\n            If the storage structure is invalid.\n        \"\"\"\n        from yaozarrs._storage import validate_zarr_store\n\n        validate_zarr_store(self)\n        return self\n\n    def ome_metadata(\n        self, *, version: str | None = None\n    ) -&gt; v05.OMEMetadata | v04.OMEZarrGroupJSON | None:\n        \"\"\"Return the OME metadata (as a yaozarrs object) if present, else None.\"\"\"\n        if not hasattr(self, \"_ome_metadata\"):\n            meta = self._metadata\n            self._ome_metadata = meta.ome_metadata(version=version)\n        return self._ome_metadata\n\n    @classmethod\n    def node_type(cls) -&gt; Literal[\"group\"]:\n        \"\"\"Return the node type (group or array).\"\"\"\n        return \"group\"\n\n    def prefetch_children(self, child_keys: Iterable[str]) -&gt; None:\n        \"\"\"Prefetch metadata for multiple children using async batch fetching.\n\n        For HTTPS URIs, this triggers fsspec's async batch fetching which uses\n        aiohttp to fetch up to 1280 files concurrently. Results are cached in\n        the _CachedMapper for subsequent access.\n\n        This is critical for performance with remote stores - a 384-well plate\n        can have 2000+ metadata files. Without batching, sequential fetches would\n        take 10+ minutes; with batching, validation completes in ~80 seconds.\n\n        Parameters\n        ----------\n        child_keys : list[str]\n            List of child keys to prefetch.\n        \"\"\"\n        # Build list of metadata file paths to fetch\n        metadata_paths = []\n        for key in child_keys:\n            child_path = f\"{self._path}/{key}\" if self._path else key\n            if self._metadata.zarr_format &gt;= 3:\n                metadata_paths.append(f\"{child_path}/zarr.json\")\n            else:\n                # For v2, we need to check .zgroup, .zarray, AND .zattrs\n                # The .zattrs file contains OME metadata and must be prefetched\n                # to avoid individual HTTP requests when loading group metadata\n                metadata_paths.extend(\n                    [\n                        f\"{child_path}/.zgroup\",\n                        f\"{child_path}/.zarray\",\n                        f\"{child_path}/.zattrs\",\n                    ]\n                )\n\n        # Batch fetch using getitems - _CachedMapper handles fallback if needed\n        try:\n            self._store.getitems(metadata_paths)\n        except Exception:\n            # If batch fetching fails, _CachedMapper will fall back to sequential\n            # access when files are actually requested via __getitem__\n            pass\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"Check if a child node exists.\"\"\"\n        child_path = f\"{self._path}/{key}\" if self._path else key\n\n        if self._metadata.zarr_format &gt;= 3:\n            return f\"{child_path}/zarr.json\" in self._store\n        else:\n            return (\n                f\"{child_path}/.zgroup\" in self._store\n                or f\"{child_path}/.zarray\" in self._store\n            )\n\n    def get(self, key: str, default: Any = None) -&gt; ZarrGroup | ZarrArray | None:\n        \"\"\"Get a child node (group or array), or return default if not found.\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __getitem__(self, key: str) -&gt; ZarrGroup | ZarrArray:\n        \"\"\"Get a child node (group or array).\"\"\"\n        child_path = f\"{self._path}/{key}\" if self._path else key\n        if self._metadata.zarr_format &gt;= 3:\n            return self._getitem_v3(child_path, key)\n        else:\n            return self._getitem_v2(child_path, key)\n\n    def _getitem_v3(self, child_path: str, key: str) -&gt; ZarrGroup | ZarrArray:\n        \"\"\"Get a v3 child node.\"\"\"\n        prefix = f\"{child_path}/\"\n        if (meta := _load_zarr_json(prefix, self._store)) is not None:\n            if meta.node_type == \"group\":\n                return ZarrGroup(self._store, child_path, meta)\n            elif meta.node_type == \"array\":\n                return ZarrArray(self._store, child_path, meta)\n            else:  # pragma: no cover\n                raise ValueError(f\"Unknown node_type: {meta.node_type}\")\n\n        raise KeyError(key)\n\n    def _getitem_v2(self, child_path: str, key: str) -&gt; ZarrGroup | ZarrArray:\n        \"\"\"Get a v2 child node.\"\"\"\n        prefix = f\"{child_path}/\"\n        # Try group\n        if (meta := _load_zgroup(prefix, self._store)) is not None:\n            return ZarrGroup(self._store, child_path, meta)\n\n        if (meta := _load_zarray(prefix, self._store)) is not None:\n            return ZarrArray(self._store, child_path, meta)\n\n        raise KeyError(key)\n\n    if TYPE_CHECKING:\n\n        def to_zarr_python(self) -&gt; zarr.Group:  # type: ignore\n            \"\"\"Convert to a zarr-python Group object (requires `zarr-python`).\"\"\"\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.ome_version","title":"<code>ome_version()</code>","text":"<p>Return ome_version if present, else None.</p> <p>Attempt to determine version as minimally as possible without parsing full models.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def ome_version(self) -&gt; str | None:\n    \"\"\"Return ome_version if present, else None.\n\n    Attempt to determine version as minimally as possible without\n    parsing full models.\n    \"\"\"\n    attrs = self._metadata.attributes\n    if \"ome\" in attrs:\n        if \"version\" in attrs[\"ome\"]:\n            return attrs[\"ome\"][\"version\"]\n    # TODO: this is probably flaky\n    if ms := attrs.get(\"multiscales\"):\n        return ms[0][\"version\"]\n    if plate := attrs.get(\"plate\"):\n        return plate[\"version\"]\n    if \"bioformats2raw.layout\" in attrs:\n        if \"0\" in self and isinstance(group := self[\"0\"], ZarrGroup):\n            return group.ome_version()\n    return None\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.validate","title":"<code>validate()</code>","text":"<p>Validate the zarr group structure.</p> <p>This is a convenience method that calls <code>yaozarrs.validate_zarr_store</code> on this group.</p> <p>Raises:</p> Type Description <code>StorageValidationError</code> <p>If the storage structure is invalid.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def validate(self) -&gt; Self:\n    \"\"\"Validate the zarr group structure.\n\n    This is a convenience method that calls [`yaozarrs.validate_zarr_store`][]\n    on this group.\n\n    Raises\n    ------\n    StorageValidationError\n        If the storage structure is invalid.\n    \"\"\"\n    from yaozarrs._storage import validate_zarr_store\n\n    validate_zarr_store(self)\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.ome_metadata","title":"<code>ome_metadata(*, version=None)</code>","text":"<p>Return the OME metadata (as a yaozarrs object) if present, else None.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def ome_metadata(\n    self, *, version: str | None = None\n) -&gt; v05.OMEMetadata | v04.OMEZarrGroupJSON | None:\n    \"\"\"Return the OME metadata (as a yaozarrs object) if present, else None.\"\"\"\n    if not hasattr(self, \"_ome_metadata\"):\n        meta = self._metadata\n        self._ome_metadata = meta.ome_metadata(version=version)\n    return self._ome_metadata\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.node_type","title":"<code>node_type()</code>  <code>classmethod</code>","text":"<p>Return the node type (group or array).</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>@classmethod\ndef node_type(cls) -&gt; Literal[\"group\"]:\n    \"\"\"Return the node type (group or array).\"\"\"\n    return \"group\"\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.prefetch_children","title":"<code>prefetch_children(child_keys)</code>","text":"<p>Prefetch metadata for multiple children using async batch fetching.</p> <p>For HTTPS URIs, this triggers fsspec's async batch fetching which uses aiohttp to fetch up to 1280 files concurrently. Results are cached in the _CachedMapper for subsequent access.</p> <p>This is critical for performance with remote stores - a 384-well plate can have 2000+ metadata files. Without batching, sequential fetches would take 10+ minutes; with batching, validation completes in ~80 seconds.</p> <p>Parameters:</p> Name Type Description Default <code>child_keys</code> <code>list[str]</code> <p>List of child keys to prefetch.</p> required Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def prefetch_children(self, child_keys: Iterable[str]) -&gt; None:\n    \"\"\"Prefetch metadata for multiple children using async batch fetching.\n\n    For HTTPS URIs, this triggers fsspec's async batch fetching which uses\n    aiohttp to fetch up to 1280 files concurrently. Results are cached in\n    the _CachedMapper for subsequent access.\n\n    This is critical for performance with remote stores - a 384-well plate\n    can have 2000+ metadata files. Without batching, sequential fetches would\n    take 10+ minutes; with batching, validation completes in ~80 seconds.\n\n    Parameters\n    ----------\n    child_keys : list[str]\n        List of child keys to prefetch.\n    \"\"\"\n    # Build list of metadata file paths to fetch\n    metadata_paths = []\n    for key in child_keys:\n        child_path = f\"{self._path}/{key}\" if self._path else key\n        if self._metadata.zarr_format &gt;= 3:\n            metadata_paths.append(f\"{child_path}/zarr.json\")\n        else:\n            # For v2, we need to check .zgroup, .zarray, AND .zattrs\n            # The .zattrs file contains OME metadata and must be prefetched\n            # to avoid individual HTTP requests when loading group metadata\n            metadata_paths.extend(\n                [\n                    f\"{child_path}/.zgroup\",\n                    f\"{child_path}/.zarray\",\n                    f\"{child_path}/.zattrs\",\n                ]\n            )\n\n    # Batch fetch using getitems - _CachedMapper handles fallback if needed\n    try:\n        self._store.getitems(metadata_paths)\n    except Exception:\n        # If batch fetching fails, _CachedMapper will fall back to sequential\n        # access when files are actually requested via __getitem__\n        pass\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a child node exists.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"Check if a child node exists.\"\"\"\n    child_path = f\"{self._path}/{key}\" if self._path else key\n\n    if self._metadata.zarr_format &gt;= 3:\n        return f\"{child_path}/zarr.json\" in self._store\n    else:\n        return (\n            f\"{child_path}/.zgroup\" in self._store\n            or f\"{child_path}/.zarray\" in self._store\n        )\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.get","title":"<code>get(key, default=None)</code>","text":"<p>Get a child node (group or array), or return default if not found.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def get(self, key: str, default: Any = None) -&gt; ZarrGroup | ZarrArray | None:\n    \"\"\"Get a child node (group or array), or return default if not found.\"\"\"\n    try:\n        return self[key]\n    except KeyError:\n        return default\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get a child node (group or array).</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def __getitem__(self, key: str) -&gt; ZarrGroup | ZarrArray:\n    \"\"\"Get a child node (group or array).\"\"\"\n    child_path = f\"{self._path}/{key}\" if self._path else key\n    if self._metadata.zarr_format &gt;= 3:\n        return self._getitem_v3(child_path, key)\n    else:\n        return self._getitem_v2(child_path, key)\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.ZarrGroup.to_zarr_python","title":"<code>to_zarr_python()</code>","text":"<p>Convert to a zarr-python Group object (requires <code>zarr-python</code>).</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def to_zarr_python(self) -&gt; zarr.Group:  # type: ignore\n    \"\"\"Convert to a zarr-python Group object (requires `zarr-python`).\"\"\"\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.open_group","title":"<code>open_group(uri, storage_options=None)</code>","text":"<p>Open a zarr v2/v3 group from a URI.</p> <p>Important</p> <p>Requires <code>yaozarrs[io]</code> or <code>fsspec</code> to be installed.</p> <p>Returns a small wrapper around the zarr group URI that allows reading metadata and traversing the hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str | PathLike</code> <p>The URI of the zarr store (e.g., \"https://...\", \"s3://...\", \"/path/to/file\"), or a zarr-python Group.</p> required <code>storage_options</code> <code>dict | None</code> <p>Additional storage options to pass to fsspec when opening the mapper.</p> <code>None</code> <p>Returns:</p> Type Description <code>ZarrGroup</code> <p>The opened zarr group with caching enabled.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If no zarr metadata is found at the specified URI.</p> <code>ValueError</code> <p>If the metadata is invalid or inconsistent, or if the root node is not a group.</p> Source code in <code>src/yaozarrs/_zarr.py</code> <pre><code>def open_group(\n    uri: str | os.PathLike | Any, storage_options: dict | None = None\n) -&gt; ZarrGroup:\n    \"\"\"Open a zarr v2/v3 group from a URI.\n\n    !!!important\n        Requires `yaozarrs[io]` or `fsspec` to be installed.\n\n    Returns a small wrapper around the zarr group URI that allows\n    reading metadata and traversing the hierarchy.\n\n    Parameters\n    ----------\n    uri : str | os.PathLike\n        The URI of the zarr store (e.g., \"https://...\", \"s3://...\", \"/path/to/file\"),\n        or a zarr-python Group.\n    storage_options : dict | None\n        Additional storage options to pass to fsspec when opening the mapper.\n\n    Returns\n    -------\n    ZarrGroup\n        The opened zarr group with caching enabled.\n\n    Raises\n    ------\n    FileNotFoundError\n        If no zarr metadata is found at the specified URI.\n    ValueError\n        If the metadata is invalid or inconsistent, or if the root node is not a group.\n    \"\"\"\n    try:\n        from fsspec import FSMap, get_mapper\n    except ImportError as e:\n        raise ImportError(\n            \"fsspec package is required for open_group().  \"\n            \"Please install with `pip install yaozarrs[io]` or \"\n            \"`pip install fsspec`.\"\n        ) from e\n\n    if isinstance(uri, ZarrGroup):\n        return uri\n\n    if isinstance(uri, (str, os.PathLike)):\n        uri = os.path.expanduser(os.fspath(uri))\n    elif hasattr(uri, \"store\"):\n        # Handle both zarr v2 and v3 Group objects\n        # v3: str(group.store) returns a URI like \"file:///path\"\n        # v2: group.store.path returns the directory path\n        if hasattr(uri.store, \"path\"):\n            # Zarr v2: DirectoryStore has .path attribute\n            uri = uri.store.path\n        else:\n            # Zarr v3: LocalStore's __str__ returns URI\n            uri = str(uri.store)\n    else:  # pragma: no cover\n        raise TypeError(\n            \"uri must be a string, os.PathLike, or have a 'store' attribute\"\n        )\n\n    storage_options = storage_options or {}\n    if str(uri).startswith(\"s3://\"):\n        storage_options.setdefault(\"anon\", True)\n    mapper = get_mapper(uri, **storage_options)  # type: ignore\n\n    if not isinstance(mapper, FSMap):  # pragma: no cover\n        raise TypeError(f\"Expected FSMap from get_mapper, got {type(mapper)}\")\n\n    # Wrap in caching layer for metadata-level caching\n    cached_mapper = _CachedMapper(mapper)\n    node = ZarrNode(cached_mapper)\n\n    if node._metadata.node_type != \"group\":\n        raise ValueError(\n            f\"Expected root node to be 'group', got '{node._metadata.node_type}'\"\n        )\n    return ZarrGroup(cached_mapper, node._path, node._metadata)\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.validate_ome_json","title":"<code>validate_ome_json(data, cls=None)</code>","text":"<pre><code>validate_ome_json(\n    data: str | bytes | bytearray, cls: type[T]\n) -&gt; T\n</code></pre><pre><code>validate_ome_json(data: str | bytes | bytearray) -&gt; AnyOME\n</code></pre> <p>Validate any ome-zarr JSON string or bytes literal.</p> <p>By default, this will validate <code>data</code> against all known OME JSON documents. This includes ome-zarr group documents for v04 (found at .zattrs in the zarr group) and v05 (found at zarr.json in the zarr group).  For v05 objects, it also detects data that would valid as the value of the <code>data[\"attributes\"][\"ome\"]</code> key inside a v05 zarr.json document.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | bytes | bytearray</code> <p>The OMENode instance to validate.</p> required <code>cls</code> <code>type[T]</code> <p>The class to validate against. Must be a subclass of <code>BaseModel</code>. If not provided, defaults to <code>OMENode</code>, meaning any valid OME node object</p> <code>None</code> <p>Returns:</p> Name Type Description <code>object</code> <code>T</code> <p>The validated (pydantic) model instance.</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the validation fails.</p> Source code in <code>src/yaozarrs/_validate.py</code> <pre><code>def validate_ome_json(\n    data: str | bytes | bytearray, cls: type[T] | Any = None\n) -&gt; T | AnyOME:\n    \"\"\"Validate any ome-zarr JSON string or bytes literal.\n\n    By default, this will validate `data` against all known OME JSON documents.\n    This includes ome-zarr group documents for v04 (found at .zattrs in the zarr group)\n    and v05 (found at zarr.json in the zarr group).  For v05 objects, it also detects\n    data that would valid as the value of the `data[\"attributes\"][\"ome\"]` key inside\n    a v05 zarr.json document.\n\n    Parameters\n    ----------\n    data : str | bytes | bytearray\n        The OMENode instance to validate.\n    cls : type[T]\n        The class to validate against. Must be a subclass of `BaseModel`.\n        If not provided, defaults to `OMENode`, meaning any valid OME node object\n\n    Returns\n    -------\n    object: T\n        The validated (pydantic) model instance.\n\n    Raises\n    ------\n    pydantic.ValidationError\n        If the validation fails.\n    \"\"\"\n    adapter = TypeAdapter[T](cls or AnyOME)\n    return adapter.validate_json(data)\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.validate_ome_object","title":"<code>validate_ome_object(node, cls=None)</code>","text":"<pre><code>validate_ome_object(node: Any, cls: type[T]) -&gt; T\n</code></pre><pre><code>validate_ome_object(node: Any) -&gt; AnyOME\n</code></pre> <p>Validate any python object representing an OME-Zarr document or node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Any</code> <p>The OME Node instance to validate.</p> required <code>cls</code> <code>type[T]</code> <p>The class to validate against. Must be a subclass of <code>BaseModel</code>. If not provided, defaults to <code>AnyOME</code>, meaning \"any valid OME node object\".</p> <code>None</code> <p>Returns:</p> Name Type Description <code>object</code> <code>T</code> <p>The validated (pydantic) model instance.</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the validation fails.</p> Source code in <code>src/yaozarrs/_validate.py</code> <pre><code>def validate_ome_object(node: Any, cls: type[T] | Any = None) -&gt; T | AnyOME:\n    \"\"\"Validate any python object representing an OME-Zarr document or node.\n\n    Parameters\n    ----------\n    node : Any\n        The OME Node instance to validate.\n    cls : type[T]\n        The class to validate against. Must be a subclass of `BaseModel`.\n        If not provided, defaults to `AnyOME`, meaning \"any valid OME node object\".\n\n    Returns\n    -------\n    object: T\n        The validated (pydantic) model instance.\n\n    Raises\n    ------\n    pydantic.ValidationError\n        If the validation fails.\n    \"\"\"\n    adapter = TypeAdapter[T](cls or AnyOME)\n    return adapter.validate_python(node)\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.validate_ome_uri","title":"<code>validate_ome_uri(uri, cls=None)</code>","text":"<pre><code>validate_ome_uri(uri: str | os.PathLike, cls: type[T]) -&gt; T\n</code></pre><pre><code>validate_ome_uri(uri: str | os.PathLike) -&gt; AnyOMEGroup\n</code></pre> <p>Load and validate root metadata in a OME-Zarr group from a URI or local path.</p> <p>Important</p> <p>This requires that you have installed yaozarrs with the <code>io</code> extra, e.g. <code>pip install yaozarrs[io]</code>.</p> <p>This function will attempt to load the OME-Zarr group metadata from the given URI or local path. The URI should be a path to a zarr group (directory or URL) with valid ome-zarr metadata, or a path directly to the metadata JSON file itself (e.g. zarr.json or .zattrs).</p> <p>This only loads and validates the root OME-Zarr group metadata.  It does not traverse the hierarchy, perform structural validation, or validate any child groups or arrays.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str | PathLike</code> <p>The URI or local path to the OME-Zarr group. This can be a file path, a directory path, or a URL.</p> required <code>cls</code> <code>type[T]</code> <p>The class to validate against. Must be a subclass of <code>BaseModel</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AnyOME</code> <code>T</code> <p>An instance of <code>v05.OMEZarrGroupJSON</code>, <code>v04.OMEZarrGroupJSON</code>, or another valid OME-Zarr node type, depending on the object detected.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the URI does not point to a valid OME-Zarr group.</p> <code>ValidationError</code> <p>If the loaded metadata is not valid according to the OME-Zarr specification.</p> Source code in <code>src/yaozarrs/_validate.py</code> <pre><code>def validate_ome_uri(\n    uri: str | os.PathLike, cls: type[T] | Any = None\n) -&gt; T | AnyOMEGroup:\n    \"\"\"Load and validate root metadata in a OME-Zarr group from a URI or local path.\n\n    !!!important\n        This requires that you have installed yaozarrs with the `io` extra, e.g.\n        `pip install yaozarrs[io]`.\n\n    This function will attempt to load the OME-Zarr group metadata from the given URI or\n    local path. The URI should be a path to a zarr group (directory or URL) with valid\n    ome-zarr metadata, or a path directly to the metadata JSON file itself (e.g.\n    zarr.json or .zattrs).\n\n    **This _only_ loads and validates the root OME-Zarr group metadata.**  It does not\n    traverse the hierarchy, perform structural validation, or validate any child groups\n    or arrays.\n\n    Parameters\n    ----------\n    uri : str | os.PathLike\n        The URI or local path to the OME-Zarr group. This can be a file path,\n        a directory path, or a URL.\n    cls : type[T]\n        The class to validate against. Must be a subclass of `BaseModel`.\n\n    Returns\n    -------\n    AnyOME: T\n        An instance of `v05.OMEZarrGroupJSON`, `v04.OMEZarrGroupJSON`, or another\n        valid OME-Zarr node type, depending on the object detected.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the URI does not point to a valid OME-Zarr group.\n    pydantic.ValidationError\n        If the loaded metadata is not valid according to the OME-Zarr specification.\n    \"\"\"\n    from ._io import read_json_from_uri\n\n    json_content, uri_str = read_json_from_uri(uri)\n    obj = validate_ome_json(json_content, cls or AnyOMEGroup)  # type: ignore\n    obj.uri = uri_str\n    return obj\n</code></pre>"},{"location":"API_Reference/yaozarrs/#yaozarrs.validate_zarr_store","title":"<code>validate_zarr_store(obj)</code>","text":"<p>Validate both structure and metadata of an OME-Zarr hierarchy.</p> <p>Important</p> <p>Requires <code>yaozarrs[io]</code> or <code>fsspec</code> to be installed.</p> <p>This is a high-level function to validate both the metadata and the structure of a complete OME-Zarr store.  This is the function used by the <code>yaozarrs validate</code> CLI command.</p> <p>Currently only supports OME-Zarr version 0.5.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>OMEZarrGroupJSON | ZarrGroup | str | Path | Any</code> <p>The zarr store to validate. Can be a URI string, a Path, a parsed OMEZarrGroupJSON object, a ZarrGroup instance, or a zarr.Group object (for backwards compatibility).</p> required <p>Returns:</p> Type Description <code>ZarrGroup</code> <p>The opened ZarrGroup if validation is successful.</p> <p>Raises:</p> Type Description <code>StorageValidationError</code> <p>If the storage structure is invalid.</p> Source code in <code>src/yaozarrs/_storage.py</code> <pre><code>def validate_zarr_store(obj: ZarrGroup | str | Path | Any) -&gt; ZarrGroup:\n    \"\"\"Validate both structure and metadata of an OME-Zarr hierarchy.\n\n    !!!important\n        Requires `yaozarrs[io]` or `fsspec` to be installed.\n\n    This is a high-level function to validate both the metadata and the structure\n    of a complete OME-Zarr store.  This is the function used by the `yaozarrs validate`\n    CLI command.\n\n    Currently only supports OME-Zarr version 0.5.\n\n    Parameters\n    ----------\n    obj : OMEZarrGroupJSON | ZarrGroup | str | Path | Any\n        The zarr store to validate. Can be a URI string, a Path, a parsed\n        OMEZarrGroupJSON object, a ZarrGroup instance, or a zarr.Group object\n        (for backwards compatibility).\n\n    Returns\n    -------\n    ZarrGroup\n        The opened ZarrGroup if validation is successful.\n\n    Raises\n    ------\n    StorageValidationError\n        If the storage structure is invalid.\n    \"\"\"\n    zarr_group = open_group(obj)\n    ome_version = zarr_group.ome_version()\n    if not ome_version:\n        raise ValueError(\n            f\"Unable to determine OME-Zarr version for {zarr_group}. \"\n            \"Is this an OME-Zarr group?\"\n        )\n\n    if ome_version == \"0.5\":\n        from yaozarrs.v05._storage import StorageValidatorV05\n\n        Validator = StorageValidatorV05\n    elif ome_version == \"0.4\":\n        from yaozarrs.v04._storage import StorageValidatorV04\n\n        Validator = StorageValidatorV04\n\n    else:\n        raise NotImplementedError(\n            f\"Structural validation for OME-Zarr version {ome_version} is \"\n            \"not implemented.\"\n        )\n\n    # Capture RuntimeWarnings from pydantic validators during validation\n    # and convert them to StorageValidationWarning\n    with warnings.catch_warnings(record=True) as captured_warnings:\n        warnings.filterwarnings(\"always\", category=ValidationWarning)\n        result = Validator.validate_group(zarr_group)\n\n    # prepend captured warnings to the result\n    for w in captured_warnings:\n        details: ErrorDetails = {\n            \"type\": \"model_warning\",\n            \"loc\": (),\n            \"msg\": str(w.message),\n        }\n        result.warnings.insert(0, details)\n\n    # Emit warnings for SHOULD directives from structural validation\n    if result.warnings:\n        # Use a custom formatter to match exception style\n        warning_instance = StorageValidationWarning(result.warnings)\n\n        _original_formatwarning = warnings.formatwarning\n\n        def _custom_formatwarning(message, category, *_, **__) -&gt; str:\n            # Format like an exception: module.Class: message\n            return f\"{category.__module__}.{category.__name__}: {message}\\n\"\n\n        warnings.formatwarning = _custom_formatwarning  # type: ignore\n        try:\n            warnings.warn(warning_instance, stacklevel=2)\n        finally:\n            warnings.formatwarning = _original_formatwarning\n\n    # Raise error if any validation issues found\n    if not result.is_valid:\n        raise StorageValidationError(result.errors)\n\n    return zarr_group\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/","title":"<code>yaozarrs.v04</code>","text":"<p>Specification: https://ngff.openmicroscopy.org/0.4</p> <p>Schema: https://github.com/ome/ngff/tree/7ac3430c74a66e5bcf53e41c429143172d68c0a4</p>"},{"location":"API_Reference/yaozarrs.v04/#images","title":"Images","text":""},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.Image","title":"<code>Image</code>","text":"<p>Top-level OME-NGFF v0.4 image metadata.</p> <p>This model corresponds to the <code>.zattrs</code> file in an image group (or <code>zarr.json</code> attributes in Zarr v3). It contains one or more multiscale pyramids plus optional OMERO rendering hints.</p> <p>Typical Structure</p> <pre><code>my_image/\n\u251c\u2500\u2500 .zattrs            # contains {\"multiscales\": [...]}\n\u251c\u2500\u2500 0/                 # Highest resolution array\n\u251c\u2500\u2500 1/                 # Next resolution level\n\u2514\u2500\u2500 labels/            # Optional segmentation masks\n</code></pre> <p>v0.4 vs v0.5</p> <p>In v0.4, the version field is inside the multiscale objects rather than at the top level. See <code>Multiscale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>multiscales</code> <code>list[Multiscale]</code> <p>One or more multiscale image pyramids in this group</p> required <code>omero</code> <code>Omero | None</code> <p>Optional OMERO rendering metadata for visualization</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>class Image(ZarrGroupModel):\n    \"\"\"Top-level OME-NGFF v0.4 image metadata.\n\n    This model corresponds to the `.zattrs` file in an image group\n    (or `zarr.json` attributes in Zarr v3). It contains one or more multiscale\n    pyramids plus optional OMERO rendering hints.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_image/\n        \u251c\u2500\u2500 .zattrs            # contains {\"multiscales\": [...]}\n        \u251c\u2500\u2500 0/                 # Highest resolution array\n        \u251c\u2500\u2500 1/                 # Next resolution level\n        \u2514\u2500\u2500 labels/            # Optional segmentation masks\n        ```\n\n    !!! note \"v0.4 vs v0.5\"\n        In v0.4, the version field is inside the multiscale objects rather than\n        at the top level. See [`Multiscale`][yaozarrs.v04.Multiscale].\n    \"\"\"\n\n    multiscales: Annotated[UniqueList[Multiscale], MinLen(1)] = Field(\n        description=\"One or more multiscale image pyramids in this group\"\n    )\n    omero: Omero | None = Field(\n        default=None,\n        description=\"Optional OMERO rendering metadata for visualization\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.Multiscale","title":"<code>Multiscale</code>","text":"<p>Multi-resolution image pyramid (&lt;=5D) with coordinate metadata.</p> <p>Defines an image at one or more resolution levels, along with the coordinate system that relates array indices to physical space. This is the core metadata for any OME-NGFF image.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional identifier for this multiscale image</p> <code>None</code> <code>axes</code> <code>list[SpaceAxis | TimeAxis | ChannelAxis | CustomAxis]</code> <p>Ordered list of dimension axes defining the coordinate system</p> required <code>datasets</code> <code>list[Dataset]</code> <p>Resolution pyramid levels, from highest to lowest resolution</p> required <code>coordinateTransformations</code> <code>list[ScaleTransformation | TranslationTransformation] | None</code> <p>Coordinate transformations that are applied to all resolution levels in the same manner.</p> <code>None</code> <code>version</code> <code>Literal['0.4']</code> <code>'0.4'</code> <code>type</code> <code>str | None</code> <p>Type of downscaling method used to generate the multiscale image pyramid.</p> <code>None</code> <code>metadata</code> <code>dict | None</code> <p>Unstructured key-value pair with additional information about the downscaling method.</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>class Multiscale(_BaseModel):\n    \"\"\"Multi-resolution image pyramid (&lt;=5D) with coordinate metadata.\n\n    Defines an image at one or more resolution levels, along with the\n    coordinate system that relates array indices to physical space. This is\n    the core metadata for any OME-NGFF image.\n    \"\"\"\n\n    name: str | None = Field(\n        default=None,\n        description=\"Optional identifier for this multiscale image\",\n    )\n    axes: AxesList = Field(\n        description=\"Ordered list of dimension axes defining the coordinate system\"\n    )\n    datasets: DatasetsList = Field(\n        description=(\"Resolution pyramid levels, from highest to lowest resolution\")\n    )\n    coordinateTransformations: CoordinateTransformsList | None = Field(\n        default=None,\n        description=(\n            \"Coordinate transformations that are applied to all resolution levels \"\n            \"in the same manner.\"\n        ),\n    )\n    version: Literal[\"0.4\"] = \"0.4\"\n\n    # NOTE: \"type\", and \"metadata\" mentioned in the spec, but NOT in image.schema\n    type: str | None = Field(  # spec says SHOULD be present, missing in schema\n        default=None,\n        description=(\n            \"Type of downscaling method used to generate the multiscale image pyramid.\"\n        ),\n    )\n    metadata: dict | None = Field(  # spec says SHOULD be present, missing in schema\n        default=None,\n        description=\"Unstructured key-value pair with additional \"\n        \"information about the downscaling method.\",\n    )\n\n    @model_serializer(mode=\"wrap\")\n    def serialize_model(\n        self, handler: SerializerFunctionWrapHandler\n    ) -&gt; dict[str, object]:\n        \"\"\"Include version in serialization if it is not the default value.\"\"\"\n        serialized = handler(self)\n        serialized[\"version\"] = self.version  # always include version in serialization\n        return serialized\n\n    @model_validator(mode=\"after\")\n    def _check_ndim(self) -&gt; Self:\n        for _id, ds in enumerate(self.datasets):\n            for _it, transform in enumerate(ds.coordinateTransformations):\n                if transform.ndim != self.ndim:\n                    raise ValueError(\n                        f\"at datasets.[{_id}].coordinateTransformations[{_it}]:\\n\"\n                        f\"  The length of the transformation ({transform.ndim}) does \"\n                        f\"not match the number of axes ({self.ndim}).\"\n                    )\n        if self.coordinateTransformations:\n            for _it, transform in enumerate(self.coordinateTransformations):\n                if transform.ndim != self.ndim:\n                    raise ValueError(\n                        f\"at coordinateTransformations[{_it}]:\\n\"\n                        f\"  The length of the transformation ({transform.ndim}) \"\n                        f\"does not match the number of axes ({self.ndim}).\"\n                    )\n        return self\n\n    @property\n    def ndim(self) -&gt; int:\n        return len(self.axes)\n\n    @classmethod\n    def from_dims(\n        cls,\n        dims: Sequence[DimSpec],\n        name: str | None = None,\n        n_levels: int = 1,\n    ) -&gt; Self:\n        \"\"\"Convenience constructor: Create Multiscale from a sequence of DimSpec.\n\n        Parameters\n        ----------\n        dims : Sequence[DimSpec]\n            A sequence of dimension specifications defining the image dimensions.\n            Must follow OME-Zarr axis ordering: `[time,] [channel,] space...`\n        name : str | None, optional\n            Name for the multiscale. Default is None.\n        n_levels : int, optional\n            Number of resolution levels in the pyramid. Default is 1.\n\n        Returns\n        -------\n        Multiscale\n            A fully configured Multiscale model.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from yaozarrs import DimSpec, v04\n        &gt;&gt;&gt; dims = [\n        ...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n        ...     DimSpec(\n        ...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n        ...     ),\n        ...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n        ...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n        ... ]\n        &gt;&gt;&gt; v04.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n        \"\"\"\n        from yaozarrs._dim_spec import _axes_datasets\n\n        return cls(name=name, **_axes_datasets(dims, n_levels))  # type: ignore\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.Multiscale.from_dims","title":"<code>from_dims(dims, name=None, n_levels=1)</code>  <code>classmethod</code>","text":"<p>Convenience constructor: Create Multiscale from a sequence of DimSpec.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>Sequence[DimSpec]</code> <p>A sequence of dimension specifications defining the image dimensions. Must follow OME-Zarr axis ordering: <code>[time,] [channel,] space...</code></p> required <code>name</code> <code>str | None</code> <p>Name for the multiscale. Default is None.</p> <code>None</code> <code>n_levels</code> <code>int</code> <p>Number of resolution levels in the pyramid. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Multiscale</code> <p>A fully configured Multiscale model.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from yaozarrs import DimSpec, v04\n&gt;&gt;&gt; dims = [\n...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n...     DimSpec(\n...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n...     ),\n...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n... ]\n&gt;&gt;&gt; v04.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n</code></pre> Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>@classmethod\ndef from_dims(\n    cls,\n    dims: Sequence[DimSpec],\n    name: str | None = None,\n    n_levels: int = 1,\n) -&gt; Self:\n    \"\"\"Convenience constructor: Create Multiscale from a sequence of DimSpec.\n\n    Parameters\n    ----------\n    dims : Sequence[DimSpec]\n        A sequence of dimension specifications defining the image dimensions.\n        Must follow OME-Zarr axis ordering: `[time,] [channel,] space...`\n    name : str | None, optional\n        Name for the multiscale. Default is None.\n    n_levels : int, optional\n        Number of resolution levels in the pyramid. Default is 1.\n\n    Returns\n    -------\n    Multiscale\n        A fully configured Multiscale model.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from yaozarrs import DimSpec, v04\n    &gt;&gt;&gt; dims = [\n    ...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n    ...     DimSpec(\n    ...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n    ...     ),\n    ...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n    ...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n    ... ]\n    &gt;&gt;&gt; v04.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n    \"\"\"\n    from yaozarrs._dim_spec import _axes_datasets\n\n    return cls(name=name, **_axes_datasets(dims, n_levels))  # type: ignore\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.Dataset","title":"<code>Dataset</code>","text":"<p>A single resolution level in a multiscale image pyramid.</p> <p>Each dataset points to a Zarr array and defines how its indices map to physical coordinates. Together, multiple datasets form a resolution pyramid where each level represents the same physical region at different sampling rates.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Zarr array for this resolution level, relative to the parent multiscale group</p> required <code>coordinateTransformations</code> <code>list[ScaleTransformation | TranslationTransformation]</code> <p>Transformations mapping array indices to physical coordinates. Must include exactly one scale transformation, and optionally one translation.</p> required Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>class Dataset(_BaseModel):\n    \"\"\"A single resolution level in a multiscale image pyramid.\n\n    Each dataset points to a Zarr array and defines how its indices map to\n    physical coordinates. Together, multiple datasets form a resolution pyramid\n    where each level represents the same physical region at different sampling rates.\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Path to the Zarr array for this resolution level, \"\n            \"relative to the parent multiscale group\"\n        )\n    )\n    coordinateTransformations: CoordinateTransformsList = Field(\n        description=(\n            \"Transformations mapping array indices to physical coordinates. \"\n            \"Must include exactly one scale transformation, \"\n            \"and optionally one translation.\"\n        )\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.ScaleTransformation","title":"<code>ScaleTransformation</code>","text":"<p>Maps array indices to physical coordinates via scaling.</p> <p>Defines the pixel/voxel size in physical units for each dimension. Every dataset must have exactly one scale transformation.</p> <p>Note</p> <p>Scale values represent physical size per pixel. For example, a scale of <code>[0.5, 0.5]</code> means each pixel is 0.5 units wide in physical space.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['scale']</code> <code>'scale'</code> <code>scale</code> <code>list[float]</code> <p>Scaling factor for each dimension in physical units per pixel</p> required Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>class ScaleTransformation(_BaseModel):\n    \"\"\"Maps array indices to physical coordinates via scaling.\n\n    Defines the pixel/voxel size in physical units for each dimension.\n    Every dataset must have exactly one scale transformation.\n\n    !!! note\n        Scale values represent physical size per pixel. For example, a scale of\n        `[0.5, 0.5]` means each pixel is 0.5 units wide in physical space.\n    \"\"\"\n\n    type: Literal[\"scale\"] = \"scale\"\n    scale: Annotated[list[float], MinLen(2)] = Field(\n        description=\"Scaling factor for each dimension in physical units per pixel\"\n    )\n\n    @property\n    def ndim(self) -&gt; int:\n        \"\"\"Number of dimensions in this transformation.\"\"\"\n        return len(self.scale)\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.ScaleTransformation.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>Number of dimensions in this transformation.</p>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.TranslationTransformation","title":"<code>TranslationTransformation</code>","text":"<p>Translates the coordinate system origin in physical space.</p> <p>Specifies the physical coordinates of the origin (index [0, 0, ...]). At most one translation may be present per dataset, and it must appear after the scale transformation.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['translation']</code> <code>'translation'</code> <code>translation</code> <code>list[float]</code> <p>Translation offset for each dimension in physical units</p> required Source code in <code>src/yaozarrs/v04/_image.py</code> <pre><code>class TranslationTransformation(_BaseModel):\n    \"\"\"Translates the coordinate system origin in physical space.\n\n    Specifies the physical coordinates of the origin (index [0, 0, ...]).\n    At most one translation may be present per dataset, and it must appear\n    after the scale transformation.\n    \"\"\"\n\n    type: Literal[\"translation\"] = \"translation\"\n    translation: Annotated[list[float], MinLen(2)] = Field(\n        description=\"Translation offset for each dimension in physical units\"\n    )\n\n    @property\n    def ndim(self) -&gt; int:\n        \"\"\"Number of dimensions in this transformation.\"\"\"\n        return len(self.translation)\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._image.TranslationTransformation.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>Number of dimensions in this transformation.</p>"},{"location":"API_Reference/yaozarrs.v04/#labels","title":"Labels","text":""},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.LabelImage","title":"<code>LabelImage</code>","text":"<p>A complete label image with multiscale pyramids and label metadata.</p> <p>Combines the standard image structure (multiscale pyramids, axes, etc.) with label-specific metadata (colors, properties, source reference). Label images must use integer data types.</p> <p>Relationship to Image</p> <p>This is an <code>Image</code> with additional <code>image-label</code> metadata. The multiscale pyramids follow the same structure as regular images but contain integer segmentation masks instead of intensity data.</p> <p>Parameters:</p> Name Type Description Default <code>image_label</code> <code>ImageLabel</code> <p>Label-specific metadata (colors, properties, source link)</p> required Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class LabelImage(Image):\n    \"\"\"A complete label image with multiscale pyramids and label metadata.\n\n    Combines the standard image structure (multiscale pyramids, axes, etc.)\n    with label-specific metadata (colors, properties, source reference).\n    Label images must use integer data types.\n\n    !!! note \"Relationship to Image\"\n        This is an [`Image`][yaozarrs.v04.Image] with additional `image-label`\n        metadata. The multiscale pyramids follow the same structure as regular\n        images but contain integer segmentation masks instead of intensity data.\n    \"\"\"\n\n    image_label: ImageLabel = Field(\n        alias=\"image-label\",\n        description=\"Label-specific metadata (colors, properties, source link)\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.ImageLabel","title":"<code>ImageLabel</code>","text":"<p>Metadata for a segmentation/annotation label image.</p> <p>Enhances a multiscale label image with display colors, semantic properties, and links back to the source intensity image. Label images are integer-valued arrays where each unique value represents a distinct object or region.</p> <p>Parameters:</p> Name Type Description Default <code>colors</code> <code>list[LabelColor] | None</code> <p>Color mappings for label values, used for visualization</p> <code>None</code> <code>properties</code> <code>list[LabelProperty] | None</code> <p>Arbitrary metadata properties for individual label values</p> <code>None</code> <code>source</code> <code>LabelSource | None</code> <p>Reference to the source intensity image that was segmented</p> <code>None</code> <code>version</code> <code>Literal['0.4']</code> <code>'0.4'</code> Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class ImageLabel(_BaseModel):\n    \"\"\"Metadata for a segmentation/annotation label image.\n\n    Enhances a multiscale label image with display colors, semantic properties,\n    and links back to the source intensity image. Label images are integer-valued\n    arrays where each unique value represents a distinct object or region.\n    \"\"\"\n\n    colors: Annotated[UniqueList[LabelColor], MinLen(1)] | None = Field(\n        default=None,\n        description=\"Color mappings for label values, used for visualization\",\n    )\n    properties: Annotated[UniqueList[LabelProperty], MinLen(1)] | None = Field(\n        default=None,\n        description=\"Arbitrary metadata properties for individual label values\",\n    )\n    source: LabelSource | None = Field(\n        default=None,\n        description=\"Reference to the source intensity image that was segmented\",\n    )\n    version: Literal[\"0.4\"] = \"0.4\"\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.LabelColor","title":"<code>LabelColor</code>","text":"<p>Display color mapping for a label value.</p> <p>Associates a specific label value with an RGBA color for visualization purposes.</p> <p>Parameters:</p> Name Type Description Default <code>label_value</code> <code>float</code> <p>Label value from the segmentation image</p> required <code>rgba</code> <code>list[int] | None</code> <p>RGBA color as [red, green, blue, alpha], each 0-255</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class LabelColor(_BaseModel):\n    \"\"\"Display color mapping for a label value.\n\n    Associates a specific label value with an RGBA color for\n    visualization purposes.\n    \"\"\"\n\n    label_value: float = Field(\n        description=\"Label value from the segmentation image\",\n        alias=\"label-value\",\n    )\n    rgba: Annotated[list[Int8bit], Len(min_length=4, max_length=4)] | None = Field(\n        default=None,\n        description=\"RGBA color as [red, green, blue, alpha], each 0-255\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.LabelProperty","title":"<code>LabelProperty</code>","text":"<p>Custom metadata for a label value.</p> <p>Associates arbitrary key-value properties with a specific label integer. Different labels can have different sets of properties.</p> <p>Example</p> <pre><code>LabelProperty(label_value=1, cell_type=\"neuron\", area=1250.5)\nLabelProperty(label_value=2, cell_type=\"glia\", perimeter=180.3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>label_value</code> <code>int</code> <p>Integer label value from the segmentation image</p> required Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class LabelProperty(_BaseModel):\n    \"\"\"Custom metadata for a label value.\n\n    Associates arbitrary key-value properties with a specific label integer.\n    Different labels can have different sets of properties.\n\n    !!! example\n        ```python\n        LabelProperty(label_value=1, cell_type=\"neuron\", area=1250.5)\n        LabelProperty(label_value=2, cell_type=\"glia\", perimeter=180.3)\n        ```\n    \"\"\"\n\n    label_value: int = Field(\n        description=\"Integer label value from the segmentation image\",\n        alias=\"label-value\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.LabelSource","title":"<code>LabelSource</code>","text":"<p>Reference to the source image that was segmented.</p> <p>Points back to the original intensity image from which this label image was derived.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str | None</code> <p>Relative path to the source image group (default: '../../', pointing to the parent of the labels/ directory)</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class LabelSource(_BaseModel):\n    \"\"\"Reference to the source image that was segmented.\n\n    Points back to the original intensity image from which this label\n    image was derived.\n    \"\"\"\n\n    image: str | None = Field(\n        default=None,\n        description=(\n            \"Relative path to the source image group (default: '../../', \"\n            \"pointing to the parent of the labels/ directory)\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._labels.LabelsGroup","title":"<code>LabelsGroup</code>","text":"<p>Top-level labels collection metadata.</p> <p>This model corresponds to the <code>.zattrs</code> file (or zarr.json attributes) in a <code>labels/</code> directory, which acts as a container for multiple segmentation/annotation images.</p> <p>Typical Structure</p> <pre><code>my_image/\n\u251c\u2500\u2500 .zattrs            # Image metadata\n\u251c\u2500\u2500 0/                 # Image arrays\n\u2514\u2500\u2500 labels/\n    \u251c\u2500\u2500 .zattrs        # Contains this metadata {\"labels\": [...]}\n    \u251c\u2500\u2500 cells/         # One label image\n    \u2514\u2500\u2500 nuclei/        # Another label image\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>list[str]</code> <p>Paths to individual label image groups within this collection</p> required Source code in <code>src/yaozarrs/v04/_labels.py</code> <pre><code>class LabelsGroup(_BaseModel):\n    \"\"\"Top-level labels collection metadata.\n\n    This model corresponds to the `.zattrs` file (or zarr.json attributes)\n    in a `labels/` directory, which acts as a container for multiple\n    segmentation/annotation images.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_image/\n        \u251c\u2500\u2500 .zattrs            # Image metadata\n        \u251c\u2500\u2500 0/                 # Image arrays\n        \u2514\u2500\u2500 labels/\n            \u251c\u2500\u2500 .zattrs        # Contains this metadata {\"labels\": [...]}\n            \u251c\u2500\u2500 cells/         # One label image\n            \u2514\u2500\u2500 nuclei/        # Another label image\n        ```\n    \"\"\"\n\n    labels: Annotated[list[str], MinLen(1)] = Field(\n        description=\"Paths to individual label image groups within this collection\"\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#plates","title":"Plates","text":""},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.Plate","title":"<code>Plate</code>","text":"<p>Top-level plate metadata for high-content screening.</p> <p>This model corresponds to the <code>.zattrs</code> file (or zarr.json attributes) in a plate group, organizing a microplate's wells in a grid layout. Each well contains one or more fields-of-view, which in turn contain multiscale images.</p> <p>Typical Structure</p> <pre><code>my_plate.ome.zarr/\n\u251c\u2500\u2500 A/                      # Row A\n\u2502   \u251c\u2500\u2500 1/                  # Well A1\n\u2502   \u2502   \u251c\u2500\u2500 0/              # FOV 0 in A1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 0/          # Multiscale level 0\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 .zattrs     # contains {\"multiscales\": [...]}\n\u2502   \u2502   \u251c\u2500\u2500 1/              # FOV 1 in A1\n\u2502   \u2502   \u2514\u2500\u2500 .zattrs         # contains {\"well\": {...}}\n\u2502   \u2514\u2500\u2500 2/                  # Well A2\n\u251c\u2500\u2500 B/                      # Row B\n\u2514\u2500\u2500 .zattrs                 # contains {\"plate\": {...}}\n</code></pre> <p>Note</p> <p>See also:</p> <ul> <li><code>Well</code></li> <li><code>FieldOfView</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>plate</code> <code>PlateDef</code> <p>Plate layout and well organization</p> required Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class Plate(ZarrGroupModel):\n    \"\"\"Top-level plate metadata for high-content screening.\n\n    This model corresponds to the `.zattrs` file (or zarr.json attributes)\n    in a plate group, organizing a microplate's wells in a grid layout.\n    Each well contains one or more fields-of-view, which in turn contain\n    multiscale images.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_plate.ome.zarr/\n        \u251c\u2500\u2500 A/                      # Row A\n        \u2502   \u251c\u2500\u2500 1/                  # Well A1\n        \u2502   \u2502   \u251c\u2500\u2500 0/              # FOV 0 in A1\n        \u2502   \u2502   \u2502   \u251c\u2500\u2500 0/          # Multiscale level 0\n        \u2502   \u2502   \u2502   \u2514\u2500\u2500 .zattrs     # contains {\"multiscales\": [...]}\n        \u2502   \u2502   \u251c\u2500\u2500 1/              # FOV 1 in A1\n        \u2502   \u2502   \u2514\u2500\u2500 .zattrs         # contains {\"well\": {...}}\n        \u2502   \u2514\u2500\u2500 2/                  # Well A2\n        \u251c\u2500\u2500 B/                      # Row B\n        \u2514\u2500\u2500 .zattrs                 # contains {\"plate\": {...}}\n        ```\n\n    !!! note\n        See also:\n\n        - [`Well`][yaozarrs.v04.Well]\n        - [`FieldOfView`][yaozarrs.v04.FieldOfView]\n    \"\"\"\n\n    plate: PlateDef = Field(\n        description=\"Plate layout and well organization\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.PlateDef","title":"<code>PlateDef</code>","text":"<p>Plate layout and well organization.</p> <p>Defines the grid structure of a microplate and maps wells to their data. This is the core content of the <code>plate</code> metadata field.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list[Column]</code> <p>Column definitions for the plate grid</p> required <code>rows</code> <code>list[Row]</code> <p>Row definitions for the plate grid</p> required <code>wells</code> <code>list[PlateWell]</code> <p>List of all wells present in this plate with their grid positions</p> required <code>acquisitions</code> <code>list[Acquisition] | None</code> <p>Imaging acquisition runs performed on this plate</p> <code>None</code> <code>field_count</code> <code>int | None</code> <p>Maximum number of fields-of-view per well across the entire plate</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Human-readable name for this plate</p> <code>None</code> <code>version</code> <code>Literal['0.4']</code> <code>'0.4'</code> Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class PlateDef(_BaseModel):\n    \"\"\"Plate layout and well organization.\n\n    Defines the grid structure of a microplate and maps wells to their data.\n    This is the core content of the `plate` metadata field.\n    \"\"\"\n\n    columns: Annotated[UniqueList[Column], MinLen(1)] = Field(\n        description=\"Column definitions for the plate grid\"\n    )\n    rows: Annotated[UniqueList[Row], MinLen(1)] = Field(\n        description=\"Row definitions for the plate grid\"\n    )\n    wells: Annotated[UniqueList[PlateWell], MinLen(1)] = Field(\n        description=\"List of all wells present in this plate with their grid positions\"\n    )\n\n    acquisitions: list[Acquisition] | None = Field(\n        default=None,\n        description=\"Imaging acquisition runs performed on this plate\",\n    )\n    field_count: PositiveInt | None = Field(\n        default=None,\n        description=\"Maximum number of fields-of-view per well across the entire plate\",\n    )\n    name: str | None = Field(\n        default=None,\n        description=\"Human-readable name for this plate\",\n    )\n    version: Literal[\"0.4\"] = \"0.4\"\n\n    @model_validator(mode=\"after\")\n    def _validate_well_indices(self) -&gt; Self:\n        for well in self.wells:\n            if well.rowIndex &gt;= len(self.rows):\n                raise ValueError(\n                    f\"Well {well.path} has rowIndex {well.rowIndex} \"\n                    f\"but only {len(self.rows)} rows exist\"\n                )\n            if well.columnIndex &gt;= len(self.columns):\n                raise ValueError(\n                    f\"Well {well.path} has columnIndex {well.columnIndex} \"\n                    f\"but only {len(self.columns)} columns exist\"\n                )\n        return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.Column","title":"<code>Column</code>","text":"<p>A column in the plate grid.</p> <p>Columns are typically numbered (1, 2, 3, ...) but can use any alphanumeric identifier.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Column identifier (typically numeric, e.g., '1', '2', '3')</p> required Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class Column(_BaseModel):\n    \"\"\"A column in the plate grid.\n\n    Columns are typically numbered (1, 2, 3, ...) but can use any\n    alphanumeric identifier.\n    \"\"\"\n\n    name: str = Field(\n        description=\"Column identifier (typically numeric, e.g., '1', '2', '3')\",\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.Row","title":"<code>Row</code>","text":"<p>A row in the plate grid.</p> <p>Rows are typically lettered (A, B, C, ...) but can use any alphanumeric identifier.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Row identifier (typically alphabetic, e.g., 'A', 'B', 'C')</p> required Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class Row(_BaseModel):\n    \"\"\"A row in the plate grid.\n\n    Rows are typically lettered (A, B, C, ...) but can use any alphanumeric identifier.\n    \"\"\"\n\n    name: str = Field(\n        description=\"Row identifier (typically alphabetic, e.g., 'A', 'B', 'C')\",\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.PlateWell","title":"<code>PlateWell</code>","text":"<p>A well location reference within a plate.</p> <p>Maps a well's row/column position to its data location. This is a lightweight reference used in plate metadata, not the full well group (see <code>Well</code> for the complete well metadata).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to the well's group (format: 'row/column', e.g., 'A/1')</p> required <code>rowIndex</code> <code>int</code> <p>Zero-based index into the plate's rows list</p> required <code>columnIndex</code> <code>int</code> <p>Zero-based index into the plate's columns list</p> required Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class PlateWell(_BaseModel):\n    \"\"\"A well location reference within a plate.\n\n    Maps a well's row/column position to its data location. This is a\n    lightweight reference used in plate metadata, not the full well group\n    (see [`Well`][yaozarrs.v04.Well] for the complete well metadata).\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Relative path to the well's group (format: 'row/column', e.g., 'A/1')\"\n        ),\n        pattern=r\"^[A-Za-z0-9]+/[A-Za-z0-9]+$\",\n    )\n    rowIndex: NonNegativeInt = Field(\n        description=\"Zero-based index into the plate's rows list\",\n    )\n    columnIndex: NonNegativeInt = Field(\n        description=\"Zero-based index into the plate's columns list\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.Acquisition","title":"<code>Acquisition</code>","text":"<p>An imaging acquisition run within a plate.</p> <p>In high-content screening, multiple acquisition runs may be performed on the same plate (e.g., at different timepoints or with different settings). This class groups related images from a single acquisition session.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Unique identifier within the plate for this acquisition</p> required <code>maximumfieldcount</code> <code>int | None</code> <p>Maximum number of fields-of-view across all wells in this acquisition</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Human-readable name for this acquisition</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Detailed description of the acquisition parameters or purpose</p> <code>None</code> <code>starttime</code> <code>int | None</code> <p>Acquisition start time as Unix epoch timestamp (seconds since 1970-01-01)</p> <code>None</code> <code>endtime</code> <code>int | None</code> <p>Acquisition end time as Unix epoch timestamp (seconds since 1970-01-01)</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class Acquisition(_BaseModel):\n    \"\"\"An imaging acquisition run within a plate.\n\n    In high-content screening, multiple acquisition runs may be performed on the\n    same plate (e.g., at different timepoints or with different settings).\n    This class groups related images from a single acquisition session.\n    \"\"\"\n\n    id: NonNegativeInt = Field(\n        description=\"Unique identifier within the plate for this acquisition\",\n    )\n    maximumfieldcount: PositiveInt | None = Field(\n        default=None,\n        description=(\n            \"Maximum number of fields-of-view across all wells in this acquisition\"\n        ),\n    )\n    name: str | None = Field(\n        default=None,\n        description=\"Human-readable name for this acquisition\",\n    )\n    description: str | None = Field(\n        default=None,\n        description=\"Detailed description of the acquisition parameters or purpose\",\n    )\n    starttime: NonNegativeInt | None = Field(\n        default=None,\n        description=(\n            \"Acquisition start time as Unix epoch timestamp (seconds since 1970-01-01)\"\n        ),\n    )\n    endtime: NonNegativeInt | None = Field(\n        default=None,\n        description=(\n            \"Acquisition end time as Unix epoch timestamp (seconds since 1970-01-01)\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.Well","title":"<code>Well</code>","text":"<p>Top-level well metadata within a plate.</p> <p>This model corresponds to the <code>.zattrs</code> file (or zarr.json attributes) in a well group. It lists all fields-of-view (imaging positions) captured within this well.</p> <p>Typical Structure</p> <pre><code>A/1/                   # Well at row A, column 1\n\u251c\u2500\u2500 .zattrs            # Contains this metadata\n\u251c\u2500\u2500 0/                 # First field-of-view\n\u2502   \u251c\u2500\u2500 .zattrs        # Image metadata\n\u2502   \u251c\u2500\u2500 0/             # Highest resolution\n\u2502   \u2514\u2500\u2500 1/             # Next resolution\n\u2514\u2500\u2500 1/                 # Second field-of-view\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>well</code> <code>WellDef</code> <p>Field-of-view organization for this well</p> required Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class Well(ZarrGroupModel):\n    \"\"\"Top-level well metadata within a plate.\n\n    This model corresponds to the `.zattrs` file (or zarr.json attributes)\n    in a well group. It lists all fields-of-view (imaging positions)\n    captured within this well.\n\n    !!! example \"Typical Structure\"\n        ```\n        A/1/                   # Well at row A, column 1\n        \u251c\u2500\u2500 .zattrs            # Contains this metadata\n        \u251c\u2500\u2500 0/                 # First field-of-view\n        \u2502   \u251c\u2500\u2500 .zattrs        # Image metadata\n        \u2502   \u251c\u2500\u2500 0/             # Highest resolution\n        \u2502   \u2514\u2500\u2500 1/             # Next resolution\n        \u2514\u2500\u2500 1/                 # Second field-of-view\n        ```\n    \"\"\"\n\n    well: WellDef = Field(\n        description=\"Field-of-view organization for this well\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.WellDef","title":"<code>WellDef</code>","text":"<p>Organization of fields-of-view within a well.</p> <p>This is the core content of the <code>well</code> metadata field, listing all imaging positions captured for this well.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list[FieldOfView]</code> <p>List of all fields-of-view imaged in this well</p> required <code>version</code> <code>Literal['0.4']</code> <code>'0.4'</code> Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class WellDef(_BaseModel):\n    \"\"\"Organization of fields-of-view within a well.\n\n    This is the core content of the `well` metadata field, listing all\n    imaging positions captured for this well.\n    \"\"\"\n\n    images: Annotated[UniqueList[FieldOfView], MinLen(1)] = Field(\n        description=\"List of all fields-of-view imaged in this well\",\n    )\n    version: Literal[\"0.4\"] = \"0.4\"\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._plate.FieldOfView","title":"<code>FieldOfView</code>","text":"<p>A single field-of-view (imaging position) within a well.</p> <p>Wells typically contain multiple fields-of-view when the well area is larger than a single camera frame. Each field-of-view is a complete multiscale image.</p> <p>This class appears within the <code>images</code> list of a <code>WellDef</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to this field's image group (typically a number like '0', '1', etc.)</p> required <code>acquisition</code> <code>int | None</code> <p>Acquisition ID linking this field to a specific acquisition run. Required when the parent plate has multiple acquisitions.</p> <code>None</code> Source code in <code>src/yaozarrs/v04/_plate.py</code> <pre><code>class FieldOfView(_BaseModel):\n    \"\"\"A single field-of-view (imaging position) within a well.\n\n    Wells typically contain multiple fields-of-view when the well area is larger\n    than a single camera frame. Each field-of-view is a complete multiscale image.\n\n    This class appears within the `images` list of a [`WellDef`][yaozarrs.v04.WellDef].\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Relative path to this field's image group \"\n            \"(typically a number like '0', '1', etc.)\"\n        ),\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n    acquisition: int | None = Field(\n        default=None,\n        description=(\n            \"Acquisition ID linking this field to a specific acquisition run. \"\n            \"Required when the parent plate has multiple acquisitions.\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#collections","title":"Collections","text":""},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._bf2raw.Bf2Raw","title":"<code>Bf2Raw</code>","text":"<p>Parameters:</p> Name Type Description Default <code>bioformats2raw_layout</code> <code>Literal[3]</code> <p>The top-level identifier metadata added by bioformats2raw</p> required Source code in <code>src/yaozarrs/v04/_bf2raw.py</code> <pre><code>class Bf2Raw(ZarrGroupModel):\n    bioformats2raw_layout: Literal[3] = Field(\n        alias=\"bioformats2raw.layout\",\n        description=\"The top-level identifier metadata added by bioformats2raw\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v04/#yaozarrs.v04._bf2raw.Series","title":"<code>Series</code>","text":"<p>Model for the ome group that contains OME-XML metadata.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>list[str]</code> <p>An array of the same length and the same order as the images defined in the OME-XML</p> required Source code in <code>src/yaozarrs/v04/_bf2raw.py</code> <pre><code>class Series(ZarrGroupModel):\n    \"\"\"Model for the ome group that contains OME-XML metadata.\"\"\"\n\n    series: Annotated[list[str], MinLen(1)] = Field(\n        description=\"An array of the same length and the same order as \"\n        \"the images defined in the OME-XML\"\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/","title":"<code>yaozarrs.v05</code>","text":"<p>Specification: https://ngff.openmicroscopy.org/0.5/</p> <p>Schema: https://github.com/ome/ngff/tree/8cbba216e37407bd2d4bd5c7128ab13bd0a6404e</p>"},{"location":"API_Reference/yaozarrs.v05/#images","title":"Images","text":""},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Image","title":"<code>Image</code>","text":"<p>Top-level OME-NGFF image metadata.</p> <p>This model corresponds to the <code>zarr.json</code> file in an image group. It contains one or more multiscale pyramids plus optional OMERO rendering hints.</p> <p>Typical Structure</p> <pre><code>my_image/\n\u251c\u2500\u2500 zarr.json          # contains [\"ome\"][\"multiscales\"]\n\u251c\u2500\u2500 0/                 # Highest resolution array\n\u251c\u2500\u2500 1/                 # Next resolution level\n\u2514\u2500\u2500 labels/            # Optional segmentation masks\n    \u251c\u2500\u2500 zarr.json      # contains [\"ome\"][\"labels\"]\n    \u2514\u2500\u2500 0              # Multiscale, labeled image.\n</code></pre> <p>Note</p> <p>For the optional <code>labels</code> group, see LabelsGroup.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>multiscales</code> <code>list[Multiscale]</code> <p>One or more multiscale image pyramids in this group</p> required <code>omero</code> <code>Omero | None</code> <p>Optional OMERO rendering metadata for visualization</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>class Image(_BaseModel):\n    \"\"\"Top-level OME-NGFF image metadata.\n\n    This model corresponds to the `zarr.json` file in an image group.\n    It contains one or more multiscale pyramids plus optional OMERO rendering hints.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_image/\n        \u251c\u2500\u2500 zarr.json          # contains [\"ome\"][\"multiscales\"]\n        \u251c\u2500\u2500 0/                 # Highest resolution array\n        \u251c\u2500\u2500 1/                 # Next resolution level\n        \u2514\u2500\u2500 labels/            # Optional segmentation masks\n            \u251c\u2500\u2500 zarr.json      # contains [\"ome\"][\"labels\"]\n            \u2514\u2500\u2500 0              # Multiscale, labeled image.\n        ```\n\n    !!! note\n        For the optional `labels` group, see [LabelsGroup][yaozarrs.v05.LabelsGroup].\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    multiscales: Annotated[UniqueList[Multiscale], MinLen(1)] = Field(\n        description=\"One or more multiscale image pyramids in this group\"\n    )\n    omero: Omero | None = Field(\n        default=None,\n        description=\"Optional OMERO rendering metadata for visualization\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Multiscale","title":"<code>Multiscale</code>","text":"<p>Multi-resolution image pyramid (&lt;=5D) with coordinate metadata.</p> <p>Defines a image at one ore more resolution levels, along with the coordinate system that relates array indices to physical space. This is the core metadata for any OME-NGFF image.</p> <p>Resolution Ordering</p> <p>Datasets must be ordered from highest to lowest resolution (i.e., finest to coarsest sampling).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional identifier for this multiscale image</p> <code>None</code> <code>axes</code> <code>list[SpaceAxis | TimeAxis | ChannelAxis | CustomAxis]</code> <p>Ordered list of dimension axes defining the coordinate system</p> required <code>datasets</code> <code>list[Dataset]</code> <p>Resolution pyramid levels, ordered from highest to lowest resolution</p> required <code>coordinateTransformations</code> <code>list[ScaleTransformation | TranslationTransformation] | None</code> <p>Coordinate transformations that are applied to all resolution levels in the same manner.</p> <code>None</code> <code>type</code> <code>str | None</code> <p>Type of downscaling method used to generate the multiscale image pyramid.</p> <code>None</code> <code>metadata</code> <code>dict | None</code> <p>Unstructured key-value pair with additional information about the downscaling method.</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>class Multiscale(_BaseModel):\n    \"\"\"Multi-resolution image pyramid (&lt;=5D) with coordinate metadata.\n\n    Defines a image at one ore more resolution levels, along with the\n    coordinate system that relates array indices to physical space. This is\n    the core metadata for any OME-NGFF image.\n\n    !!! note \"Resolution Ordering\"\n        Datasets must be ordered from highest to lowest resolution\n        (i.e., finest to coarsest sampling).\n    \"\"\"\n\n    name: str | None = Field(\n        default=None,\n        description=\"Optional identifier for this multiscale image\",\n    )\n    axes: AxesList = Field(\n        description=\"Ordered list of dimension axes defining the coordinate system\"\n    )\n    datasets: DatasetsList = Field(\n        description=(\n            \"Resolution pyramid levels, ordered from highest to lowest resolution\"\n        )\n    )\n    coordinateTransformations: CoordinateTransformsList | None = Field(\n        default=None,\n        description=(\n            \"Coordinate transformations that are applied to all resolution levels \"\n            \"in the same manner.\"\n        ),\n    )\n\n    # NOTE: \"type\", and \"metadata\" mentioned in the spec, but NOT in image.schema\n    type: str | None = Field(  # spec says SHOULD be present, missing in schema\n        default=None,\n        description=(\n            \"Type of downscaling method used to generate the multiscale image pyramid.\"\n        ),\n    )\n    metadata: dict | None = Field(  # spec says SHOULD be present, missing in schema\n        default=None,\n        description=\"Unstructured key-value pair with additional \"\n        \"information about the downscaling method.\",\n    )\n\n    @model_validator(mode=\"after\")\n    def _post_validate(self) -&gt; Self:\n        # The number and order of dimensions in each dataset MUST\n        # correspond to number and order of \"axes\".\n        # TODO ... this is ambiguous.  is it the same as the following check?\n\n        # The length of the scale and translation array MUST be the same as the length\n        # of \"axes\".\n        for _id, ds in enumerate(self.datasets):\n            for _it, transform in enumerate(ds.coordinateTransformations):\n                if transform.ndim != self.ndim:\n                    raise ValueError(\n                        f\"at datasets.[{_id}].coordinateTransformations[{_it}]:\\n\"\n                        f\"  The length of the transformation ({transform.ndim}) does \"\n                        f\"not match the number of axes ({self.ndim}).\"\n                    )\n        if self.coordinateTransformations:\n            for _it, transform in enumerate(self.coordinateTransformations):\n                if transform.ndim != self.ndim:\n                    raise ValueError(\n                        f\"at coordinateTransformations[{_it}]:\\n\"\n                        f\"  The length of the transformation ({transform.ndim}) \"\n                        f\"does not match the number of axes ({self.ndim}).\"\n                    )\n\n        # The \"paths\" of the datasets MUST be be ordered from the highest resolution to\n        # the lowest resolution (i.e. largest to smallest\n        spatial_indices: dict[int, str] = {\n            i: ax.name for i, ax in enumerate(self.axes) if ax.type == \"space\"\n        }\n        spatial_scales = [\n            tuple(ds.scale_transform.scale[idx] for idx in spatial_indices)\n            for ds in self.datasets\n        ]\n        if spatial_scales != sorted(spatial_scales):\n            raise ValueError(\n                \"The datasets are not ordered from highest to lowest resolution. \"\n                f\"Found spatial scales: {spatial_scales}\"\n            )\n\n        return self\n\n    @property\n    def ndim(self) -&gt; int:\n        return len(self.axes)\n\n    @classmethod\n    def from_dims(\n        cls,\n        dims: Sequence[DimSpec],\n        name: str | None = None,\n        n_levels: int = 1,\n    ) -&gt; Self:\n        \"\"\"Convenience constructor: Create Multiscale from a sequence of DimSpec.\n\n        Parameters\n        ----------\n        dims : Sequence[DimSpec]\n            A sequence of dimension specifications defining the image dimensions.\n            Must follow OME-Zarr axis ordering: `[time,] [channel,] space...`\n        name : str | None, optional\n            Name for the multiscale. Default is None.\n        n_levels : int, optional\n            Number of resolution levels in the pyramid. Default is 1.\n\n        Returns\n        -------\n        Multiscale\n            A fully configured Multiscale model.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from yaozarrs import DimSpec, v05\n        &gt;&gt;&gt; dims = [\n        ...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n        ...     DimSpec(\n        ...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n        ...     ),\n        ...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n        ...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n        ... ]\n        &gt;&gt;&gt; v05.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n        \"\"\"\n        from yaozarrs._dim_spec import _axes_datasets\n\n        return cls(name=name, **_axes_datasets(dims, n_levels))  # type: ignore\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Multiscale.from_dims","title":"<code>from_dims(dims, name=None, n_levels=1)</code>  <code>classmethod</code>","text":"<p>Convenience constructor: Create Multiscale from a sequence of DimSpec.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>Sequence[DimSpec]</code> <p>A sequence of dimension specifications defining the image dimensions. Must follow OME-Zarr axis ordering: <code>[time,] [channel,] space...</code></p> required <code>name</code> <code>str | None</code> <p>Name for the multiscale. Default is None.</p> <code>None</code> <code>n_levels</code> <code>int</code> <p>Number of resolution levels in the pyramid. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Multiscale</code> <p>A fully configured Multiscale model.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from yaozarrs import DimSpec, v05\n&gt;&gt;&gt; dims = [\n...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n...     DimSpec(\n...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n...     ),\n...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n... ]\n&gt;&gt;&gt; v05.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n</code></pre> Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>@classmethod\ndef from_dims(\n    cls,\n    dims: Sequence[DimSpec],\n    name: str | None = None,\n    n_levels: int = 1,\n) -&gt; Self:\n    \"\"\"Convenience constructor: Create Multiscale from a sequence of DimSpec.\n\n    Parameters\n    ----------\n    dims : Sequence[DimSpec]\n        A sequence of dimension specifications defining the image dimensions.\n        Must follow OME-Zarr axis ordering: `[time,] [channel,] space...`\n    name : str | None, optional\n        Name for the multiscale. Default is None.\n    n_levels : int, optional\n        Number of resolution levels in the pyramid. Default is 1.\n\n    Returns\n    -------\n    Multiscale\n        A fully configured Multiscale model.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from yaozarrs import DimSpec, v05\n    &gt;&gt;&gt; dims = [\n    ...     DimSpec(name=\"t\", size=512, unit=\"second\"),\n    ...     DimSpec(\n    ...         name=\"z\", size=50, scale=2.0, unit=\"micrometer\", scale_factor=1.0\n    ...     ),\n    ...     DimSpec(name=\"y\", size=512, scale=0.5, unit=\"micrometer\"),\n    ...     DimSpec(name=\"x\", size=512, scale=0.5, unit=\"micrometer\"),\n    ... ]\n    &gt;&gt;&gt; v05.Multiscale.from_dims(dims, name=\"my_multiscale\", n_levels=3)\n    \"\"\"\n    from yaozarrs._dim_spec import _axes_datasets\n\n    return cls(name=name, **_axes_datasets(dims, n_levels))  # type: ignore\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Dataset","title":"<code>Dataset</code>","text":"<p>A single resolution level in a multiscale image pyramid.</p> <p>Each dataset points to a Zarr array and defines how its indices map to physical coordinates. Together, multiple datasets form a resolution pyramid where each level represents the same physical region at different sampling rates.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Zarr array for this resolution level, relative to the parent multiscale group</p> required <code>coordinateTransformations</code> <code>list[ScaleTransformation | TranslationTransformation]</code> <p>Transformations mapping array indices to physical coordinates. Must include exactly one scale transformation, and optionally one translation.</p> required Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>class Dataset(_BaseModel):\n    \"\"\"A single resolution level in a multiscale image pyramid.\n\n    Each dataset points to a Zarr array and defines how its indices map to\n    physical coordinates. Together, multiple datasets form a resolution pyramid\n    where each level represents the same physical region at different sampling rates.\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Path to the Zarr array for this resolution level, \"\n            \"relative to the parent multiscale group\"\n        )\n    )\n    coordinateTransformations: CoordinateTransformsList = Field(\n        description=(\n            \"Transformations mapping array indices to physical coordinates. \"\n            \"Must include exactly one scale transformation, \"\n            \"and optionally one translation.\"\n        )\n    )\n\n    @property\n    def scale_transform(self) -&gt; ScaleTransformation:\n        \"\"\"Return the scale transformation from the list.\n\n        (CoordinateTransformsList validator ensures there is exactly one.)\n        \"\"\"\n        return next(\n            t\n            for t in self.coordinateTransformations\n            if isinstance(t, ScaleTransformation)\n        )\n\n    @property\n    def translation_transform(self) -&gt; TranslationTransformation | None:\n        \"\"\"Return the translation transformation from the list, if present.\n\n        (CoordinateTransformsList validator ensures there is at most one.)\n        \"\"\"\n        return next(\n            (\n                t\n                for t in self.coordinateTransformations\n                if isinstance(t, TranslationTransformation)\n            ),\n            None,\n        )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Dataset.scale_transform","title":"<code>scale_transform</code>  <code>property</code>","text":"<p>Return the scale transformation from the list.</p> <p>(CoordinateTransformsList validator ensures there is exactly one.)</p>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.Dataset.translation_transform","title":"<code>translation_transform</code>  <code>property</code>","text":"<p>Return the translation transformation from the list, if present.</p> <p>(CoordinateTransformsList validator ensures there is at most one.)</p>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.ScaleTransformation","title":"<code>ScaleTransformation</code>","text":"<p>Maps array indices to physical coordinates via scaling.</p> <p>Defines the pixel/voxel size in physical units for each dimension. Every dataset must have exactly one scale transformation.</p> <p>Note</p> <p>Scale values represent physical size per pixel. For example, a scale of <code>[0.5, 0.5]</code> means each pixel is 0.5 units wide in physical space.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['scale']</code> <code>'scale'</code> <code>scale</code> <code>list[float]</code> <p>Scaling factor for each dimension in physical units per pixel</p> required Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>class ScaleTransformation(_BaseModel):\n    \"\"\"Maps array indices to physical coordinates via scaling.\n\n    Defines the pixel/voxel size in physical units for each dimension.\n    Every dataset must have exactly one scale transformation.\n\n    !!! note\n        Scale values represent physical size per pixel. For example, a scale of\n        `[0.5, 0.5]` means each pixel is 0.5 units wide in physical space.\n    \"\"\"\n\n    type: Literal[\"scale\"] = \"scale\"\n    scale: Annotated[list[float], MinLen(2)] = Field(\n        description=\"Scaling factor for each dimension in physical units per pixel\"\n    )\n\n    @property\n    def ndim(self) -&gt; int:\n        \"\"\"Number of dimensions in this transformation.\"\"\"\n        return len(self.scale)\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.ScaleTransformation.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>Number of dimensions in this transformation.</p>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.TranslationTransformation","title":"<code>TranslationTransformation</code>","text":"<p>Translates the coordinate system origin in physical space.</p> <p>Specifies the physical coordinates of the origin (index [0, 0, ...]). At most one translation may be present per dataset, and it must appear after the scale transformation.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['translation']</code> <code>'translation'</code> <code>translation</code> <code>list[float]</code> <p>Translation offset for each dimension in physical units</p> required Source code in <code>src/yaozarrs/v05/_image.py</code> <pre><code>class TranslationTransformation(_BaseModel):\n    \"\"\"Translates the coordinate system origin in physical space.\n\n    Specifies the physical coordinates of the origin (index [0, 0, ...]).\n    At most one translation may be present per dataset, and it must appear\n    after the scale transformation.\n    \"\"\"\n\n    type: Literal[\"translation\"] = \"translation\"\n    translation: Annotated[list[float], MinLen(2)] = Field(\n        description=\"Translation offset for each dimension in physical units\"\n    )\n\n    @property\n    def ndim(self) -&gt; int:\n        \"\"\"Number of dimensions in this transformation.\"\"\"\n        return len(self.translation)\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._image.TranslationTransformation.ndim","title":"<code>ndim</code>  <code>property</code>","text":"<p>Number of dimensions in this transformation.</p>"},{"location":"API_Reference/yaozarrs.v05/#labels","title":"Labels","text":""},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.LabelImage","title":"<code>LabelImage</code>","text":"<p>A complete label image with multiscale pyramids and label metadata.</p> <p>Combines the standard image structure (multiscale pyramids, axes, etc.) with label-specific metadata (colors, properties, source reference). Label images must use integer data types.</p> <p>Relationship to Image</p> <p>This is an <code>Image</code> with additional <code>image-label</code> metadata. The multiscale pyramids follow the same structure as regular images but contain integer segmentation masks instead of intensity data.</p> <p>Parameters:</p> Name Type Description Default <code>image_label</code> <code>ImageLabel</code> <p>Label-specific metadata (colors, properties, source link)</p> required Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class LabelImage(Image):\n    \"\"\"A complete label image with multiscale pyramids and label metadata.\n\n    Combines the standard image structure (multiscale pyramids, axes, etc.)\n    with label-specific metadata (colors, properties, source reference).\n    Label images must use integer data types.\n\n    !!! note \"Relationship to Image\"\n        This is an [`Image`][yaozarrs.v05.Image] with additional `image-label`\n        metadata. The multiscale pyramids follow the same structure as regular images\n        but contain integer segmentation masks instead of intensity data.\n    \"\"\"\n\n    image_label: ImageLabel = Field(\n        alias=\"image-label\",\n        description=\"Label-specific metadata (colors, properties, source link)\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.ImageLabel","title":"<code>ImageLabel</code>","text":"<p>Metadata for a segmentation/annotation label image.</p> <p>Enhances a multiscale label image with display colors, semantic properties, and links back to the source intensity image. Label images are integer-valued arrays where each unique value represents a distinct object or region.</p> <p>Parameters:</p> Name Type Description Default <code>colors</code> <code>list[LabelColor] | None</code> <p>Color mappings for label values, used for visualization</p> <code>None</code> <code>properties</code> <code>list[LabelProperty] | None</code> <p>Arbitrary metadata properties for individual label values</p> <code>None</code> <code>source</code> <code>LabelSource | None</code> <p>Reference to the source intensity image that was segmented</p> <code>None</code> <code>version</code> <code>Literal['0.5'] | None</code> <p>OME-NGFF image-label specification version (often omitted)</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class ImageLabel(_BaseModel):\n    \"\"\"Metadata for a segmentation/annotation label image.\n\n    Enhances a multiscale label image with display colors, semantic properties,\n    and links back to the source intensity image. Label images are integer-valued\n    arrays where each unique value represents a distinct object or region.\n    \"\"\"\n\n    colors: Annotated[UniqueList[LabelColor], MinLen(1)] | None = Field(\n        default=None,\n        description=\"Color mappings for label values, used for visualization\",\n    )\n    properties: Annotated[UniqueList[LabelProperty], MinLen(1)] | None = Field(\n        default=None,\n        description=\"Arbitrary metadata properties for individual label values\",\n    )\n    source: LabelSource | None = Field(\n        default=None,\n        description=\"Reference to the source intensity image that was segmented\",\n    )\n\n    version: Literal[\"0.5\"] | None = Field(\n        default=None,\n        description=\"OME-NGFF image-label specification version (often omitted)\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.LabelColor","title":"<code>LabelColor</code>","text":"<p>Display color mapping for a label value.</p> <p>Associates a specific label integer value with an RGBA color for visualization purposes.</p> <p>Parameters:</p> Name Type Description Default <code>label_value</code> <code>float</code> <p>Integer label value from the segmentation image</p> required <code>rgba</code> <code>list[int] | None</code> <p>RGBA color as [red, green, blue, alpha], each 0-255</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class LabelColor(_BaseModel):\n    \"\"\"Display color mapping for a label value.\n\n    Associates a specific label integer value with an RGBA color for\n    visualization purposes.\n    \"\"\"\n\n    label_value: float = Field(\n        description=\"Integer label value from the segmentation image\",\n        alias=\"label-value\",\n    )\n    rgba: Annotated[list[Int8bit], Len(min_length=4, max_length=4)] | None = Field(\n        default=None,\n        description=\"RGBA color as [red, green, blue, alpha], each 0-255\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.LabelProperty","title":"<code>LabelProperty</code>","text":"<p>Custom metadata for a label value.</p> <p>Associates arbitrary key-value properties with a specific label integer. Different labels can have different sets of properties - there's no requirement for consistency across labels.</p> <p>Example</p> <pre><code>LabelProperty(label_value=1, cell_type=\"neuron\", area=1250.5)\nLabelProperty(label_value=2, cell_type=\"glia\", perimeter=180.3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>label_value</code> <code>int</code> <p>Integer label value from the segmentation image</p> required Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class LabelProperty(_BaseModel):\n    \"\"\"Custom metadata for a label value.\n\n    Associates arbitrary key-value properties with a specific label integer.\n    Different labels can have different sets of properties - there's no requirement\n    for consistency across labels.\n\n    !!! example\n        ```python\n        LabelProperty(label_value=1, cell_type=\"neuron\", area=1250.5)\n        LabelProperty(label_value=2, cell_type=\"glia\", perimeter=180.3)\n        ```\n    \"\"\"\n\n    label_value: int = Field(\n        description=\"Integer label value from the segmentation image\",\n        alias=\"label-value\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.LabelSource","title":"<code>LabelSource</code>","text":"<p>Reference to the source image that was segmented.</p> <p>Points back to the original intensity image from which this label image was derived.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str | None</code> <p>Relative path to the source image group (default: '../../', pointing to the parent of the labels/ directory)</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class LabelSource(_BaseModel):\n    \"\"\"Reference to the source image that was segmented.\n\n    Points back to the original intensity image from which this label\n    image was derived.\n    \"\"\"\n\n    image: str | None = Field(\n        default=None,\n        description=(\n            \"Relative path to the source image group (default: '../../', \"\n            \"pointing to the parent of the labels/ directory)\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._labels.LabelsGroup","title":"<code>LabelsGroup</code>","text":"<p>Top-level labels collection metadata.</p> <p>This model corresponds to the <code>zarr.json</code> file in a <code>labels/</code> directory, which acts as a container for multiple segmentation/annotation images.</p> <p>Typical Structure</p> <pre><code>my_image/\n\u251c\u2500\u2500 zarr.json          # Image metadata\n\u251c\u2500\u2500 0/                 # Image arrays\n\u2514\u2500\u2500 labels/\n    \u251c\u2500\u2500 zarr.json      # Contains this metadata\n    \u251c\u2500\u2500 cells/         # One label image\n    \u2514\u2500\u2500 nuclei/        # Another label image\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>labels</code> <code>list[str]</code> <p>Paths to individual label image groups within this collection</p> required Source code in <code>src/yaozarrs/v05/_labels.py</code> <pre><code>class LabelsGroup(_BaseModel):\n    \"\"\"Top-level labels collection metadata.\n\n    This model corresponds to the `zarr.json` file in a `labels/` directory,\n    which acts as a container for multiple segmentation/annotation images.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_image/\n        \u251c\u2500\u2500 zarr.json          # Image metadata\n        \u251c\u2500\u2500 0/                 # Image arrays\n        \u2514\u2500\u2500 labels/\n            \u251c\u2500\u2500 zarr.json      # Contains this metadata\n            \u251c\u2500\u2500 cells/         # One label image\n            \u2514\u2500\u2500 nuclei/        # Another label image\n        ```\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    labels: Annotated[list[str], MinLen(1)] = Field(\n        description=\"Paths to individual label image groups within this collection\"\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#plates","title":"Plates","text":""},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.Plate","title":"<code>Plate</code>","text":"<p>Top-level plate metadata for high-content screening.</p> <p>This model corresponds to the <code>zarr.json</code> file in a plate group, organizing a microplate's wells in a grid layout. Each well contains one or more fields-of-view, which in turn contain multiscale images.</p> <p>Typical Structure</p> <pre><code>my_plate.ome.zarr\n\u251c\u2500\u2500 A                       # Col A\n\u2502   \u251c\u2500\u2500 1                   # Row 1\n\u2502   \u2502   \u251c\u2500\u2500 0               # FOV 0 (in A1)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 0           # FOV 0 - Multiscale level 0\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 zarr.json   # contains [\"ome\"][\"multiscales\"]\n\u2502   \u2502   \u251c\u2500\u2500 1               # FOV 1 (in A1)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 0           # FOV 1 - Multiscale level 0\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 zarr.json   # contains [\"ome\"][\"multiscales\"]\n\u2502   \u2502   \u2514\u2500\u2500 zarr.json       # well metadata (contains ['ome']['well'])\n\u2502   \u251c\u2500\u2500 2\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 3\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 B\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 C\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 zarr.json                # plate metadata (contains ['ome']['plate'])\n</code></pre> <p>Note</p> <p>See also:</p> <ul> <li><code>Well</code></li> <li><code>FieldOfView</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>plate</code> <code>PlateDef</code> <p>Plate layout and well organization</p> required <code>bioformats2raw_layout</code> <code>Literal[3] | None</code> <p>Marker indicating this plate was created by bioformats2raw version 3</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class Plate(_BaseModel):\n    \"\"\"Top-level plate metadata for high-content screening.\n\n    This model corresponds to the `zarr.json` file in a plate group, organizing\n    a microplate's wells in a grid layout. Each well contains one or more\n    fields-of-view, which in turn contain multiscale images.\n\n    !!! example \"Typical Structure\"\n        ```\n        my_plate.ome.zarr\n        \u251c\u2500\u2500 A                       # Col A\n        \u2502   \u251c\u2500\u2500 1                   # Row 1\n        \u2502   \u2502   \u251c\u2500\u2500 0               # FOV 0 (in A1)\n        \u2502   \u2502   \u2502   \u251c\u2500\u2500 0           # FOV 0 - Multiscale level 0\n        \u2502   \u2502   \u2502   \u2514\u2500\u2500 zarr.json   # contains [\"ome\"][\"multiscales\"]\n        \u2502   \u2502   \u251c\u2500\u2500 1               # FOV 1 (in A1)\n        \u2502   \u2502   \u2502   \u251c\u2500\u2500 0           # FOV 1 - Multiscale level 0\n        \u2502   \u2502   \u2502   \u2514\u2500\u2500 zarr.json   # contains [\"ome\"][\"multiscales\"]\n        \u2502   \u2502   \u2514\u2500\u2500 zarr.json       # well metadata (contains ['ome']['well'])\n        \u2502   \u251c\u2500\u2500 2\n        \u2502   \u2502   \u2514\u2500\u2500 ...\n        \u2502   \u2514\u2500\u2500 3\n        \u2502       \u2514\u2500\u2500 ...\n        \u251c\u2500\u2500 B\n        \u2502   \u2514\u2500\u2500 ...\n        \u251c\u2500\u2500 C\n        \u2502   \u2514\u2500\u2500 ...\n        \u2514\u2500\u2500 zarr.json                # plate metadata (contains ['ome']['plate'])\n        ```\n\n    !!! note\n        See also:\n\n        - [`Well`][yaozarrs.v05.Well]\n        - [`FieldOfView`][yaozarrs.v05.FieldOfView]\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    plate: PlateDef = Field(\n        description=\"Plate layout and well organization\",\n    )\n\n    bioformats2raw_layout: Literal[3] | None = Field(\n        default=None,\n        alias=\"bioformats2raw.layout\",\n        description=(\n            \"Marker indicating this plate was created by bioformats2raw version 3\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.PlateDef","title":"<code>PlateDef</code>","text":"<p>Plate layout and well organization.</p> <p>Defines the grid structure of a microplate and maps wells to their data. This is the core content of the <code>plate</code> metadata field.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list[Column]</code> <p>Column definitions for the plate grid</p> required <code>rows</code> <code>list[Row]</code> <p>Row definitions for the plate grid</p> required <code>wells</code> <code>list[PlateWell]</code> <p>List of all wells present in this plate with their grid positions</p> required <code>acquisitions</code> <code>list[Acquisition] | None</code> <p>Imaging acquisition runs performed on this plate</p> <code>None</code> <code>field_count</code> <code>int | None</code> <p>Maximum number of fields-of-view per well across the entire plate</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Human-readable name for this plate</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class PlateDef(_BaseModel):\n    \"\"\"Plate layout and well organization.\n\n    Defines the grid structure of a microplate and maps wells to their data.\n    This is the core content of the `plate` metadata field.\n    \"\"\"\n\n    columns: Annotated[UniqueList[Column], MinLen(1)] = Field(\n        description=\"Column definitions for the plate grid\"\n    )\n    rows: Annotated[UniqueList[Row], MinLen(1)] = Field(\n        description=\"Row definitions for the plate grid\"\n    )\n    wells: Annotated[UniqueList[PlateWell], MinLen(1)] = Field(\n        description=\"List of all wells present in this plate with their grid positions\"\n    )\n\n    acquisitions: list[Acquisition] | None = Field(\n        default=None,\n        description=\"Imaging acquisition runs performed on this plate\",\n    )\n    field_count: PositiveInt | None = Field(\n        default=None,\n        description=\"Maximum number of fields-of-view per well across the entire plate\",\n    )\n    name: str | None = Field(\n        default=None,\n        description=\"Human-readable name for this plate\",\n    )\n\n    @model_validator(mode=\"after\")\n    def _validate_well_indices(self) -&gt; Self:\n        for well in self.wells:\n            if well.rowIndex &gt;= len(self.rows):\n                raise ValueError(\n                    f\"Well {well.path} has rowIndex {well.rowIndex} \"\n                    f\"but only {len(self.rows)} rows exist\"\n                )\n            if well.columnIndex &gt;= len(self.columns):\n                raise ValueError(\n                    f\"Well {well.path} has columnIndex {well.columnIndex} \"\n                    f\"but only {len(self.columns)} columns exist\"\n                )\n        return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.Column","title":"<code>Column</code>","text":"<p>A column in the plate grid.</p> <p>Columns are typically numbered (1, 2, 3, ...) but can use any alphanumeric identifier.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Column identifier (typically numeric, e.g., '1', '2', '3')</p> required Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class Column(_BaseModel):\n    \"\"\"A column in the plate grid.\n\n    Columns are typically numbered (1, 2, 3, ...) but can use any\n    alphanumeric identifier.\n    \"\"\"\n\n    name: str = Field(\n        description=\"Column identifier (typically numeric, e.g., '1', '2', '3')\",\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.Row","title":"<code>Row</code>","text":"<p>A row in the plate grid.</p> <p>Rows are typically lettered (A, B, C, ...) but can use any alphanumeric identifier.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Row identifier (typically alphabetic, e.g., 'A', 'B', 'C')</p> required Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class Row(_BaseModel):\n    \"\"\"A row in the plate grid.\n\n    Rows are typically lettered (A, B, C, ...) but can use any alphanumeric identifier.\n    \"\"\"\n\n    name: str = Field(\n        description=\"Row identifier (typically alphabetic, e.g., 'A', 'B', 'C')\",\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.PlateWell","title":"<code>PlateWell</code>","text":"<p>A well location reference within a plate.</p> <p>Maps a well's row/column position to its data location. This is a lightweight reference used in plate metadata, not the full well group (see <code>Well</code> for the complete well metadata).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to the well's group (format: 'row/column', e.g., 'A/1')</p> required <code>rowIndex</code> <code>int</code> <p>Zero-based index into the plate's rows list</p> required <code>columnIndex</code> <code>int</code> <p>Zero-based index into the plate's columns list</p> required Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class PlateWell(_BaseModel):\n    \"\"\"A well location reference within a plate.\n\n    Maps a well's row/column position to its data location. This is a\n    lightweight reference used in plate metadata, not the full well group\n    (see [`Well`][yaozarrs.v05.Well] for the complete well metadata).\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Relative path to the well's group (format: 'row/column', e.g., 'A/1')\"\n        ),\n        pattern=r\"^[A-Za-z0-9]+/[A-Za-z0-9]+$\",\n    )\n    rowIndex: NonNegativeInt = Field(\n        description=\"Zero-based index into the plate's rows list\",\n    )\n    columnIndex: NonNegativeInt = Field(\n        description=\"Zero-based index into the plate's columns list\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.Acquisition","title":"<code>Acquisition</code>","text":"<p>An imaging acquisition run within a plate.</p> <p>In high-content screening, multiple acquisition runs may be performed on the same plate (e.g., at different timepoints or with different settings). This class groups related images from a single acquisition session.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>Unique identifier within the plate for this acquisition</p> required <code>maximumfieldcount</code> <code>int | None</code> <p>Maximum number of fields-of-view across all wells in this acquisition</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Human-readable name for this acquisition</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Detailed description of the acquisition parameters or purpose</p> <code>None</code> <code>starttime</code> <code>int | None</code> <p>Acquisition start time as Unix epoch timestamp (seconds since 1970-01-01)</p> <code>None</code> <code>endtime</code> <code>int | None</code> <p>Acquisition end time as Unix epoch timestamp (seconds since 1970-01-01)</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class Acquisition(_BaseModel):\n    \"\"\"An imaging acquisition run within a plate.\n\n    In high-content screening, multiple acquisition runs may be performed on the\n    same plate (e.g., at different timepoints or with different settings).\n    This class groups related images from a single acquisition session.\n    \"\"\"\n\n    id: NonNegativeInt = Field(\n        description=\"Unique identifier within the plate for this acquisition\",\n    )\n    maximumfieldcount: PositiveInt | None = Field(\n        default=None,\n        description=(\n            \"Maximum number of fields-of-view across all wells in this acquisition\"\n        ),\n    )\n    name: str | None = Field(\n        default=None,\n        description=\"Human-readable name for this acquisition\",\n    )\n    description: str | None = Field(\n        default=None,\n        description=\"Detailed description of the acquisition parameters or purpose\",\n    )\n    starttime: NonNegativeInt | None = Field(\n        default=None,\n        description=(\n            \"Acquisition start time as Unix epoch timestamp (seconds since 1970-01-01)\"\n        ),\n    )\n    endtime: NonNegativeInt | None = Field(\n        default=None,\n        description=(\n            \"Acquisition end time as Unix epoch timestamp (seconds since 1970-01-01)\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.Well","title":"<code>Well</code>","text":"<p>Top-level well metadata within a plate.</p> <p>This model corresponds to the <code>zarr.json</code> file in a well group. It lists all fields-of-view (imaging positions) captured within this well.</p> <p>Typical Structure</p> <pre><code>A/1/                   # Well at row A, column 1\n\u251c\u2500\u2500 zarr.json          # Contains this metadata\n\u251c\u2500\u2500 0/                 # First field-of-view\n\u2502   \u251c\u2500\u2500 zarr.json      # Image metadata\n\u2502   \u251c\u2500\u2500 0/             # Highest resolution\n\u2502   \u2514\u2500\u2500 1/             # Next resolution\n\u2514\u2500\u2500 1/                 # Second field-of-view\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>well</code> <code>WellDef</code> <p>Field-of-view organization for this well</p> required Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class Well(_BaseModel):\n    \"\"\"Top-level well metadata within a plate.\n\n    This model corresponds to the `zarr.json` file in a well group. It lists\n    all fields-of-view (imaging positions) captured within this well.\n\n    !!! example \"Typical Structure\"\n        ```\n        A/1/                   # Well at row A, column 1\n        \u251c\u2500\u2500 zarr.json          # Contains this metadata\n        \u251c\u2500\u2500 0/                 # First field-of-view\n        \u2502   \u251c\u2500\u2500 zarr.json      # Image metadata\n        \u2502   \u251c\u2500\u2500 0/             # Highest resolution\n        \u2502   \u2514\u2500\u2500 1/             # Next resolution\n        \u2514\u2500\u2500 1/                 # Second field-of-view\n        ```\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    well: WellDef = Field(\n        description=\"Field-of-view organization for this well\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.WellDef","title":"<code>WellDef</code>","text":"<p>Organization of fields-of-view within a well.</p> <p>This is the core content of the <code>well</code> metadata field, listing all imaging positions captured for this well.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list[FieldOfView]</code> <p>List of all fields-of-view imaged in this well</p> required Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class WellDef(_BaseModel):\n    \"\"\"Organization of fields-of-view within a well.\n\n    This is the core content of the `well` metadata field, listing all\n    imaging positions captured for this well.\n    \"\"\"\n\n    images: Annotated[UniqueList[FieldOfView], MinLen(1)] = Field(\n        description=\"List of all fields-of-view imaged in this well\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._plate.FieldOfView","title":"<code>FieldOfView</code>","text":"<p>A single field-of-view (imaging position) within a well.</p> <p>Wells typically contain multiple fields-of-view when the well area is larger than a single camera frame. Each field-of-view is a complete multiscale image.</p> <p>This class appears within the <code>images</code> list of a <code>WellDef</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to this field's image group (typically a number like '0', '1', etc.)</p> required <code>acquisition</code> <code>int | None</code> <p>Acquisition ID linking this field to a specific acquisition run. Required when the parent plate has multiple acquisitions.</p> <code>None</code> Source code in <code>src/yaozarrs/v05/_plate.py</code> <pre><code>class FieldOfView(_BaseModel):\n    \"\"\"A single field-of-view (imaging position) within a well.\n\n    Wells typically contain multiple fields-of-view when the well area is larger\n    than a single camera frame. Each field-of-view is a complete multiscale image.\n\n    This class appears within the `images` list of a [`WellDef`][yaozarrs.v05.WellDef].\n    \"\"\"\n\n    path: str = Field(\n        description=(\n            \"Relative path to this field's image group \"\n            \"(typically a number like '0', '1', etc.)\"\n        ),\n        pattern=r\"^[A-Za-z0-9]+$\",\n    )\n    acquisition: int | None = Field(\n        default=None,\n        description=(\n            \"Acquisition ID linking this field to a specific acquisition run. \"\n            \"Required when the parent plate has multiple acquisitions.\"\n        ),\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#collections","title":"Collections","text":""},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._bf2raw.Bf2Raw","title":"<code>Bf2Raw</code>","text":"<p>Model for <code>zarr.json</code> in a group representing multi-series image collections.</p> <p>The bioformats2raw layout was added in v0.4 as a transitional specification to specify filesets that already exist in the wild. An upcoming NGFF specification will replace this layout with explicit metadata.</p> <p>This model is a transitional spec for representing multi-position image collections in OME-NGFF v0.5. It is currently the only way to represent multi-position image collections. It also has a recommended place for OME-XML metadata.</p> <p>Typical Structure</p> <pre><code>root.ome.zarr             # One converted fileset from bioformats2raw\n\u251c\u2500\u2500 zarr.json             # Contains \"bioformats2raw.layout\" metadata\n\u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n\u2502   \u251c\u2500\u2500 zarr.json         # Contains \"series\" metadata\n\u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n\u251c\u2500\u2500 0                     # First image in the collection\n\u251c\u2500\u2500 1                     # Second image in the collection\n\u2514\u2500\u2500 ...\n</code></pre> <p>Note</p> <p>The <code>OME/zarr.json</code> file typically contains <code>Series</code> metadata that explicitly lists image paths. If not present, images MUST be numbered as shown above, starting from <code>0</code>, e.g., <code>0/</code>, <code>1/</code>, <code>2/</code>, etc.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>bioformats2raw_layout</code> <code>Literal[3]</code> <p>Layout version marker added by bioformats2raw (currently 3)</p> required Source code in <code>src/yaozarrs/v05/_bf2raw.py</code> <pre><code>class Bf2Raw(_BaseModel):\n    \"\"\"Model for `zarr.json` in a group representing multi-series image collections.\n\n    The bioformats2raw layout was added in v0.4 as a transitional specification to\n    specify filesets that already exist in the wild. An upcoming NGFF specification will\n    replace this layout with explicit metadata.\n\n    This model is a transitional spec for representing multi-position image collections\n    in OME-NGFF v0.5. It is currently the only way to represent multi-position image\n    collections. It also has a recommended place for OME-XML metadata.\n\n    !!! example \"Typical Structure\"\n        ```\n        root.ome.zarr             # One converted fileset from bioformats2raw\n        \u251c\u2500\u2500 zarr.json             # Contains \"bioformats2raw.layout\" metadata\n        \u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n        \u2502   \u251c\u2500\u2500 zarr.json         # Contains \"series\" metadata\n        \u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n        \u251c\u2500\u2500 0                     # First image in the collection\n        \u251c\u2500\u2500 1                     # Second image in the collection\n        \u2514\u2500\u2500 ...\n        ```\n\n    !!! note\n        The `OME/zarr.json` file typically contains [`Series`][yaozarrs.v05.Series]\n        metadata that explicitly lists image paths. If not present, images MUST be\n        numbered as shown above, starting from `0`, e.g., `0/`, `1/`, `2/`, etc.\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    bioformats2raw_layout: Literal[3] = Field(\n        alias=\"bioformats2raw.layout\",\n        description=\"Layout version marker added by bioformats2raw (currently 3)\",\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.v05/#yaozarrs.v05._bf2raw.Series","title":"<code>Series</code>","text":"<p>Model for <code>OME/zarr.json</code> in an <code>Bf2Raw</code> collection.</p> <p>Used when converting files containing multiple distinct images (e.g., multi-series microscopy formats) to OME-NGFF. Each series becomes a separate image group, and this metadata lists them all.</p> <p>Typical Structure</p> <pre><code>root.ome.zarr             # One converted fileset from bioformats2raw\n\u251c\u2500\u2500 zarr.json             # Contains \"bioformats2raw.layout\" metadata\n\u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n\u2502   \u251c\u2500\u2500 zarr.json         # Contains \"series\" metadata\n\u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n\u251c\u2500\u2500 0                     # First image in the collection\n\u251c\u2500\u2500 1                     # Second image in the collection\n\u2514\u2500\u2500 ...\n</code></pre> <p>Note</p> <p>The spec is ambiguous about whether <code>series</code> is required. This library treats it as required for disambiguation. Since otherwise this model would simply contain \"version\".</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Literal['0.5']</code> <p>OME-NGFF specification version</p> <code>'0.5'</code> <code>series</code> <code>list[str]</code> <p>Ordered list of paths to image groups, matching the order in the companion OME-XML metadata</p> required Source code in <code>src/yaozarrs/v05/_bf2raw.py</code> <pre><code>class Series(_BaseModel):\n    \"\"\"Model for `OME/zarr.json` in an [`Bf2Raw`][yaozarrs.v05.Bf2Raw] collection.\n\n    Used when converting files containing multiple distinct images (e.g.,\n    multi-series microscopy formats) to OME-NGFF. Each series becomes a\n    separate image group, and this metadata lists them all.\n\n    !!! example \"Typical Structure\"\n        ```\n        root.ome.zarr             # One converted fileset from bioformats2raw\n        \u251c\u2500\u2500 zarr.json             # Contains \"bioformats2raw.layout\" metadata\n        \u251c\u2500\u2500 OME                   # Special group for containing OME metadata\n        \u2502   \u251c\u2500\u2500 zarr.json         # Contains \"series\" metadata\n        \u2502   \u2514\u2500\u2500 METADATA.ome.xml  # OME-XML file stored within the Zarr fileset\n        \u251c\u2500\u2500 0                     # First image in the collection\n        \u251c\u2500\u2500 1                     # Second image in the collection\n        \u2514\u2500\u2500 ...\n        ```\n\n    !!! note\n        The spec is ambiguous about whether `series` is required.\n        This library treats it as required for disambiguation. Since otherwise this\n        model would simply contain \"version\".\n    \"\"\"\n\n    version: Literal[\"0.5\"] = Field(\n        default=\"0.5\",\n        description=\"OME-NGFF specification version\",\n    )\n    series: Annotated[list[str], MinLen(1)] = Field(\n        description=(\n            \"Ordered list of paths to image groups, matching the order in \"\n            \"the companion OME-XML metadata\"\n        )\n    )\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/","title":"<code>yaozarrs.write.v05</code>","text":"<p>This module provides convenience functions to write OME-Zarr v0.5 stores.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#overview","title":"Overview","text":"<p>The general pattern is:</p> <ol> <li>Decide what kind of OME model best matches your data (see Guide to    OME-Zarr if you're new to OME Zarr), and construct your    OME-Zarr metadata model using    yaozarrs.v05 models:<ul> <li>Single Image (&lt;=5D): use <code>Image</code>.</li> <li>Multi-Well Plate: use <code>Plate</code>.</li> <li>Collection of images (e.g. 5D images at multiple positions, or any other     6+D data): use bioformats2raw layout with     <code>Bf2Raw</code>.</li> </ul> </li> <li> <p>Decide whether to use high level write functions    (<code>write_image</code>, <code>write_plate</code>, etc...) or lower level    prepare/Builder methods (<code>prepare_image</code>, <code>PlateBuilder</code>, etc...):</p> <ul> <li> <p>High Level <code>write_*</code> functions immediately write data and return a <code>Path</code> to the root   of the written zarr group.</p> Name Description <code>write_image</code> Write a single Image OME-Zarr v0.5 store. <code>write_plate</code> Write a multi-well Plate OME-Zarr v0.5 store. <code>write_bioformats2raw</code> Write a bioformats2raw-style OME-Zarr v0.5 store. </li> <li> <p>Low Level <code>prepare_*/Builder</code> methods prepare the zarr hierarchy,   instantiate empty Arrays, and return a mapping of dataset-path to backend   Array object, which you can then use to write data.  For complex groups,     they can write one dataset at a time, or in any order you like.</p> Name Description <code>prepare_image</code> Prepare a single Image OME-Zarr v0.5 store for writing. <code>LabelsBuilder</code> Prepare a Labels OME-Zarr v0.5 store for writing. <code>PlateBuilder</code> Prepare a multi-well Plate OME-Zarr v0.5 store for writing. <code>Bf2RawBuilder</code> Prepare a bioformats2raw-style OME-Zarr v0.5 store for writing. </li> </ul> Still confused: Which API should I use? <ul> <li>Use high level <code>write_*</code> functions for simple one-shot writes, where you can provide the full data arrays up front (either in-memory with numpy, or dask, etc...)</li> <li>Use lower level <code>prepare_*/Builder</code> APIs when you need to customize how data is written, perhaps in a streaming, or slice-by-slice manner, or when you want to use the backend array writing API directly.</li> </ul> <p>Note: lower level builders are recommended for Plates and Bf2Raw collections</p> </li> <li> <p>Call the appropriate function with your metadata model and data arrays.</p> </li> </ol> <p>Tip</p> <p>A key observation here is that there is generally a one-to-one mapping between a <code>Dataset</code> (nested inside the <code>Image</code> model), and an array node in the output zarr hierarchy.  Most functions that accept arrays and/or <code>(shape, dtype)</code> pairs are expecting one per Dataset in the model.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#choosing-an-array-writer-backend","title":"Choosing an Array Writer Backend","text":"<p>All functions in this module eventually write zarr arrays.  You can control what backend is used to write arrays using the <code>writer</code> argument to each function, which takes a string literal (name of the backend), or a custom <code>CreateArrayFunc</code> function.  If you want to use builtin writers backends, you must install with the appropriate extras:</p> <ul> <li>zarr-python: <code>pip install yaozarrs[write-zarr]</code></li> <li>tensorstore: <code>pip install yaozarrs[write-tensorstore]</code></li> </ul> <p>You may also implement and pass in your own <code>writer</code> function.  See the Custom Writers guide for details.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05","title":"<code>yaozarrs.write.v05</code>","text":"<p>Writing utilities for OME-Zarr v0.5 format.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.LabelsBuilder","title":"<code>LabelsBuilder</code>","text":"<p>Builder for labels groups within an Image.</p> <p>The labels group structure includes: - A labels group with LabelsGroup metadata listing all label names - Each label as a separate LabelImage subgroup (e.g., <code>cells/</code>, <code>nuclei/</code>)</p> <p>This builder supports two workflows:</p> <ol> <li> <p>Immediate write (simpler): Use <code>write_label()</code> to write each label    with its data immediately. The builder auto-generates and updates    LabelsGroup metadata after each call.</p> </li> <li> <p>Prepare-only (flexible): Use <code>add_label()</code> to register all labels,    then <code>prepare()</code> to create the hierarchy with empty arrays. Write data    to the returned array handles yourself.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the labels Zarr group (typically <code>image_path/labels</code>).</p> required <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays. Default is \"auto\".</p> <code>'auto'</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for all arrays. Default is \"auto\".</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing groups. Default is False. Note: existing directories that don't look like zarr groups will NOT be removed, an exception will be raised instead.</p> <code>False</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <p>Examples:</p> <p>Immediate write workflow:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import LabelsBuilder\n&gt;&gt;&gt; def make_label_image():\n...     return v05.LabelImage(\n...         multiscales=[\n...             v05.Multiscale(\n...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n...                 datasets=[\n...                     v05.Dataset(\n...                         path=\"0\",\n...                         coordinateTransformations=[\n...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n...                         ],\n...                     )\n...                 ],\n...             )\n...         ],\n...         image_label=v05.ImageLabel(),\n...     )\n&gt;&gt;&gt; builder = LabelsBuilder(\"my_image.zarr/labels\")\n&gt;&gt;&gt; builder.write_label(\n...     \"cells\", make_label_image(), np.zeros((64, 64), dtype=np.uint32)\n... )\n&lt;LabelsBuilder: 1 labels&gt;\n&gt;&gt;&gt; builder.write_label(\n...     \"nuclei\", make_label_image(), np.zeros((64, 64), dtype=np.uint32)\n... )\n&lt;LabelsBuilder: 2 labels&gt;\n</code></pre> <p>Prepare-only workflow:</p> <pre><code>&gt;&gt;&gt; builder2 = LabelsBuilder(\"my_image2.zarr/labels\")\n&gt;&gt;&gt; builder2.add_label(\n...     \"cells\",\n...     make_label_image(),\n...     ((64, 64), np.uint32),  # shape, dtype spec\n... )\n&lt;LabelsBuilder: 1 labels&gt;\n&gt;&gt;&gt; path, arrays = builder2.prepare()\n&gt;&gt;&gt; arrays[\"cells/0\"][:] = np.random.randint(0, 10, (64, 64), dtype=np.uint32)\n</code></pre> See Also <p>write_image : High-level function with labels parameter for writing everything at once.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>class LabelsBuilder:\n    \"\"\"Builder for labels groups within an Image.\n\n    The labels group structure includes:\n    - A labels group with LabelsGroup metadata listing all label names\n    - Each label as a separate LabelImage subgroup (e.g., `cells/`, `nuclei/`)\n\n    This builder supports two workflows:\n\n    1. **Immediate write** (simpler): Use `write_label()` to write each label\n       with its data immediately. The builder auto-generates and updates\n       LabelsGroup metadata after each call.\n\n    2. **Prepare-only** (flexible): Use `add_label()` to register all labels,\n       then `prepare()` to create the hierarchy with empty arrays. Write data\n       to the returned array handles yourself.\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the labels Zarr group (typically `image_path/labels`).\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays. Default is \"auto\".\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for all arrays. Default is \"auto\".\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    overwrite : bool, optional\n        If True, overwrite existing groups. Default is False.\n        Note: existing directories that don't look like zarr groups will NOT be removed,\n        an exception will be raised instead.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n\n    Examples\n    --------\n    **Immediate write workflow:**\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import LabelsBuilder\n    &gt;&gt;&gt; def make_label_image():\n    ...     return v05.LabelImage(\n    ...         multiscales=[\n    ...             v05.Multiscale(\n    ...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n    ...                 datasets=[\n    ...                     v05.Dataset(\n    ...                         path=\"0\",\n    ...                         coordinateTransformations=[\n    ...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n    ...                         ],\n    ...                     )\n    ...                 ],\n    ...             )\n    ...         ],\n    ...         image_label=v05.ImageLabel(),\n    ...     )\n    &gt;&gt;&gt; builder = LabelsBuilder(\"my_image.zarr/labels\")\n    &gt;&gt;&gt; builder.write_label(\n    ...     \"cells\", make_label_image(), np.zeros((64, 64), dtype=np.uint32)\n    ... )\n    &lt;LabelsBuilder: 1 labels&gt;\n    &gt;&gt;&gt; builder.write_label(\n    ...     \"nuclei\", make_label_image(), np.zeros((64, 64), dtype=np.uint32)\n    ... )\n    &lt;LabelsBuilder: 2 labels&gt;\n\n    **Prepare-only workflow:**\n\n    &gt;&gt;&gt; builder2 = LabelsBuilder(\"my_image2.zarr/labels\")\n    &gt;&gt;&gt; builder2.add_label(\n    ...     \"cells\",\n    ...     make_label_image(),\n    ...     ((64, 64), np.uint32),  # shape, dtype spec\n    ... )\n    &lt;LabelsBuilder: 1 labels&gt;\n    &gt;&gt;&gt; path, arrays = builder2.prepare()\n    &gt;&gt;&gt; arrays[\"cells/0\"][:] = np.random.randint(0, 10, (64, 64), dtype=np.uint32)\n\n    See Also\n    --------\n    write_image : High-level function with labels parameter for writing everything at\n    once.\n    \"\"\"\n\n    def __init__(\n        self,\n        dest: str | PathLike,\n        *,\n        writer: ZarrWriter = \"auto\",\n        chunks: ShapeLike | Literal[\"auto\"] | None = \"auto\",\n        shards: ShapeLike | None = None,\n        overwrite: bool = False,\n        compression: CompressionName = \"blosc-zstd\",\n    ) -&gt; None:\n        self._dest = Path(dest)\n        self._writer: ZarrWriter = writer\n        self._chunks: ShapeLike | Literal[\"auto\"] | None = chunks\n        self._shards = shards\n        self._overwrite = overwrite\n        self._compression: CompressionName = compression\n\n        # For prepare-only workflow: {label_name: (LabelImage, specs)}\n        self._labels: dict[str, tuple[LabelImage, ShapeAndDTypeOrPyramid]] = {}\n\n        # For immediate write workflow\n        self._initialized = False\n        self._written_labels: list[str] = []\n\n    @property\n    def root_path(self) -&gt; Path:\n        \"\"\"Path to the labels group.\"\"\"\n        return self._dest\n\n    def write_label(\n        self,\n        name: str,\n        label_image: LabelImage,\n        datasets: ArrayOrPyramid,\n        *,\n        progress: bool = False,\n    ) -&gt; Self:\n        \"\"\"Write a label immediately with its data.\n\n        This method creates the label structure and writes data in one call.\n        The labels group structure and LabelsGroup metadata are created/updated\n        automatically. Use this for the \"immediate write\" workflow.\n\n        Parameters\n        ----------\n        name : str\n            Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").\n        label_image : LabelImage\n            OME-Zarr LabelImage metadata model for this label.\n        datasets : ArrayLike | Sequence[ArrayLike]\n            Data array(s) for each resolution level. For a single dataset,\n            pass the array directly without wrapping in a list.\n        progress : bool, optional\n            Show progress bar for dask arrays. Default is False.\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If a label with this name was already written or added.\n        NotImplementedError\n            If the LabelImage has multiple multiscales.\n        \"\"\"\n        self._validate_label_name(name)\n\n        # Initialize labels group structure if needed\n        self._ensure_initialized()\n\n        # Update labels/zarr.json with this label\n        self._update_labels_group(name)\n\n        # Write the label using the existing write_image function\n        # (LabelImage is a subclass of Image)\n        write_image(\n            self._dest / name,\n            label_image,\n            datasets,\n            writer=self._writer,\n            chunks=self._chunks,\n            shards=self._shards,\n            overwrite=self._overwrite,\n            compression=self._compression,\n            progress=progress,\n        )\n\n        return self\n\n    def add_label(\n        self,\n        name: str,\n        label_image: LabelImage,\n        datasets: ShapeAndDTypeOrPyramid,\n    ) -&gt; Self:\n        \"\"\"Add a label for the prepare-only workflow.\n\n        Registers a label to be created when `prepare()` is called. Use this\n        when you want to create the Zarr structure without writing data\n        immediately. After calling `prepare()`, write data to the returned\n        array handles.\n\n        Parameters\n        ----------\n        name : str\n            Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").\n        label_image : LabelImage\n            OME-Zarr LabelImage metadata model for this label.\n        datasets : ShapeAndDTypeOrPyramid\n            Shape/dtype spec(s) for each resolution level:\n            - Single level: `(shape, dtype)`\n            - Multiple levels: `[(shape1, dtype1), (shape2, dtype2)]`\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If a label with this name was already added or written, or if the\n            number of specs doesn't match the metadata.\n        NotImplementedError\n            If the LabelImage has multiple multiscales.\n        \"\"\"\n        self._validate_label_name(name)\n        _, specs_seq = _validate_and_normalize_datasets(\n            label_image, datasets, f\"Label '{name}': \"\n        )\n        self._labels[name] = (label_image, specs_seq)\n        return self\n\n    def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n        \"\"\"Create the Zarr hierarchy and return array handles.\n\n        Creates the complete labels group structure including LabelsGroup\n        metadata, and empty arrays for all registered labels. Call this after\n        registering all labels with `add_label()`.\n\n        The returned arrays support numpy-style indexing for writing data:\n        `arrays[\"label_name/dataset\"][:] = data`.\n\n        Returns\n        -------\n        tuple[Path, dict[str, Any]]\n            A tuple of (root_path, arrays) where `arrays` maps composite keys\n            like `\"cells/0\"` (label name / dataset path) to array objects. The\n            array type depends on the configured writer (zarr.Array or\n            tensorstore.TensorStore).\n\n        Raises\n        ------\n        ValueError\n            If no labels have been added with `add_label()`.\n        FileExistsError\n            If destination exists and `overwrite` is False.\n        ImportError\n            If no suitable writer backend is installed.\n        \"\"\"\n        if not self._labels:  # pragma: no cover\n            raise ValueError(\"No labels added. Use add_label() before prepare().\")\n\n        # Create labels/zarr.json with LabelsGroup metadata\n        labels_group = LabelsGroup(labels=list(self._labels.keys()))\n        _create_zarr3_group(self._dest, labels_group, self._overwrite)\n\n        # Create arrays for each label using prepare_image\n        all_arrays: dict[str, Any] = {}\n        for label_name, (label_image, datasets) in self._labels.items():\n            _label_path, label_arrays = prepare_image(\n                self._dest / label_name,\n                label_image,\n                datasets,\n                chunks=self._chunks,\n                shards=self._shards,\n                writer=self._writer,\n                overwrite=self._overwrite,\n                compression=self._compression,\n            )\n            # Flatten into all_arrays with \"label_name/dataset\" keys\n            for dataset_path, arr in label_arrays.items():\n                all_arrays[f\"{label_name}/{dataset_path}\"] = arr\n\n        return self._dest, all_arrays\n\n    def __repr__(self) -&gt; str:\n        total_labels = len(self._labels) + len(self._written_labels)\n        return f\"&lt;{self.__class__.__name__}: {total_labels} labels&gt;\"\n\n    # ------------------ Internal methods ------------------\n\n    def _validate_label_name(self, name: str) -&gt; None:\n        if name in self._written_labels:  # pragma: no cover\n            raise ValueError(f\"Label '{name}' already written via write_label().\")\n        if name in self._labels:  # pragma: no cover\n            raise ValueError(f\"Label '{name}' already added via add_label().\")\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Create labels group directory if not already done.\n\n        Note: labels/zarr.json is created/updated by _update_labels_group(),\n        not here. This allows starting with zero labels.\n        \"\"\"\n        if self._initialized:\n            return\n\n        # Create root directory\n        self._dest.mkdir(parents=True, exist_ok=True)\n        self._initialized = True\n\n    def _update_labels_group(self, label_name: str) -&gt; None:\n        \"\"\"Update labels/zarr.json with new label name.\n\n        Similar to Bf2RawBuilder._update_ome_series(), this regenerates\n        the LabelsGroup metadata from currently written labels and rewrites\n        zarr.json.\n        \"\"\"\n        if label_name in self._written_labels:\n            # already added ... this is an internal method, don't need to raise\n            return  # pragma: no cover\n\n        self._written_labels.append(label_name)\n        labels_group = LabelsGroup(labels=self._written_labels)\n        zarr_json = {\n            \"zarr_format\": 3,\n            \"node_type\": \"group\",\n            \"attributes\": {\n                \"ome\": labels_group.model_dump(mode=\"json\", exclude_none=True),\n            },\n        }\n        (self._dest / \"zarr.json\").write_text(json.dumps(zarr_json, indent=2))\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.LabelsBuilder.root_path","title":"<code>root_path</code>  <code>property</code>","text":"<p>Path to the labels group.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.LabelsBuilder.write_label","title":"<code>write_label(name, label_image, datasets, *, progress=False)</code>","text":"<p>Write a label immediately with its data.</p> <p>This method creates the label structure and writes data in one call. The labels group structure and LabelsGroup metadata are created/updated automatically. Use this for the \"immediate write\" workflow.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").</p> required <code>label_image</code> <code>LabelImage</code> <p>OME-Zarr LabelImage metadata model for this label.</p> required <code>datasets</code> <code>ArrayLike | Sequence[ArrayLike]</code> <p>Data array(s) for each resolution level. For a single dataset, pass the array directly without wrapping in a list.</p> required <code>progress</code> <code>bool</code> <p>Show progress bar for dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a label with this name was already written or added.</p> <code>NotImplementedError</code> <p>If the LabelImage has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_label(\n    self,\n    name: str,\n    label_image: LabelImage,\n    datasets: ArrayOrPyramid,\n    *,\n    progress: bool = False,\n) -&gt; Self:\n    \"\"\"Write a label immediately with its data.\n\n    This method creates the label structure and writes data in one call.\n    The labels group structure and LabelsGroup metadata are created/updated\n    automatically. Use this for the \"immediate write\" workflow.\n\n    Parameters\n    ----------\n    name : str\n        Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").\n    label_image : LabelImage\n        OME-Zarr LabelImage metadata model for this label.\n    datasets : ArrayLike | Sequence[ArrayLike]\n        Data array(s) for each resolution level. For a single dataset,\n        pass the array directly without wrapping in a list.\n    progress : bool, optional\n        Show progress bar for dask arrays. Default is False.\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If a label with this name was already written or added.\n    NotImplementedError\n        If the LabelImage has multiple multiscales.\n    \"\"\"\n    self._validate_label_name(name)\n\n    # Initialize labels group structure if needed\n    self._ensure_initialized()\n\n    # Update labels/zarr.json with this label\n    self._update_labels_group(name)\n\n    # Write the label using the existing write_image function\n    # (LabelImage is a subclass of Image)\n    write_image(\n        self._dest / name,\n        label_image,\n        datasets,\n        writer=self._writer,\n        chunks=self._chunks,\n        shards=self._shards,\n        overwrite=self._overwrite,\n        compression=self._compression,\n        progress=progress,\n    )\n\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.LabelsBuilder.add_label","title":"<code>add_label(name, label_image, datasets)</code>","text":"<p>Add a label for the prepare-only workflow.</p> <p>Registers a label to be created when <code>prepare()</code> is called. Use this when you want to create the Zarr structure without writing data immediately. After calling <code>prepare()</code>, write data to the returned array handles.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").</p> required <code>label_image</code> <code>LabelImage</code> <p>OME-Zarr LabelImage metadata model for this label.</p> required <code>datasets</code> <code>ShapeAndDTypeOrPyramid</code> <p>Shape/dtype spec(s) for each resolution level: - Single level: <code>(shape, dtype)</code> - Multiple levels: <code>[(shape1, dtype1), (shape2, dtype2)]</code></p> required <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a label with this name was already added or written, or if the number of specs doesn't match the metadata.</p> <code>NotImplementedError</code> <p>If the LabelImage has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def add_label(\n    self,\n    name: str,\n    label_image: LabelImage,\n    datasets: ShapeAndDTypeOrPyramid,\n) -&gt; Self:\n    \"\"\"Add a label for the prepare-only workflow.\n\n    Registers a label to be created when `prepare()` is called. Use this\n    when you want to create the Zarr structure without writing data\n    immediately. After calling `prepare()`, write data to the returned\n    array handles.\n\n    Parameters\n    ----------\n    name : str\n        Label name (becomes the subgroup path, e.g., \"cells\", \"nuclei\").\n    label_image : LabelImage\n        OME-Zarr LabelImage metadata model for this label.\n    datasets : ShapeAndDTypeOrPyramid\n        Shape/dtype spec(s) for each resolution level:\n        - Single level: `(shape, dtype)`\n        - Multiple levels: `[(shape1, dtype1), (shape2, dtype2)]`\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If a label with this name was already added or written, or if the\n        number of specs doesn't match the metadata.\n    NotImplementedError\n        If the LabelImage has multiple multiscales.\n    \"\"\"\n    self._validate_label_name(name)\n    _, specs_seq = _validate_and_normalize_datasets(\n        label_image, datasets, f\"Label '{name}': \"\n    )\n    self._labels[name] = (label_image, specs_seq)\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.LabelsBuilder.prepare","title":"<code>prepare()</code>","text":"<p>Create the Zarr hierarchy and return array handles.</p> <p>Creates the complete labels group structure including LabelsGroup metadata, and empty arrays for all registered labels. Call this after registering all labels with <code>add_label()</code>.</p> <p>The returned arrays support numpy-style indexing for writing data: <code>arrays[\"label_name/dataset\"][:] = data</code>.</p> <p>Returns:</p> Type Description <code>tuple[Path, dict[str, Any]]</code> <p>A tuple of (root_path, arrays) where <code>arrays</code> maps composite keys like <code>\"cells/0\"</code> (label name / dataset path) to array objects. The array type depends on the configured writer (zarr.Array or tensorstore.TensorStore).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no labels have been added with <code>add_label()</code>.</p> <code>FileExistsError</code> <p>If destination exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n    \"\"\"Create the Zarr hierarchy and return array handles.\n\n    Creates the complete labels group structure including LabelsGroup\n    metadata, and empty arrays for all registered labels. Call this after\n    registering all labels with `add_label()`.\n\n    The returned arrays support numpy-style indexing for writing data:\n    `arrays[\"label_name/dataset\"][:] = data`.\n\n    Returns\n    -------\n    tuple[Path, dict[str, Any]]\n        A tuple of (root_path, arrays) where `arrays` maps composite keys\n        like `\"cells/0\"` (label name / dataset path) to array objects. The\n        array type depends on the configured writer (zarr.Array or\n        tensorstore.TensorStore).\n\n    Raises\n    ------\n    ValueError\n        If no labels have been added with `add_label()`.\n    FileExistsError\n        If destination exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n    \"\"\"\n    if not self._labels:  # pragma: no cover\n        raise ValueError(\"No labels added. Use add_label() before prepare().\")\n\n    # Create labels/zarr.json with LabelsGroup metadata\n    labels_group = LabelsGroup(labels=list(self._labels.keys()))\n    _create_zarr3_group(self._dest, labels_group, self._overwrite)\n\n    # Create arrays for each label using prepare_image\n    all_arrays: dict[str, Any] = {}\n    for label_name, (label_image, datasets) in self._labels.items():\n        _label_path, label_arrays = prepare_image(\n            self._dest / label_name,\n            label_image,\n            datasets,\n            chunks=self._chunks,\n            shards=self._shards,\n            writer=self._writer,\n            overwrite=self._overwrite,\n            compression=self._compression,\n        )\n        # Flatten into all_arrays with \"label_name/dataset\" keys\n        for dataset_path, arr in label_arrays.items():\n            all_arrays[f\"{label_name}/{dataset_path}\"] = arr\n\n    return self._dest, all_arrays\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.PlateBuilder","title":"<code>PlateBuilder</code>","text":"<p>Builder for OME-Zarr v0.5 Plate hierarchies with auto-generated metadata.</p> <p>The Plate hierarchy includes: - A root Plate group with metadata (auto-generated from written wells) - Well subgroups (e.g., A/1/, B/2/, etc...) each containing Well metadata - Field subgroups (e.g., 0/, 1/) within each well, each an Image</p> <p>This builder supports two workflows:</p> <ol> <li> <p>Immediate write (simpler): Use <code>write_well()</code> to write each well    with its field data immediately. The builder auto-generates and updates    plate metadata (rows, columns, wells) after each call, similar to how    Bf2RawBuilder auto-updates the series list.</p> </li> <li> <p>Prepare-only (flexible): Use <code>add_well()</code> to register all wells,    then <code>prepare()</code> to create the hierarchy with empty arrays. Plate    metadata is auto-generated from all registered wells.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the Plate Zarr group.</p> required <code>plate</code> <code>Plate | None</code> <p>Optional OME-Zarr Plate metadata model. If None (default), plate metadata (rows, columns, wells) is auto-generated from written/added wells. If provided, validates that written wells match the metadata.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays. Default is \"auto\".</p> <code>'auto'</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for all arrays. Default is \"auto\".</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing groups. Default is False. Note: existing directories that don't look like zarr groups will NOT be removed, an exception will be raised instead.</p> <code>False</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <p>Examples:</p> <p>Auto-generation workflow (recommended):</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import PlateBuilder\n&gt;&gt;&gt;\n&gt;&gt;&gt; def make_image():\n...     return v05.Image(\n...         multiscales=[\n...             v05.Multiscale(\n...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n...                 datasets=[\n...                     v05.Dataset(\n...                         path=\"0\",\n...                         coordinateTransformations=[\n...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n...                         ],\n...                     )\n...                 ],\n...             )\n...         ]\n...     )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # No plate metadata needed - it's auto-generated!\n&gt;&gt;&gt; builder = PlateBuilder(\"plate_auto.zarr\")\n&gt;&gt;&gt; builder.write_well(\n...     row=\"A\",\n...     col=\"1\",\n...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n... )\n&lt;PlateBuilder: 1 wells&gt;\n&gt;&gt;&gt; builder.write_well(\n...     row=\"A\",\n...     col=\"2\",\n...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n... )\n&lt;PlateBuilder: 2 wells&gt;\n&gt;&gt;&gt; assert (builder.root_path / \"zarr.json\").exists()  # Plate metadata auto-updated\n</code></pre> <p>With explicit plate metadata:</p> <pre><code>&gt;&gt;&gt; plate = v05.Plate(\n...     plate=v05.PlateDef(\n...         columns=[v05.Column(name=\"1\")],\n...         rows=[v05.Row(name=\"A\")],\n...         wells=[v05.PlateWell(path=\"A/1\", rowIndex=0, columnIndex=0)],\n...     )\n... )\n&gt;&gt;&gt; builder2 = PlateBuilder(\"plate_explicit.zarr\", plate=plate)\n&gt;&gt;&gt; builder2.write_well(\n...     row=\"A\",\n...     col=\"1\",\n...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n... )\n&lt;PlateBuilder: 1 wells&gt;\n</code></pre> See Also <p>write_plate : High-level function to write all wells at once.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>class PlateBuilder:\n    \"\"\"Builder for OME-Zarr v0.5 Plate hierarchies with auto-generated metadata.\n\n    The Plate hierarchy includes:\n    - A root Plate group with metadata (auto-generated from written wells)\n    - Well subgroups (e.g., A/1/, B/2/, etc...) each containing Well metadata\n    - Field subgroups (e.g., 0/, 1/) within each well, each an Image\n\n    This builder supports two workflows:\n\n    1. **Immediate write** (simpler): Use `write_well()` to write each well\n       with its field data immediately. The builder auto-generates and updates\n       plate metadata (rows, columns, wells) after each call, similar to how\n       Bf2RawBuilder auto-updates the series list.\n\n    2. **Prepare-only** (flexible): Use `add_well()` to register all wells,\n       then `prepare()` to create the hierarchy with empty arrays. Plate\n       metadata is auto-generated from all registered wells.\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the Plate Zarr group.\n    plate : Plate | None, optional\n        Optional OME-Zarr Plate metadata model. If None (default), plate\n        metadata (rows, columns, wells) is auto-generated from written/added\n        wells. If provided, validates that written wells match the metadata.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays. Default is \"auto\".\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for all arrays. Default is \"auto\".\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    overwrite : bool, optional\n        If True, overwrite existing groups. Default is False.\n        Note: existing directories that don't look like zarr groups will NOT be removed,\n        an exception will be raised instead.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n\n    Examples\n    --------\n    **Auto-generation workflow (recommended):**\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import PlateBuilder\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; def make_image():\n    ...     return v05.Image(\n    ...         multiscales=[\n    ...             v05.Multiscale(\n    ...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n    ...                 datasets=[\n    ...                     v05.Dataset(\n    ...                         path=\"0\",\n    ...                         coordinateTransformations=[\n    ...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n    ...                         ],\n    ...                     )\n    ...                 ],\n    ...             )\n    ...         ]\n    ...     )\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # No plate metadata needed - it's auto-generated!\n    &gt;&gt;&gt; builder = PlateBuilder(\"plate_auto.zarr\")\n    &gt;&gt;&gt; builder.write_well(\n    ...     row=\"A\",\n    ...     col=\"1\",\n    ...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n    ... )\n    &lt;PlateBuilder: 1 wells&gt;\n    &gt;&gt;&gt; builder.write_well(\n    ...     row=\"A\",\n    ...     col=\"2\",\n    ...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n    ... )\n    &lt;PlateBuilder: 2 wells&gt;\n    &gt;&gt;&gt; assert (builder.root_path / \"zarr.json\").exists()  # Plate metadata auto-updated\n\n    **With explicit plate metadata:**\n\n    &gt;&gt;&gt; plate = v05.Plate(\n    ...     plate=v05.PlateDef(\n    ...         columns=[v05.Column(name=\"1\")],\n    ...         rows=[v05.Row(name=\"A\")],\n    ...         wells=[v05.PlateWell(path=\"A/1\", rowIndex=0, columnIndex=0)],\n    ...     )\n    ... )\n    &gt;&gt;&gt; builder2 = PlateBuilder(\"plate_explicit.zarr\", plate=plate)\n    &gt;&gt;&gt; builder2.write_well(\n    ...     row=\"A\",\n    ...     col=\"1\",\n    ...     images={\"0\": (make_image(), np.zeros((32, 32), dtype=np.uint16))},\n    ... )\n    &lt;PlateBuilder: 1 wells&gt;\n\n    See Also\n    --------\n    write_plate : High-level function to write all wells at once.\n    \"\"\"\n\n    def __init__(\n        self,\n        dest: str | PathLike,\n        *,\n        plate: Plate | None = None,\n        writer: ZarrWriter = \"auto\",\n        chunks: ShapeLike | Literal[\"auto\"] | None = \"auto\",\n        shards: ShapeLike | None = None,\n        overwrite: bool = False,\n        compression: CompressionName = \"blosc-zstd\",\n    ) -&gt; None:\n        self._dest = Path(dest)\n        self._user_plate = plate  # Store user-provided plate (if any)\n        self._writer: ZarrWriter = writer\n        self._chunks: ShapeLike | Literal[\"auto\"] | None = chunks\n        self._shards = shards\n        self._overwrite = overwrite\n        self._compression: CompressionName = compression\n\n        # For prepare-only workflow: {well_path: {fov: (Image, specs)}}\n        self._wells: dict[str, dict[str, ImageWithShapeSpecs]] = {}\n\n        # For immediate write workflow\n        self._initialized = False\n        # Track written wells: {(row, col): {fov: (Image, datasets)}}\n        self._written_wells_data: dict[\n            tuple[str, str], dict[str, ImageWithDatasets]\n        ] = {}\n\n    @property\n    def root_path(self) -&gt; Path:\n        \"\"\"Path to the root of the plate hierarchy.\"\"\"\n        return self._dest\n\n    def write_well(\n        self,\n        row: str,\n        col: str,\n        images: Mapping[str, ImageWithDatasets],\n        *,\n        progress: bool = False,\n    ) -&gt; Self:\n        \"\"\"Write a well immediately with its `images` (fields of view) and data.\n\n        This method creates the well structure and writes all field data in one\n        call. The plate structure and well metadata are created/updated\n        automatically. Plate metadata (rows, columns, wells) is auto-generated\n        from all written wells and rewritten after each call.\n\n        Parameters\n        ----------\n        row : str\n            Row name like \"A\", \"B\", etc.\n        col : str\n            Column name like \"1\", \"2\", etc.\n        images : Mapping[str, ImageWithDatasets]\n            Mapping of `{fov -&gt; (image_model, datasets)}` where:\n            - fov: Field of view identifier like \"0\", \"1\", etc.\n            - datasets can be:\n              - Single array (for one dataset): `{\"0\": (image, data)}`\n              - Sequence (for multiple datasets): `{\"0\": (image, [data1, data2])}`\n        progress : bool, optional\n            Show progress bar for dask arrays. Default is False.\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If row/col combination was already written or added, or if a user-\n            provided Plate doesn't include this well.\n        NotImplementedError\n            If any Image has multiple multiscales.\n        \"\"\"\n        # Validate well hasn't been used\n        self._validate_well_coordinates(row, col)\n\n        # Initialize plate structure if needed\n        self._ensure_initialized()\n\n        # Normalize fields (convert single arrays to sequences)\n        normalized_fields: dict[str, tuple[Image, Sequence[ArrayLike]]] = {}\n        for fov, (image_model, datasets) in images.items():\n            _, datasets_seq = _validate_and_normalize_datasets(\n                image_model, datasets, f\"Well '{row}/{col}', field '{fov}': \"\n            )\n            normalized_fields[fov] = (image_model, datasets_seq)\n\n        # Track this well's data before writing\n        self._written_wells_data[(row, col)] = cast(\n            \"dict[str, ImageWithDatasets]\", normalized_fields\n        )\n\n        # Update plate metadata with the new well\n        self._update_plate_metadata()\n\n        # Generate Well metadata for this well and create well subgroup\n        well_group_path = self._dest / f\"{row}/{col}\"\n        well_metadata = self._generate_well_metadata(list(images))\n        _create_zarr3_group(well_group_path, well_metadata, self._overwrite)\n\n        # Write each field of view\n        for fov, (image_model, datasets_seq) in normalized_fields.items():\n            field_path = well_group_path / fov\n            write_image(\n                field_path,\n                image_model,\n                datasets_seq,\n                writer=self._writer,\n                chunks=self._chunks,\n                shards=self._shards,\n                overwrite=self._overwrite,\n                compression=self._compression,\n                progress=progress,\n            )\n\n        return self\n\n    def add_well(\n        self,\n        *,\n        row: str,\n        col: str,\n        images: Mapping[str, ImageWithShapeSpecs],\n    ) -&gt; Self:\n        \"\"\"Add a well for the prepare-only workflow.\n\n        Registers a well with its fields to be created when `prepare()` is called.\n        Use this when you want to create the Zarr structure without writing data\n        immediately. After calling `prepare()`, write data to the returned array\n        handles.\n\n        Parameters\n        ----------\n        row : str\n            Row name like \"A\", \"B\", etc.\n        col : str\n            Column name like \"1\", \"2\", etc.\n        images : Mapping[str, ImageWithShapeSpecs]\n            Mapping of `{fov -&gt; (image_model, specs)}` where specs provide the\n            dtype and shape for each resolution level:\n            - Single level: `(image, (shape, dtype))`\n            - Multiple levels: `(image, [(shape1, dtype1), (shape2, dtype2)])`\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If row/col combination was already added/written, or if a user-\n            provided Plate doesn't include this well, or if field specs\n            don't match Image metadata.\n        NotImplementedError\n            If any Image has multiple multiscales.\n        \"\"\"\n        # Validate well hasn't been used\n        self._validate_well_coordinates(row, col)\n\n        # Validate and normalize all fields before accepting\n        well_path = f\"{row}/{col}\"\n        normalized_fields: dict[str, ImageWithShapeSpecs] = {}\n\n        for fov, (image_model, specs) in images.items():\n            _, specs_seq = _validate_and_normalize_datasets(\n                image_model, specs, f\"Well '{well_path}', field '{fov}': \"\n            )\n            normalized_fields[fov] = (image_model, specs_seq)\n\n        self._wells[well_path] = normalized_fields\n        return self\n\n    def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n        \"\"\"Create the Zarr hierarchy and return array handles.\n\n        Creates the complete Plate structure including plate metadata (auto-\n        generated from registered wells), well subgroups with Well metadata,\n        and empty arrays for all registered fields. Call this after registering\n        all wells with `add_well()`.\n\n        The returned arrays support numpy-style indexing for writing data:\n        `arrays[\"well/field/dataset\"][:] = data`.\n\n        Returns\n        -------\n        tuple[Path, dict[str, Any]]\n            A tuple of (root_path, arrays) where `arrays` maps composite keys\n            like `\"A/1/0/0\"` (well_path / field / dataset_path) to array\n            objects. The array type depends on the configured writer\n            (zarr.Array or tensorstore.TensorStore).\n\n        Raises\n        ------\n        ValueError\n            If no wells have been added with `add_well()`.\n        FileExistsError\n            If destination exists and `overwrite` is False.\n        ImportError\n            If no suitable writer backend is installed.\n        \"\"\"\n        if not self._wells:\n            raise ValueError(\"No wells added. Use add_well() before prepare().\")\n\n        # Generate plate metadata from registered wells\n        plate = _merge_plate_metadata(self._get_images_dict(), self._user_plate)\n\n        # Create plate zarr.json\n        _create_zarr3_group(self._dest, plate, self._overwrite)\n\n        # Create arrays for each well/field combination\n        all_arrays: dict[str, Any] = {}\n\n        for well_path, fields in self._wells.items():\n            # Generate Well metadata and group\n            well_metadata = self._generate_well_metadata(list(fields))\n            well_group_path = self._dest / well_path\n            _create_zarr3_group(well_group_path, well_metadata, self._overwrite)\n\n            # Create arrays for each field\n            for fov, (image_model, datasets) in fields.items():\n                field_path = well_group_path / fov\n\n                _field_path, field_arrays = prepare_image(\n                    field_path,\n                    image_model,\n                    datasets,\n                    chunks=self._chunks,\n                    shards=self._shards,\n                    writer=self._writer,\n                    overwrite=self._overwrite,\n                    compression=self._compression,\n                )\n\n                # Flatten into all_arrays with \"well/field/dataset\" keys\n                for dataset_path, arr in field_arrays.items():\n                    composite_key = f\"{well_path}/{fov}/{dataset_path}\"\n                    all_arrays[composite_key] = arr\n\n        return self._dest, all_arrays\n\n    def __repr__(self) -&gt; str:\n        total_wells = len(self._wells) + len(self._written_wells_data)\n        return f\"&lt;{self.__class__.__name__}: {total_wells} wells&gt;\"\n\n    # ------------------ Internal methods ------------------\n\n    def _validate_well_coordinates(self, row: str, col: str) -&gt; None:\n        \"\"\"Validate that well coordinates haven't been used yet.\"\"\"\n        # Check if already written or added\n        well_coords = (row, col)\n        if well_coords in self._written_wells_data:\n            raise ValueError(f\"Well ({row}, {col}) already written via write_well().\")\n        well_path = f\"{row}/{col}\"\n        if well_path in self._wells:\n            raise ValueError(f\"Well ({row}, {col}) already added via add_well().\")\n\n        # If user provided a plate, validate against it\n        if self._user_plate is not None:\n            valid_well_paths = [well.path for well in self._user_plate.plate.wells]\n            if well_path not in valid_well_paths:\n                raise ValueError(\n                    f\"Well path '{well_path}' not found in plate metadata. \"\n                    f\"Valid wells are: {valid_well_paths}\"\n                )\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Create plate root directory if not already done.\n\n        Note: Plate zarr.json is created/updated by _update_plate_metadata(),\n        not here. This allows starting with zero wells.\n        \"\"\"\n        if self._initialized:\n            return\n\n        # Create root directory\n        self._dest.mkdir(parents=True, exist_ok=True)\n        self._initialized = True\n\n    def _get_images_dict(self) -&gt; dict[tuple[str, str, str], ImageWithAny]:\n        \"\"\"Convert internal well storage to images dict format.\n\n        Combines both `_written_wells_data` (immediate write workflow) and\n        `_wells` (prepare-only workflow) into a single images dict.\n        \"\"\"\n        images_dict: dict[tuple[str, str, str], ImageWithAny] = {}\n        # From immediate write workflow\n        for (row, col), fields in self._written_wells_data.items():\n            for fov, image_data in fields.items():\n                images_dict[(row, col, fov)] = image_data\n        # From prepare-only workflow\n        for well_path, fields in self._wells.items():\n            row, col = well_path.split(\"/\")\n            for fov, image_data in fields.items():\n                images_dict[(row, col, fov)] = image_data\n        return images_dict\n\n    def _generate_current_plate_metadata(self) -&gt; Plate:\n        \"\"\"Generate plate metadata from currently written wells.\n\n        If user provided a Plate, use that. Otherwise, auto-generate from\n        written wells (similar to write_plate auto-generation).\n        \"\"\"\n        if self._user_plate is not None:\n            return self._user_plate\n        return _merge_plate_metadata(self._get_images_dict(), self._user_plate)\n\n    def _update_plate_metadata(self) -&gt; None:\n        \"\"\"Update plate zarr.json with current wells.\n\n        Similar to Bf2RawBuilder._update_ome_series(), this regenerates\n        the plate metadata from currently written wells and rewrites zarr.json.\n        \"\"\"\n        plate = self._generate_current_plate_metadata()\n        zarr_json = {\n            \"zarr_format\": 3,\n            \"node_type\": \"group\",\n            \"attributes\": {\n                \"ome\": plate.model_dump(mode=\"json\", exclude_none=True),\n            },\n        }\n        (self._dest / \"zarr.json\").write_text(json.dumps(zarr_json, indent=2))\n\n        # Create row directories if needed\n        row_names = {row for (row, _col) in self._written_wells_data.keys()} | {\n            row for row_path in self._wells.keys() for row in [row_path.split(\"/\")[0]]\n        }\n        for row_name in row_names:\n            row_path = self._dest / row_name\n            if not row_path.exists():\n                _create_zarr3_group(row_path, ome_model=None, overwrite=self._overwrite)\n\n    def _generate_well_metadata(self, field_names: list[str]) -&gt; Well:\n        \"\"\"Generate Well metadata from field names.\n\n        Parameters\n        ----------\n        well_path : str\n            Well path like \"A/1\"\n        field_names : list[str]\n            List of field of view identifiers like [\"0\", \"1\"]\n\n        Returns\n        -------\n        Well\n            Well metadata with images list populated.\n        \"\"\"\n        # Auto-generate Well metadata\n        # Sort field_names for consistent ordering\n        images = [\n            FieldOfView(path=fov, acquisition=None) for fov in sorted(field_names)\n        ]\n\n        return Well(well=WellDef(images=images))\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.PlateBuilder.root_path","title":"<code>root_path</code>  <code>property</code>","text":"<p>Path to the root of the plate hierarchy.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.PlateBuilder.write_well","title":"<code>write_well(row, col, images, *, progress=False)</code>","text":"<p>Write a well immediately with its <code>images</code> (fields of view) and data.</p> <p>This method creates the well structure and writes all field data in one call. The plate structure and well metadata are created/updated automatically. Plate metadata (rows, columns, wells) is auto-generated from all written wells and rewritten after each call.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>str</code> <p>Row name like \"A\", \"B\", etc.</p> required <code>col</code> <code>str</code> <p>Column name like \"1\", \"2\", etc.</p> required <code>images</code> <code>Mapping[str, ImageWithDatasets]</code> <p>Mapping of <code>{fov -&gt; (image_model, datasets)}</code> where: - fov: Field of view identifier like \"0\", \"1\", etc. - datasets can be:   - Single array (for one dataset): <code>{\"0\": (image, data)}</code>   - Sequence (for multiple datasets): <code>{\"0\": (image, [data1, data2])}</code></p> required <code>progress</code> <code>bool</code> <p>Show progress bar for dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If row/col combination was already written or added, or if a user- provided Plate doesn't include this well.</p> <code>NotImplementedError</code> <p>If any Image has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_well(\n    self,\n    row: str,\n    col: str,\n    images: Mapping[str, ImageWithDatasets],\n    *,\n    progress: bool = False,\n) -&gt; Self:\n    \"\"\"Write a well immediately with its `images` (fields of view) and data.\n\n    This method creates the well structure and writes all field data in one\n    call. The plate structure and well metadata are created/updated\n    automatically. Plate metadata (rows, columns, wells) is auto-generated\n    from all written wells and rewritten after each call.\n\n    Parameters\n    ----------\n    row : str\n        Row name like \"A\", \"B\", etc.\n    col : str\n        Column name like \"1\", \"2\", etc.\n    images : Mapping[str, ImageWithDatasets]\n        Mapping of `{fov -&gt; (image_model, datasets)}` where:\n        - fov: Field of view identifier like \"0\", \"1\", etc.\n        - datasets can be:\n          - Single array (for one dataset): `{\"0\": (image, data)}`\n          - Sequence (for multiple datasets): `{\"0\": (image, [data1, data2])}`\n    progress : bool, optional\n        Show progress bar for dask arrays. Default is False.\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If row/col combination was already written or added, or if a user-\n        provided Plate doesn't include this well.\n    NotImplementedError\n        If any Image has multiple multiscales.\n    \"\"\"\n    # Validate well hasn't been used\n    self._validate_well_coordinates(row, col)\n\n    # Initialize plate structure if needed\n    self._ensure_initialized()\n\n    # Normalize fields (convert single arrays to sequences)\n    normalized_fields: dict[str, tuple[Image, Sequence[ArrayLike]]] = {}\n    for fov, (image_model, datasets) in images.items():\n        _, datasets_seq = _validate_and_normalize_datasets(\n            image_model, datasets, f\"Well '{row}/{col}', field '{fov}': \"\n        )\n        normalized_fields[fov] = (image_model, datasets_seq)\n\n    # Track this well's data before writing\n    self._written_wells_data[(row, col)] = cast(\n        \"dict[str, ImageWithDatasets]\", normalized_fields\n    )\n\n    # Update plate metadata with the new well\n    self._update_plate_metadata()\n\n    # Generate Well metadata for this well and create well subgroup\n    well_group_path = self._dest / f\"{row}/{col}\"\n    well_metadata = self._generate_well_metadata(list(images))\n    _create_zarr3_group(well_group_path, well_metadata, self._overwrite)\n\n    # Write each field of view\n    for fov, (image_model, datasets_seq) in normalized_fields.items():\n        field_path = well_group_path / fov\n        write_image(\n            field_path,\n            image_model,\n            datasets_seq,\n            writer=self._writer,\n            chunks=self._chunks,\n            shards=self._shards,\n            overwrite=self._overwrite,\n            compression=self._compression,\n            progress=progress,\n        )\n\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.PlateBuilder.add_well","title":"<code>add_well(*, row, col, images)</code>","text":"<p>Add a well for the prepare-only workflow.</p> <p>Registers a well with its fields to be created when <code>prepare()</code> is called. Use this when you want to create the Zarr structure without writing data immediately. After calling <code>prepare()</code>, write data to the returned array handles.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>str</code> <p>Row name like \"A\", \"B\", etc.</p> required <code>col</code> <code>str</code> <p>Column name like \"1\", \"2\", etc.</p> required <code>images</code> <code>Mapping[str, ImageWithShapeSpecs]</code> <p>Mapping of <code>{fov -&gt; (image_model, specs)}</code> where specs provide the dtype and shape for each resolution level: - Single level: <code>(image, (shape, dtype))</code> - Multiple levels: <code>(image, [(shape1, dtype1), (shape2, dtype2)])</code></p> required <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If row/col combination was already added/written, or if a user- provided Plate doesn't include this well, or if field specs don't match Image metadata.</p> <code>NotImplementedError</code> <p>If any Image has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def add_well(\n    self,\n    *,\n    row: str,\n    col: str,\n    images: Mapping[str, ImageWithShapeSpecs],\n) -&gt; Self:\n    \"\"\"Add a well for the prepare-only workflow.\n\n    Registers a well with its fields to be created when `prepare()` is called.\n    Use this when you want to create the Zarr structure without writing data\n    immediately. After calling `prepare()`, write data to the returned array\n    handles.\n\n    Parameters\n    ----------\n    row : str\n        Row name like \"A\", \"B\", etc.\n    col : str\n        Column name like \"1\", \"2\", etc.\n    images : Mapping[str, ImageWithShapeSpecs]\n        Mapping of `{fov -&gt; (image_model, specs)}` where specs provide the\n        dtype and shape for each resolution level:\n        - Single level: `(image, (shape, dtype))`\n        - Multiple levels: `(image, [(shape1, dtype1), (shape2, dtype2)])`\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If row/col combination was already added/written, or if a user-\n        provided Plate doesn't include this well, or if field specs\n        don't match Image metadata.\n    NotImplementedError\n        If any Image has multiple multiscales.\n    \"\"\"\n    # Validate well hasn't been used\n    self._validate_well_coordinates(row, col)\n\n    # Validate and normalize all fields before accepting\n    well_path = f\"{row}/{col}\"\n    normalized_fields: dict[str, ImageWithShapeSpecs] = {}\n\n    for fov, (image_model, specs) in images.items():\n        _, specs_seq = _validate_and_normalize_datasets(\n            image_model, specs, f\"Well '{well_path}', field '{fov}': \"\n        )\n        normalized_fields[fov] = (image_model, specs_seq)\n\n    self._wells[well_path] = normalized_fields\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.PlateBuilder.prepare","title":"<code>prepare()</code>","text":"<p>Create the Zarr hierarchy and return array handles.</p> <p>Creates the complete Plate structure including plate metadata (auto- generated from registered wells), well subgroups with Well metadata, and empty arrays for all registered fields. Call this after registering all wells with <code>add_well()</code>.</p> <p>The returned arrays support numpy-style indexing for writing data: <code>arrays[\"well/field/dataset\"][:] = data</code>.</p> <p>Returns:</p> Type Description <code>tuple[Path, dict[str, Any]]</code> <p>A tuple of (root_path, arrays) where <code>arrays</code> maps composite keys like <code>\"A/1/0/0\"</code> (well_path / field / dataset_path) to array objects. The array type depends on the configured writer (zarr.Array or tensorstore.TensorStore).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no wells have been added with <code>add_well()</code>.</p> <code>FileExistsError</code> <p>If destination exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n    \"\"\"Create the Zarr hierarchy and return array handles.\n\n    Creates the complete Plate structure including plate metadata (auto-\n    generated from registered wells), well subgroups with Well metadata,\n    and empty arrays for all registered fields. Call this after registering\n    all wells with `add_well()`.\n\n    The returned arrays support numpy-style indexing for writing data:\n    `arrays[\"well/field/dataset\"][:] = data`.\n\n    Returns\n    -------\n    tuple[Path, dict[str, Any]]\n        A tuple of (root_path, arrays) where `arrays` maps composite keys\n        like `\"A/1/0/0\"` (well_path / field / dataset_path) to array\n        objects. The array type depends on the configured writer\n        (zarr.Array or tensorstore.TensorStore).\n\n    Raises\n    ------\n    ValueError\n        If no wells have been added with `add_well()`.\n    FileExistsError\n        If destination exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n    \"\"\"\n    if not self._wells:\n        raise ValueError(\"No wells added. Use add_well() before prepare().\")\n\n    # Generate plate metadata from registered wells\n    plate = _merge_plate_metadata(self._get_images_dict(), self._user_plate)\n\n    # Create plate zarr.json\n    _create_zarr3_group(self._dest, plate, self._overwrite)\n\n    # Create arrays for each well/field combination\n    all_arrays: dict[str, Any] = {}\n\n    for well_path, fields in self._wells.items():\n        # Generate Well metadata and group\n        well_metadata = self._generate_well_metadata(list(fields))\n        well_group_path = self._dest / well_path\n        _create_zarr3_group(well_group_path, well_metadata, self._overwrite)\n\n        # Create arrays for each field\n        for fov, (image_model, datasets) in fields.items():\n            field_path = well_group_path / fov\n\n            _field_path, field_arrays = prepare_image(\n                field_path,\n                image_model,\n                datasets,\n                chunks=self._chunks,\n                shards=self._shards,\n                writer=self._writer,\n                overwrite=self._overwrite,\n                compression=self._compression,\n            )\n\n            # Flatten into all_arrays with \"well/field/dataset\" keys\n            for dataset_path, arr in field_arrays.items():\n                composite_key = f\"{well_path}/{fov}/{dataset_path}\"\n                all_arrays[composite_key] = arr\n\n    return self._dest, all_arrays\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.Bf2RawBuilder","title":"<code>Bf2RawBuilder</code>","text":"<p>Builder for bioformats2raw layout hierarchies.</p> <p>The bioformats2raw layout is a convention for storing multiple OME-Zarr images in a single hierarchy. It includes:</p> <ul> <li>A root group with <code>bioformats2raw.layout</code> version attribute</li> <li>An <code>OME/</code> subgroup listing all series names</li> <li>Each series as a separate Image subgroup (e.g., <code>0/</code>, <code>1/</code>)</li> <li>Optional <code>OME/METADATA.ome.xml</code> with full OME-XML metadata</li> </ul> <p>This builder supports two workflows:</p> <ol> <li> <p>Immediate write (simpler): Use <code>write_image()</code> to write each series    with its data immediately. The builder manages root structure and series    list automatically.</p> </li> <li> <p>Prepare-only (flexible): Use <code>add_series()</code> to register all series,    then <code>prepare()</code> to create the hierarchy with empty arrays. Write data    to the returned arrays yourself.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the root Zarr group.</p> required <code>ome_xml</code> <code>str | None</code> <p>Original OME-XML string to store as <code>OME/METADATA.ome.xml</code>.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays. Default is \"auto\".</p> <code>'auto'</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for all arrays. Default is \"auto\".</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing groups. Default is False. Note: existing directories that don't look like zarr groups will NOT be removed, an exception will be raised instead.</p> <code>False</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <p>Examples:</p> <p>Immediate write workflow:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import Bf2RawBuilder\n&gt;&gt;&gt; def make_image():\n...     return v05.Image(\n...         multiscales=[\n...             v05.Multiscale(\n...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n...                 datasets=[\n...                     v05.Dataset(\n...                         path=\"0\",\n...                         coordinateTransformations=[\n...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n...                         ],\n...                     )\n...                 ],\n...             )\n...         ]\n...     )\n&gt;&gt;&gt; builder = Bf2RawBuilder(\"builder_immediate.zarr\")\n&gt;&gt;&gt; builder.write_image(\"0\", make_image(), np.zeros((32, 32), dtype=np.uint16))\n&lt;Bf2RawBuilder: 1 images&gt;\n&gt;&gt;&gt; builder.write_image(\"1\", make_image(), np.zeros((16, 16), dtype=np.uint16))\n&lt;Bf2RawBuilder: 2 images&gt;\n&gt;&gt;&gt; assert (builder.root_path / \"0\" / \"zarr.json\").exists()\n</code></pre> <p>Prepare-only workflow:</p> <pre><code>&gt;&gt;&gt; builder2 = Bf2RawBuilder(\"builder_prepare.zarr\")\n&gt;&gt;&gt; builder2.add_series(\"0\", make_image(), ((32, 32), np.uint16))  # shape, dtype\n&lt;Bf2RawBuilder: 1 images&gt;\n&gt;&gt;&gt; builder2.add_series(\"1\", make_image(), ((16, 16), np.uint16))\n&lt;Bf2RawBuilder: 2 images&gt;\n&gt;&gt;&gt; path, arrays = builder2.prepare()\n&gt;&gt;&gt; arrays[\"0/0\"][:] = np.zeros((32, 32), dtype=np.uint16)  # Write data yourself\n&gt;&gt;&gt; arrays[\"1/0\"][:] = np.zeros((16, 16), dtype=np.uint16)\n&gt;&gt;&gt; assert path.exists()\n</code></pre> See Also <p>write_bioformats2raw : High-level function to write all series at once.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>class Bf2RawBuilder:\n    \"\"\"Builder for bioformats2raw layout hierarchies.\n\n    The bioformats2raw layout is a convention for storing multiple OME-Zarr\n    images in a single hierarchy. It includes:\n\n    - A root group with `bioformats2raw.layout` version attribute\n    - An `OME/` subgroup listing all series names\n    - Each series as a separate Image subgroup (e.g., `0/`, `1/`)\n    - Optional `OME/METADATA.ome.xml` with full OME-XML metadata\n\n    This builder supports two workflows:\n\n    1. **Immediate write** (simpler): Use `write_image()` to write each series\n       with its data immediately. The builder manages root structure and series\n       list automatically.\n\n    2. **Prepare-only** (flexible): Use `add_series()` to register all series,\n       then `prepare()` to create the hierarchy with empty arrays. Write data\n       to the returned arrays yourself.\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the root Zarr group.\n    ome_xml : str | None, optional\n        Original OME-XML string to store as `OME/METADATA.ome.xml`.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays. Default is \"auto\".\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for all arrays. Default is \"auto\".\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    overwrite : bool, optional\n        If True, overwrite existing groups. Default is False.\n        Note: existing directories that don't look like zarr groups will NOT be removed,\n        an exception will be raised instead.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n\n    Examples\n    --------\n    **Immediate write workflow:**\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import Bf2RawBuilder\n    &gt;&gt;&gt; def make_image():\n    ...     return v05.Image(\n    ...         multiscales=[\n    ...             v05.Multiscale(\n    ...                 axes=[v05.SpaceAxis(name=\"y\"), v05.SpaceAxis(name=\"x\")],\n    ...                 datasets=[\n    ...                     v05.Dataset(\n    ...                         path=\"0\",\n    ...                         coordinateTransformations=[\n    ...                             v05.ScaleTransformation(scale=[1.0, 1.0])\n    ...                         ],\n    ...                     )\n    ...                 ],\n    ...             )\n    ...         ]\n    ...     )\n    &gt;&gt;&gt; builder = Bf2RawBuilder(\"builder_immediate.zarr\")\n    &gt;&gt;&gt; builder.write_image(\"0\", make_image(), np.zeros((32, 32), dtype=np.uint16))\n    &lt;Bf2RawBuilder: 1 images&gt;\n    &gt;&gt;&gt; builder.write_image(\"1\", make_image(), np.zeros((16, 16), dtype=np.uint16))\n    &lt;Bf2RawBuilder: 2 images&gt;\n    &gt;&gt;&gt; assert (builder.root_path / \"0\" / \"zarr.json\").exists()\n\n    **Prepare-only workflow:**\n\n    &gt;&gt;&gt; builder2 = Bf2RawBuilder(\"builder_prepare.zarr\")\n    &gt;&gt;&gt; builder2.add_series(\"0\", make_image(), ((32, 32), np.uint16))  # shape, dtype\n    &lt;Bf2RawBuilder: 1 images&gt;\n    &gt;&gt;&gt; builder2.add_series(\"1\", make_image(), ((16, 16), np.uint16))\n    &lt;Bf2RawBuilder: 2 images&gt;\n    &gt;&gt;&gt; path, arrays = builder2.prepare()\n    &gt;&gt;&gt; arrays[\"0/0\"][:] = np.zeros((32, 32), dtype=np.uint16)  # Write data yourself\n    &gt;&gt;&gt; arrays[\"1/0\"][:] = np.zeros((16, 16), dtype=np.uint16)\n    &gt;&gt;&gt; assert path.exists()\n\n    See Also\n    --------\n    write_bioformats2raw : High-level function to write all series at once.\n    \"\"\"\n\n    def __init__(\n        self,\n        dest: str | PathLike,\n        *,\n        ome_xml: str | None = None,\n        writer: ZarrWriter = \"auto\",\n        chunks: ShapeLike | Literal[\"auto\"] | None = \"auto\",\n        shards: ShapeLike | None = None,\n        overwrite: bool = False,\n        compression: CompressionName = \"blosc-zstd\",\n    ) -&gt; None:\n        self._dest = Path(dest)\n        self._ome_xml = ome_xml\n        self._writer: ZarrWriter = writer\n        self._chunks: ShapeLike | Literal[\"auto\"] | None = chunks\n        self._shards = shards\n        self._overwrite = overwrite\n        self._compression: CompressionName = compression\n        self._indent = 2\n\n        # For prepare-only workflow: {series_name: (image, dataset_specs)}\n        self._series: dict[str, ImageWithShapeSpecs] = {}\n\n        # For immediate write workflow\n        self._initialized = False\n        self._written_series: list[str] = []\n\n    @property\n    def root_path(self) -&gt; Path:\n        \"\"\"Path to the root of the bioformats2raw hierarchy.\"\"\"\n        return self._dest\n\n    def write_image(\n        self,\n        name: str,\n        image: Image,\n        datasets: ArrayOrPyramid,\n        *,\n        progress: bool = False,\n    ) -&gt; Self:\n        \"\"\"Write a series immediately with its data.\n\n        This method creates the series structure and writes data in one call.\n        The root structure and OME metadata are created/updated automatically.\n        Use this for the \"immediate write\" workflow.\n\n        Parameters\n        ----------\n        name : str\n            Series name (becomes the subgroup path, e.g., \"0\", \"1\").\n        image : Image\n            OME-Zarr Image metadata model for this series.\n        datasets : ArrayLike | Sequence[ArrayLike]\n            Data array(s) for each resolution level. For a single dataset,\n            pass the array directly without wrapping in a list.\n        progress : bool, optional\n            Show progress bar when writing dask arrays. Default is False.\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If a series with this name was already written or added.\n        NotImplementedError\n            If the Image has multiple multiscales.\n        \"\"\"\n        self._validate_series_name(name)\n\n        # Initialize root structure if needed\n        self._ensure_initialized()\n\n        # Update OME/zarr.json with this series\n        self._update_ome_series(name)\n\n        # Write the series using the existing write_image function\n        write_image(\n            self._dest / name,\n            image,\n            datasets,\n            writer=self._writer,\n            chunks=self._chunks,\n            shards=self._shards,\n            overwrite=self._overwrite,\n            compression=self._compression,\n            progress=progress,\n        )\n\n        return self\n\n    def add_series(\n        self,\n        name: str,\n        image: Image,\n        datasets: ShapeAndDTypeOrPyramid,\n    ) -&gt; Self:\n        \"\"\"Add a series for the prepare-only workflow.\n\n        Registers a series to be created when `prepare()` is called. Use this\n        when you want to create the Zarr structure without writing data\n        immediately. After calling `prepare()`, write data to the returned\n        array handles.\n\n        Parameters\n        ----------\n        name : str\n            Series name (becomes the subgroup path, e.g., \"0\", \"1\").\n        image : Image\n            OME-Zarr Image metadata model for this series.\n        datasets : ShapeAndDType | Sequence[ShapeAndDType]\n            Shape and dtype specification(s) for each resolution level, as\n            `(shape, dtype)` tuples. For a single dataset, pass the tuple\n            directly without wrapping in a list.\n\n        Returns\n        -------\n        Self\n            The builder instance (for method chaining).\n\n        Raises\n        ------\n        ValueError\n            If a series with this name was already added or written, or if the\n            number of dataset specs doesn't match the metadata.\n        NotImplementedError\n            If the Image has multiple multiscales.\n        \"\"\"\n        self._validate_series_name(name)\n        _, datasets_seq = _validate_and_normalize_datasets(\n            image, datasets, f\"Series '{name}': \"\n        )\n        self._series[name] = (image, datasets_seq)\n        return self\n\n    def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n        \"\"\"Create the Zarr hierarchy and return array handles.\n\n        Creates the complete bioformats2raw structure including root metadata,\n        OME directory with series list, and empty arrays for all registered\n        series. Call this after registering all series with `add_series()`.\n\n        The returned arrays support numpy-style indexing for writing data:\n        `arrays[\"series/dataset\"][:] = data`.\n\n        Returns\n        -------\n        tuple[Path, dict[str, Any]]\n            A tuple of (root_path, arrays) where `arrays` maps composite keys\n            like `\"0/0\"` (series name / dataset path) to array objects. The\n            array type depends on the configured writer (zarr.Array or\n            tensorstore.TensorStore).\n\n        Raises\n        ------\n        ValueError\n            If no series have been added with `add_series()`.\n        FileExistsError\n            If destination exists and `overwrite` is False.\n        ImportError\n            If no suitable writer backend is installed.\n        \"\"\"\n        if not self._series:  # pragma: no cover\n            raise ValueError(\"No series added. Use add_series() before prepare().\")\n\n        # Create root zarr.json with bioformats2raw.layout\n        bf2raw = Bf2Raw(bioformats2raw_layout=3)  # type: ignore\n        _create_zarr3_group(self._dest, bf2raw, self._overwrite)\n\n        # Create OME/zarr.json with series list\n        ome_path = self._dest / \"OME\"\n        series_model = Series(series=list(self._series))\n        _create_zarr3_group(ome_path, series_model, self._overwrite)\n\n        # Write METADATA.ome.xml if provided\n        if self._ome_xml is not None:\n            (ome_path / \"METADATA.ome.xml\").write_text(self._ome_xml)\n\n        # Create arrays for each series using prepare_image\n        all_arrays: dict[str, Any] = {}\n        for series_name, (image_model, dataset_specs) in self._series.items():\n            _root_path, series_arrays = prepare_image(\n                self._dest / series_name,\n                image_model,\n                dataset_specs,\n                chunks=self._chunks,\n                shards=self._shards,\n                writer=self._writer,\n                overwrite=self._overwrite,\n                compression=self._compression,\n            )\n            # Flatten into all_arrays with \"series/dataset\" keys\n            for dataset_path, arr in series_arrays.items():\n                all_arrays[f\"{series_name}/{dataset_path}\"] = arr\n\n        return self._dest, all_arrays\n\n    def __repr__(self) -&gt; str:\n        total_images = len(self._series) + len(self._written_series)\n        return f\"&lt;{self.__class__.__name__}: {total_images} images&gt;\"\n\n    # ------------------------ Internal Methods --------------------------\n\n    def _validate_series_name(self, name: str) -&gt; None:\n        if name in self._written_series:\n            raise ValueError(f\"Series '{name}' already written via write_image().\")\n        if name in self._series:\n            raise ValueError(f\"Series '{name}' already added via add_series().\")\n\n    def _ensure_initialized(self) -&gt; None:\n        \"\"\"Create root structure if not already done.\"\"\"\n        if self._initialized:\n            return\n\n        # Create root zarr.json with bioformats2raw.layout\n        bf2raw = Bf2Raw(bioformats2raw_layout=3)  # type: ignore\n        _create_zarr3_group(self._dest, bf2raw, self._overwrite)\n\n        # Create OME directory and write METADATA.ome.xml if provided\n        ome_path = self._dest / \"OME\"\n        ome_path.mkdir(parents=True, exist_ok=True)\n        if self._ome_xml is not None:\n            (ome_path / \"METADATA.ome.xml\").write_text(self._ome_xml)\n\n        self._initialized = True\n\n    def _update_ome_series(self, series_name: str) -&gt; None:\n        \"\"\"Update OME/zarr.json with new series name.\"\"\"\n        if series_name in self._written_series:\n            # already added ... this is an internal method, don't need to raise\n            return  # pragma: no cover\n\n        self._written_series.append(series_name)\n        series_model = Series(series=self._written_series)\n        zarr_json = {\n            \"zarr_format\": 3,\n            \"node_type\": \"group\",\n            \"attributes\": {\n                \"ome\": series_model.model_dump(mode=\"json\", exclude_none=True),\n            },\n        }\n        (self._dest / \"OME\" / \"zarr.json\").write_text(\n            json.dumps(zarr_json, indent=self._indent)\n        )\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.Bf2RawBuilder.root_path","title":"<code>root_path</code>  <code>property</code>","text":"<p>Path to the root of the bioformats2raw hierarchy.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.Bf2RawBuilder.write_image","title":"<code>write_image(name, image, datasets, *, progress=False)</code>","text":"<p>Write a series immediately with its data.</p> <p>This method creates the series structure and writes data in one call. The root structure and OME metadata are created/updated automatically. Use this for the \"immediate write\" workflow.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Series name (becomes the subgroup path, e.g., \"0\", \"1\").</p> required <code>image</code> <code>Image</code> <p>OME-Zarr Image metadata model for this series.</p> required <code>datasets</code> <code>ArrayLike | Sequence[ArrayLike]</code> <p>Data array(s) for each resolution level. For a single dataset, pass the array directly without wrapping in a list.</p> required <code>progress</code> <code>bool</code> <p>Show progress bar when writing dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a series with this name was already written or added.</p> <code>NotImplementedError</code> <p>If the Image has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_image(\n    self,\n    name: str,\n    image: Image,\n    datasets: ArrayOrPyramid,\n    *,\n    progress: bool = False,\n) -&gt; Self:\n    \"\"\"Write a series immediately with its data.\n\n    This method creates the series structure and writes data in one call.\n    The root structure and OME metadata are created/updated automatically.\n    Use this for the \"immediate write\" workflow.\n\n    Parameters\n    ----------\n    name : str\n        Series name (becomes the subgroup path, e.g., \"0\", \"1\").\n    image : Image\n        OME-Zarr Image metadata model for this series.\n    datasets : ArrayLike | Sequence[ArrayLike]\n        Data array(s) for each resolution level. For a single dataset,\n        pass the array directly without wrapping in a list.\n    progress : bool, optional\n        Show progress bar when writing dask arrays. Default is False.\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If a series with this name was already written or added.\n    NotImplementedError\n        If the Image has multiple multiscales.\n    \"\"\"\n    self._validate_series_name(name)\n\n    # Initialize root structure if needed\n    self._ensure_initialized()\n\n    # Update OME/zarr.json with this series\n    self._update_ome_series(name)\n\n    # Write the series using the existing write_image function\n    write_image(\n        self._dest / name,\n        image,\n        datasets,\n        writer=self._writer,\n        chunks=self._chunks,\n        shards=self._shards,\n        overwrite=self._overwrite,\n        compression=self._compression,\n        progress=progress,\n    )\n\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.Bf2RawBuilder.add_series","title":"<code>add_series(name, image, datasets)</code>","text":"<p>Add a series for the prepare-only workflow.</p> <p>Registers a series to be created when <code>prepare()</code> is called. Use this when you want to create the Zarr structure without writing data immediately. After calling <code>prepare()</code>, write data to the returned array handles.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Series name (becomes the subgroup path, e.g., \"0\", \"1\").</p> required <code>image</code> <code>Image</code> <p>OME-Zarr Image metadata model for this series.</p> required <code>datasets</code> <code>ShapeAndDType | Sequence[ShapeAndDType]</code> <p>Shape and dtype specification(s) for each resolution level, as <code>(shape, dtype)</code> tuples. For a single dataset, pass the tuple directly without wrapping in a list.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The builder instance (for method chaining).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a series with this name was already added or written, or if the number of dataset specs doesn't match the metadata.</p> <code>NotImplementedError</code> <p>If the Image has multiple multiscales.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def add_series(\n    self,\n    name: str,\n    image: Image,\n    datasets: ShapeAndDTypeOrPyramid,\n) -&gt; Self:\n    \"\"\"Add a series for the prepare-only workflow.\n\n    Registers a series to be created when `prepare()` is called. Use this\n    when you want to create the Zarr structure without writing data\n    immediately. After calling `prepare()`, write data to the returned\n    array handles.\n\n    Parameters\n    ----------\n    name : str\n        Series name (becomes the subgroup path, e.g., \"0\", \"1\").\n    image : Image\n        OME-Zarr Image metadata model for this series.\n    datasets : ShapeAndDType | Sequence[ShapeAndDType]\n        Shape and dtype specification(s) for each resolution level, as\n        `(shape, dtype)` tuples. For a single dataset, pass the tuple\n        directly without wrapping in a list.\n\n    Returns\n    -------\n    Self\n        The builder instance (for method chaining).\n\n    Raises\n    ------\n    ValueError\n        If a series with this name was already added or written, or if the\n        number of dataset specs doesn't match the metadata.\n    NotImplementedError\n        If the Image has multiple multiscales.\n    \"\"\"\n    self._validate_series_name(name)\n    _, datasets_seq = _validate_and_normalize_datasets(\n        image, datasets, f\"Series '{name}': \"\n    )\n    self._series[name] = (image, datasets_seq)\n    return self\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.Bf2RawBuilder.prepare","title":"<code>prepare()</code>","text":"<p>Create the Zarr hierarchy and return array handles.</p> <p>Creates the complete bioformats2raw structure including root metadata, OME directory with series list, and empty arrays for all registered series. Call this after registering all series with <code>add_series()</code>.</p> <p>The returned arrays support numpy-style indexing for writing data: <code>arrays[\"series/dataset\"][:] = data</code>.</p> <p>Returns:</p> Type Description <code>tuple[Path, dict[str, Any]]</code> <p>A tuple of (root_path, arrays) where <code>arrays</code> maps composite keys like <code>\"0/0\"</code> (series name / dataset path) to array objects. The array type depends on the configured writer (zarr.Array or tensorstore.TensorStore).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no series have been added with <code>add_series()</code>.</p> <code>FileExistsError</code> <p>If destination exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def prepare(self) -&gt; tuple[Path, dict[str, Any]]:\n    \"\"\"Create the Zarr hierarchy and return array handles.\n\n    Creates the complete bioformats2raw structure including root metadata,\n    OME directory with series list, and empty arrays for all registered\n    series. Call this after registering all series with `add_series()`.\n\n    The returned arrays support numpy-style indexing for writing data:\n    `arrays[\"series/dataset\"][:] = data`.\n\n    Returns\n    -------\n    tuple[Path, dict[str, Any]]\n        A tuple of (root_path, arrays) where `arrays` maps composite keys\n        like `\"0/0\"` (series name / dataset path) to array objects. The\n        array type depends on the configured writer (zarr.Array or\n        tensorstore.TensorStore).\n\n    Raises\n    ------\n    ValueError\n        If no series have been added with `add_series()`.\n    FileExistsError\n        If destination exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n    \"\"\"\n    if not self._series:  # pragma: no cover\n        raise ValueError(\"No series added. Use add_series() before prepare().\")\n\n    # Create root zarr.json with bioformats2raw.layout\n    bf2raw = Bf2Raw(bioformats2raw_layout=3)  # type: ignore\n    _create_zarr3_group(self._dest, bf2raw, self._overwrite)\n\n    # Create OME/zarr.json with series list\n    ome_path = self._dest / \"OME\"\n    series_model = Series(series=list(self._series))\n    _create_zarr3_group(ome_path, series_model, self._overwrite)\n\n    # Write METADATA.ome.xml if provided\n    if self._ome_xml is not None:\n        (ome_path / \"METADATA.ome.xml\").write_text(self._ome_xml)\n\n    # Create arrays for each series using prepare_image\n    all_arrays: dict[str, Any] = {}\n    for series_name, (image_model, dataset_specs) in self._series.items():\n        _root_path, series_arrays = prepare_image(\n            self._dest / series_name,\n            image_model,\n            dataset_specs,\n            chunks=self._chunks,\n            shards=self._shards,\n            writer=self._writer,\n            overwrite=self._overwrite,\n            compression=self._compression,\n        )\n        # Flatten into all_arrays with \"series/dataset\" keys\n        for dataset_path, arr in series_arrays.items():\n            all_arrays[f\"{series_name}/{dataset_path}\"] = arr\n\n    return self._dest, all_arrays\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.write_image","title":"<code>write_image(dest, image, datasets, *, labels=None, writer='auto', overwrite=False, chunks='auto', shards=None, compression='blosc-zstd', progress=False)</code>","text":"<p>Write an OME-Zarr v0.5 Image group with data.</p> <p>This is the high-level function for writing a complete OME-Zarr image. It creates the Zarr group hierarchy, writes metadata, and stores data in a single call.</p> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the Zarr group. Will be created if it doesn't exist.</p> required <code>image</code> <code>Image</code> <p>OME-Zarr Image metadata model. Must have exactly one multiscale, with one Dataset entry per array in <code>datasets</code>.</p> required <code>datasets</code> <code>ArrayOrPyramid</code> <p>Data array(s) to write (numpy, dask, or any array with shape/dtype). - For a single dataset, pass the array directly:   <code>write_image(dest, image, data)</code> - For multiple datasets (e.g., multiscale pyramid), pass a sequence:   <code>write_image(dest, image, [data0, data1, ...])</code> Must match the number and order of <code>image.multiscales[0].datasets</code>.</p> required <code>labels</code> <code>Mapping[str, tuple[LabelImage, ArrayOrPyramid]] | None</code> <p>Optional label images to write alongside the image. Keys are label names (e.g., \"cells\", \"nuclei\"), values are (LabelImage, datasets) tuples. Labels will be written to <code>dest/labels/{name}/</code>. Default is None.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays. \"auto\" prefers tensorstore if available, otherwise falls back to zarr-python. Pass a custom function matching the <code>CreateArrayFunc</code> protocol for custom backends.</p> <code>'auto'</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing Zarr group at <code>dest</code>. Default is False.</p> <code>False</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for storage. \"auto\" (default) calculates ~4MB chunks with non-spatial dims set to 1. None uses the full array shape (single chunk). Tuple values are clamped to the array shape.</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. \"blosc-zstd\" (default) provides good compression with shuffle filter. \"zstd\" uses raw zstd without blosc container.</p> <code>'blosc-zstd'</code> <code>progress</code> <code>bool</code> <p>Show progress bar when writing dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created Zarr group.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the Image model has multiple multiscales (not yet supported).</p> <code>ValueError</code> <p>If the number of datasets doesn't match the metadata.</p> <code>FileExistsError</code> <p>If <code>dest</code> exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> <p>Examples:</p> <p>Write a simple 3D image (CYX) - single dataset:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import write_image\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = np.zeros((2, 64, 64), dtype=np.uint16)\n&gt;&gt;&gt; image = v05.Image(\n...     multiscales=[\n...         v05.Multiscale(\n...             axes=[\n...                 v05.ChannelAxis(name=\"c\"),\n...                 v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n...                 v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n...             ],\n...             datasets=[\n...                 v05.Dataset(\n...                     path=\"0\",\n...                     coordinateTransformations=[\n...                         v05.ScaleTransformation(scale=[1.0, 0.5, 0.5])\n...                     ],\n...                 )\n...             ],\n...         )\n...     ]\n... )\n&gt;&gt;&gt; result = write_image(\"example.ome.zarr\", image, data)\n&gt;&gt;&gt; assert result.exists()\n</code></pre> <p>Write a 3D image (CYX) with associated labels:</p> <pre><code>&gt;&gt;&gt; # Create label images for segmentation\n&gt;&gt;&gt; cells_label = v05.LabelImage(\n...     **image.model_dump(),\n...     image_label={\"colors\": [{\"label_value\": 1, \"rgba\": [255, 0, 0, 255]}]},\n... )\n&gt;&gt;&gt; cells_data = np.zeros((2, 64, 64), dtype=np.uint8)\n&gt;&gt;&gt; nuclei_label = v05.LabelImage(**image.model_dump(), image_label={})\n&gt;&gt;&gt; nuclei_data = np.zeros((2, 64, 64), dtype=np.uint8)\n&gt;&gt;&gt; result = write_image(\n...     \"example.ome.zarr\",\n...     image,\n...     data,\n...     labels={\n...         \"cells\": (cells_label, cells_data),\n...         \"nuclei\": (nuclei_label, nuclei_data),\n...     },\n...     overwrite=True,\n... )\n&gt;&gt;&gt; assert (result / \"labels\" / \"cells\" / \"0\" / \"zarr.json\").exists()\n</code></pre> See Also <p>prepare_image : Create arrays without writing data (for custom write logic). write_bioformats2raw : Write multi-series bioformats2raw layout.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_image(\n    dest: str | PathLike,\n    image: Image,\n    datasets: ArrayOrPyramid,\n    *,\n    labels: Mapping[str, tuple[LabelImage, ArrayOrPyramid]] | None = None,\n    writer: ZarrWriter = \"auto\",\n    overwrite: bool = False,\n    chunks: tuple[int, ...] | Literal[\"auto\"] | None = \"auto\",\n    shards: tuple[int, ...] | None = None,\n    compression: CompressionName = \"blosc-zstd\",\n    progress: bool = False,\n) -&gt; Path:\n    \"\"\"Write an OME-Zarr v0.5 Image group with data.\n\n    This is the high-level function for writing a complete OME-Zarr image.\n    It creates the Zarr group hierarchy, writes metadata, and stores data\n    in a single call.\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the Zarr group. Will be created if it doesn't exist.\n    image : Image\n        OME-Zarr Image metadata model. Must have exactly one multiscale, with\n        one Dataset entry per array in `datasets`.\n    datasets : ArrayOrPyramid\n        Data array(s) to write (numpy, dask, or any array with shape/dtype).\n        - For a single dataset, pass the array directly:\n          `write_image(dest, image, data)`\n        - For multiple datasets (e.g., multiscale pyramid), pass a sequence:\n          `write_image(dest, image, [data0, data1, ...])`\n        Must match the number and order of `image.multiscales[0].datasets`.\n    labels : Mapping[str, tuple[LabelImage, ArrayOrPyramid]] | None, optional\n        Optional label images to write alongside the image. Keys are label names\n        (e.g., \"cells\", \"nuclei\"), values are (LabelImage, datasets) tuples.\n        Labels will be written to `dest/labels/{name}/`. Default is None.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays. \"auto\" prefers tensorstore if\n        available, otherwise falls back to zarr-python. Pass a custom function\n        matching the `CreateArrayFunc` protocol for custom backends.\n    overwrite : bool, optional\n        If True, overwrite existing Zarr group at `dest`. Default is False.\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for storage. \"auto\" (default) calculates ~4MB chunks with\n        non-spatial dims set to 1. None uses the full array shape (single chunk).\n        Tuple values are clamped to the array shape.\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. \"blosc-zstd\" (default) provides good compression with\n        shuffle filter. \"zstd\" uses raw zstd without blosc container.\n    progress : bool, optional\n        Show progress bar when writing dask arrays. Default is False.\n\n\n    Returns\n    -------\n    Path\n        Path to the created Zarr group.\n\n    Raises\n    ------\n    NotImplementedError\n        If the Image model has multiple multiscales (not yet supported).\n    ValueError\n        If the number of datasets doesn't match the metadata.\n    FileExistsError\n        If `dest` exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n\n    Examples\n    --------\n    Write a simple 3D image (CYX) - single dataset:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import write_image\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; data = np.zeros((2, 64, 64), dtype=np.uint16)\n    &gt;&gt;&gt; image = v05.Image(\n    ...     multiscales=[\n    ...         v05.Multiscale(\n    ...             axes=[\n    ...                 v05.ChannelAxis(name=\"c\"),\n    ...                 v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    ...                 v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n    ...             ],\n    ...             datasets=[\n    ...                 v05.Dataset(\n    ...                     path=\"0\",\n    ...                     coordinateTransformations=[\n    ...                         v05.ScaleTransformation(scale=[1.0, 0.5, 0.5])\n    ...                     ],\n    ...                 )\n    ...             ],\n    ...         )\n    ...     ]\n    ... )\n    &gt;&gt;&gt; result = write_image(\"example.ome.zarr\", image, data)\n    &gt;&gt;&gt; assert result.exists()\n\n    Write a 3D image (CYX) with associated labels:\n\n    &gt;&gt;&gt; # Create label images for segmentation\n    &gt;&gt;&gt; cells_label = v05.LabelImage(\n    ...     **image.model_dump(),\n    ...     image_label={\"colors\": [{\"label_value\": 1, \"rgba\": [255, 0, 0, 255]}]},\n    ... )\n    &gt;&gt;&gt; cells_data = np.zeros((2, 64, 64), dtype=np.uint8)\n    &gt;&gt;&gt; nuclei_label = v05.LabelImage(**image.model_dump(), image_label={})\n    &gt;&gt;&gt; nuclei_data = np.zeros((2, 64, 64), dtype=np.uint8)\n    &gt;&gt;&gt; result = write_image(\n    ...     \"example.ome.zarr\",\n    ...     image,\n    ...     data,\n    ...     labels={\n    ...         \"cells\": (cells_label, cells_data),\n    ...         \"nuclei\": (nuclei_label, nuclei_data),\n    ...     },\n    ...     overwrite=True,\n    ... )\n    &gt;&gt;&gt; assert (result / \"labels\" / \"cells\" / \"0\" / \"zarr.json\").exists()\n\n    See Also\n    --------\n    prepare_image : Create arrays without writing data (for custom write logic).\n    write_bioformats2raw : Write multi-series bioformats2raw layout.\n    \"\"\"\n    multiscale, datasets_seq = _validate_and_normalize_datasets(image, datasets)\n\n    # Extract specs from arrays for prepare_image\n    specs: list[ShapeAndDType] = [(arr.shape, arr.dtype) for arr in datasets_seq]\n\n    # Create arrays using prepare_image\n    dest_path, arrays = prepare_image(\n        dest,\n        image,\n        specs,\n        chunks=chunks,\n        shards=shards,\n        writer=writer,\n        overwrite=overwrite,\n        compression=compression,\n    )\n\n    # Write data to arrays\n    for data_array, dataset_meta in zip(datasets_seq, multiscale.datasets):\n        _write_to_array(arrays[dataset_meta.path], data_array, progress=progress)\n\n    # Write labels if provided\n    if labels:\n        labels_builder = LabelsBuilder(\n            dest_path / \"labels\",\n            writer=writer,\n            chunks=chunks,\n            shards=shards,\n            overwrite=overwrite,\n            compression=compression,\n        )\n        for label_name, (label_image, label_datasets) in labels.items():\n            labels_builder.write_label(\n                label_name, label_image, label_datasets, progress=progress\n            )\n\n    return dest_path\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.write_plate","title":"<code>write_plate(dest, images, *, plate=None, writer='auto', overwrite=False, chunks='auto', shards=None, compression='blosc-zstd', progress=False)</code>","text":"<p>Write an OME-Zarr v0.5 Plate group with data.</p> <p>This is the high-level function for writing a complete OME-Zarr plate. It creates the plate hierarchy (plate/wells/fields), writes metadata, and stores image data in a single call.</p> <p>The plate structure::</p> <pre><code>dest/\n\u251c\u2500\u2500 zarr.json          # Plate metadata\n\u251c\u2500\u2500 A/\n\u2502   \u251c\u2500\u2500 1/\n\u2502   \u2502   \u251c\u2500\u2500 zarr.json  # Well metadata (auto-generated)\n\u2502   \u2502   \u251c\u2500\u2500 0/         # Field 0\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 zarr.json  # Image metadata\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 0/     # dataset arrays\n\u2502   \u2502   \u2514\u2500\u2500 1/         # Field 1 (if multiple fields)\n\u2502   \u2514\u2500\u2500 2/\n\u2514\u2500\u2500 B/\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the Plate Zarr group.</p> required <code>images</code> <code>Mapping[tuple[str, str, str], ImageWithDatasets]</code> <p>Mapping of <code>{(row, col, fov) -&gt; (image_model, [datasets, ...])}</code>. Each tuple key specifies (row_name, column_name, field_of_view) like (\"A\", \"1\", \"0\"). Row and column names are auto-extracted from the keys.</p> required <code>plate</code> <code>Plate | dict[str, Any] | None</code> <p>Optional plate metadata. Can be: - None (default): Auto-generate from images dict keys - dict: Merge with auto-generated metadata (user values take precedence) - Plate: Use as-is (must match images dict) Common dict keys: 'name', 'acquisitions', 'field_count'. Auto-generated: 'rows', 'columns', 'wells'.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays. Default is \"auto\".</p> <code>'auto'</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing Zarr groups. Default is False.</p> <code>False</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for all arrays. See <code>write_image</code> for details.</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <code>progress</code> <code>bool</code> <p>Show progress bar when writing dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created Plate Zarr group.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If image keys don't match plate wells, or if datasets don't match metadata.</p> <code>FileExistsError</code> <p>If <code>dest</code> exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> <p>Examples:</p> <p>Write a simple 2x2 plate with auto-generated metadata:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import write_plate\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create image metadata (same for all fields)\n&gt;&gt;&gt; def make_image():\n...     return v05.Image(\n...         multiscales=[\n...             v05.Multiscale(\n...                 axes=[\n...                     v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n...                     v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n...                 ],\n...                 datasets=[\n...                     v05.Dataset(\n...                         path=\"0\",\n...                         coordinateTransformations=[\n...                             v05.ScaleTransformation(scale=[0.5, 0.5])\n...                         ],\n...                     )\n...                 ],\n...             )\n...         ]\n...     )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Rows, columns, and wells are auto-generated from the images dict!\n&gt;&gt;&gt; images = {\n...     (\"A\", \"1\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n...     (\"A\", \"2\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n...     (\"B\", \"1\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n...     (\"B\", \"2\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n... }\n&gt;&gt;&gt;\n&gt;&gt;&gt; result = write_plate(\"my_plate1.ome.zarr\", images)\n&gt;&gt;&gt; assert (result / \"A\" / \"1\" / \"0\" / \"zarr.json\").exists()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Or add custom metadata like a name\n&gt;&gt;&gt; result2 = write_plate(\n...     \"my_plate2.ome.zarr\",\n...     images,\n...     plate={\"name\": \"My Experiment\"},\n...     overwrite=True,\n... )\n</code></pre> See Also <p>PlateBuilder : Builder class for incremental well/field writing. write_image : Write a single Image group.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_plate(\n    dest: str | PathLike,\n    images: Mapping[tuple[str, str, str], ImageWithDatasets],\n    *,\n    plate: Plate | dict[str, Any] | None = None,\n    writer: ZarrWriter = \"auto\",\n    overwrite: bool = False,\n    chunks: tuple[int, ...] | Literal[\"auto\"] | None = \"auto\",\n    shards: tuple[int, ...] | None = None,\n    compression: CompressionName = \"blosc-zstd\",\n    progress: bool = False,\n) -&gt; Path:\n    \"\"\"Write an OME-Zarr v0.5 Plate group with data.\n\n    This is the high-level function for writing a complete OME-Zarr plate.\n    It creates the plate hierarchy (plate/wells/fields), writes metadata,\n    and stores image data in a single call.\n\n    The plate structure::\n\n        dest/\n        \u251c\u2500\u2500 zarr.json          # Plate metadata\n        \u251c\u2500\u2500 A/\n        \u2502   \u251c\u2500\u2500 1/\n        \u2502   \u2502   \u251c\u2500\u2500 zarr.json  # Well metadata (auto-generated)\n        \u2502   \u2502   \u251c\u2500\u2500 0/         # Field 0\n        \u2502   \u2502   \u2502   \u251c\u2500\u2500 zarr.json  # Image metadata\n        \u2502   \u2502   \u2502   \u2514\u2500\u2500 0/     # dataset arrays\n        \u2502   \u2502   \u2514\u2500\u2500 1/         # Field 1 (if multiple fields)\n        \u2502   \u2514\u2500\u2500 2/\n        \u2514\u2500\u2500 B/\n            \u2514\u2500\u2500 ...\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the Plate Zarr group.\n    images : Mapping[tuple[str, str, str], ImageWithDatasets]\n        Mapping of `{(row, col, fov) -&gt; (image_model, [datasets, ...])}`.\n        Each tuple key specifies (row_name, column_name, field_of_view) like\n        (\"A\", \"1\", \"0\"). Row and column names are auto-extracted from the keys.\n    plate : Plate | dict[str, Any] | None, optional\n        Optional plate metadata. Can be:\n        - None (default): Auto-generate from images dict keys\n        - dict: Merge with auto-generated metadata (user values take precedence)\n        - Plate: Use as-is (must match images dict)\n        Common dict keys: 'name', 'acquisitions', 'field_count'.\n        Auto-generated: 'rows', 'columns', 'wells'.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays. Default is \"auto\".\n    overwrite : bool, optional\n        If True, overwrite existing Zarr groups. Default is False.\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for all arrays. See `write_image` for details.\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n    progress : bool, optional\n        Show progress bar when writing dask arrays. Default is False.\n\n    Returns\n    -------\n    Path\n        Path to the created Plate Zarr group.\n\n    Raises\n    ------\n    ValueError\n        If image keys don't match plate wells, or if datasets don't match metadata.\n    FileExistsError\n        If `dest` exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n\n    Examples\n    --------\n    Write a simple 2x2 plate with auto-generated metadata:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import write_plate\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Create image metadata (same for all fields)\n    &gt;&gt;&gt; def make_image():\n    ...     return v05.Image(\n    ...         multiscales=[\n    ...             v05.Multiscale(\n    ...                 axes=[\n    ...                     v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    ...                     v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n    ...                 ],\n    ...                 datasets=[\n    ...                     v05.Dataset(\n    ...                         path=\"0\",\n    ...                         coordinateTransformations=[\n    ...                             v05.ScaleTransformation(scale=[0.5, 0.5])\n    ...                         ],\n    ...                     )\n    ...                 ],\n    ...             )\n    ...         ]\n    ...     )\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Rows, columns, and wells are auto-generated from the images dict!\n    &gt;&gt;&gt; images = {\n    ...     (\"A\", \"1\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n    ...     (\"A\", \"2\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n    ...     (\"B\", \"1\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n    ...     (\"B\", \"2\", \"0\"): (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n    ... }\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; result = write_plate(\"my_plate1.ome.zarr\", images)\n    &gt;&gt;&gt; assert (result / \"A\" / \"1\" / \"0\" / \"zarr.json\").exists()\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; # Or add custom metadata like a name\n    &gt;&gt;&gt; result2 = write_plate(\n    ...     \"my_plate2.ome.zarr\",\n    ...     images,\n    ...     plate={\"name\": \"My Experiment\"},\n    ...     overwrite=True,\n    ... )\n\n    See Also\n    --------\n    PlateBuilder : Builder class for incremental well/field writing.\n    write_image : Write a single Image group.\n    \"\"\"\n    # Merge user-provided plate metadata with auto-generated\n    plate_obj = _merge_plate_metadata(images, plate)\n\n    # Use PlateBuilder to handle the writing\n    builder = PlateBuilder(\n        dest,\n        plate=plate_obj,\n        writer=writer,\n        chunks=chunks,\n        shards=shards,\n        overwrite=overwrite,\n        compression=compression,\n    )\n\n    # Group images by well: {(row, col): {fov: (Image, datasets)}}\n    wells_data: dict[tuple[str, str], dict[str, ImageWithDatasets]] = {}\n    for (row, col, fov), image_data in images.items():\n        wells_data.setdefault((row, col), {})[fov] = image_data\n\n    # Write each well with all its fields\n    for (row, col), fields_data in wells_data.items():\n        builder.write_well(row=row, col=col, images=fields_data, progress=progress)\n\n    return builder.root_path\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.write_bioformats2raw","title":"<code>write_bioformats2raw(dest, images, *, ome_xml=None, writer='auto', overwrite=False, chunks='auto', shards=None, compression='blosc-zstd', progress=False)</code>","text":"<p>Write a bioformats2raw-layout OME-Zarr with multiple series.</p> <p>The bioformats2raw layout is a convention for storing multiple images (series) in a single Zarr hierarchy. It includes a root group with <code>bioformats2raw.layout</code> version, an <code>OME/</code> group with series metadata, and each series as a separate Image subgroup.</p> <p>This is the high-level function for writing all series at once. For incremental writes, use <code>Bf2RawBuilder</code> directly.</p> <p>Writes the following structure:</p> <pre><code>dest/\n\u251c\u2500\u2500 zarr.json              # root: attributes[\"ome\"][\"bioformats2raw.layout\"]\n\u251c\u2500\u2500 0/                     # first series (images[\"0\"])\n\u2502   \u251c\u2500\u2500 zarr.json          # Image metadata (images[\"0\"][0])\n\u2502   \u251c\u2500\u2500 0/                 # first resolution level\n\u2502   \u2502   \u251c\u2500\u2500 zarr.json      # array metadata\n\u2502   \u2502   \u2514\u2500\u2500 c/             # chunks directory\n\u2502   \u2514\u2500\u2500 1/                 # second resolution level (if multiscale)\n\u2502       \u251c\u2500\u2500 zarr.json\n\u2502       \u2514\u2500\u2500 c/\n\u251c\u2500\u2500 1/                     # second series (images[\"1\"])\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 OME/\n    \u251c\u2500\u2500 zarr.json          # attributes[\"ome\"][\"series\"] = [\"0\", \"1\", ...]\n    \u2514\u2500\u2500 METADATA.ome.xml   # optional OME-XML (if ome_xml provided)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the root Zarr group.</p> required <code>images</code> <code>dict[str, ImageWithDatasets]</code> <p>Mapping of <code>{series_name -&gt; (image_model, [datasets, ...])}</code>. Each series name (e.g., \"0\", \"1\") becomes a subgroup in the root group, with the Image model defining the zarr.json and the datasets providing the data arrays.</p> required <code>ome_xml</code> <code>str | None</code> <p>OME-XML string to store as <code>OME/METADATA.ome.xml</code>. Useful for preserving full metadata from converted files.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend to use for writing arrays.</p> <code>'auto'</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing Zarr groups. Default is False.</p> <code>False</code> <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape for all arrays. See <code>write_image</code> for details.</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <code>progress</code> <code>bool</code> <p>Show progress bar when writing dask arrays. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the root Zarr group.</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If <code>dest</code> exists and <code>overwrite</code> is False.</p> <code>ValueError</code> <p>If any series has mismatched datasets/metadata.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> <p>Examples:</p> <p>Write a multi-series OME-Zarr:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import write_bioformats2raw\n&gt;&gt;&gt;\n&gt;&gt;&gt; def make_image():\n...     return v05.Image(\n...         multiscales=[\n...             v05.Multiscale(\n...                 axes=[\n...                     v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n...                     v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n...                 ],\n...                 datasets=[\n...                     v05.Dataset(\n...                         path=\"0\",\n...                         coordinateTransformations=[\n...                             v05.ScaleTransformation(scale=[0.5, 0.5])\n...                         ],\n...                     )\n...                 ],\n...             )\n...         ]\n...     )\n&gt;&gt;&gt; images = {\n...     \"0\": (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n...     \"1\": (make_image(), [np.zeros((32, 32), dtype=np.uint16)]),\n... }\n&gt;&gt;&gt; result = write_bioformats2raw(\"multi_series.zarr\", images)\n&gt;&gt;&gt; (result / \"OME\" / \"zarr.json\").exists()\nTrue\n&gt;&gt;&gt; (result / \"0\" / \"zarr.json\").exists()\nTrue\n</code></pre> See Also <p>Bf2RawBuilder : Builder class for incremental series writing. write_image : Write a single Image group.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def write_bioformats2raw(\n    dest: str | PathLike,\n    # mapping of {series_name -&gt; ( Image, [datasets, ...] )}\n    images: Mapping[str, ImageWithDatasets],\n    *,\n    ome_xml: str | None = None,\n    writer: ZarrWriter = \"auto\",\n    overwrite: bool = False,\n    chunks: tuple[int, ...] | Literal[\"auto\"] | None = \"auto\",\n    shards: tuple[int, ...] | None = None,\n    compression: CompressionName = \"blosc-zstd\",\n    progress: bool = False,\n) -&gt; Path:\n    \"\"\"Write a bioformats2raw-layout OME-Zarr with multiple series.\n\n    The bioformats2raw layout is a convention for storing multiple images\n    (series) in a single Zarr hierarchy. It includes a root group with\n    `bioformats2raw.layout` version, an `OME/` group with series metadata,\n    and each series as a separate Image subgroup.\n\n    This is the high-level function for writing all series at once. For\n    incremental writes, use `Bf2RawBuilder` directly.\n\n    Writes the following structure:\n\n        dest/\n        \u251c\u2500\u2500 zarr.json              # root: attributes[\"ome\"][\"bioformats2raw.layout\"]\n        \u251c\u2500\u2500 0/                     # first series (images[\"0\"])\n        \u2502   \u251c\u2500\u2500 zarr.json          # Image metadata (images[\"0\"][0])\n        \u2502   \u251c\u2500\u2500 0/                 # first resolution level\n        \u2502   \u2502   \u251c\u2500\u2500 zarr.json      # array metadata\n        \u2502   \u2502   \u2514\u2500\u2500 c/             # chunks directory\n        \u2502   \u2514\u2500\u2500 1/                 # second resolution level (if multiscale)\n        \u2502       \u251c\u2500\u2500 zarr.json\n        \u2502       \u2514\u2500\u2500 c/\n        \u251c\u2500\u2500 1/                     # second series (images[\"1\"])\n        \u2502   \u2514\u2500\u2500 ...\n        \u2514\u2500\u2500 OME/\n            \u251c\u2500\u2500 zarr.json          # attributes[\"ome\"][\"series\"] = [\"0\", \"1\", ...]\n            \u2514\u2500\u2500 METADATA.ome.xml   # optional OME-XML (if ome_xml provided)\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the root Zarr group.\n    images : dict[str, ImageWithDatasets]\n        Mapping of `{series_name -&gt; (image_model, [datasets, ...])}`.\n        Each series name (e.g., \"0\", \"1\") becomes a subgroup in the root group, with\n        the Image model defining the zarr.json and the datasets providing the data\n        arrays.\n    ome_xml : str | None, optional\n        OME-XML string to store as `OME/METADATA.ome.xml`.\n        Useful for preserving full metadata from converted files.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend to use for writing arrays.\n    overwrite : bool, optional\n        If True, overwrite existing Zarr groups. Default is False.\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape for all arrays. See `write_image` for details.\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n    progress : bool, optional\n        Show progress bar when writing dask arrays. Default is False.\n\n    Returns\n    -------\n    Path\n        Path to the root Zarr group.\n\n    Raises\n    ------\n    FileExistsError\n        If `dest` exists and `overwrite` is False.\n    ValueError\n        If any series has mismatched datasets/metadata.\n    ImportError\n        If no suitable writer backend is installed.\n\n    Examples\n    --------\n    Write a multi-series OME-Zarr:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import write_bioformats2raw\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; def make_image():\n    ...     return v05.Image(\n    ...         multiscales=[\n    ...             v05.Multiscale(\n    ...                 axes=[\n    ...                     v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    ...                     v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n    ...                 ],\n    ...                 datasets=[\n    ...                     v05.Dataset(\n    ...                         path=\"0\",\n    ...                         coordinateTransformations=[\n    ...                             v05.ScaleTransformation(scale=[0.5, 0.5])\n    ...                         ],\n    ...                     )\n    ...                 ],\n    ...             )\n    ...         ]\n    ...     )\n    &gt;&gt;&gt; images = {\n    ...     \"0\": (make_image(), [np.zeros((64, 64), dtype=np.uint16)]),\n    ...     \"1\": (make_image(), [np.zeros((32, 32), dtype=np.uint16)]),\n    ... }\n    &gt;&gt;&gt; result = write_bioformats2raw(\"multi_series.zarr\", images)\n    &gt;&gt;&gt; (result / \"OME\" / \"zarr.json\").exists()\n    True\n    &gt;&gt;&gt; (result / \"0\" / \"zarr.json\").exists()\n    True\n\n    See Also\n    --------\n    Bf2RawBuilder : Builder class for incremental series writing.\n    write_image : Write a single Image group.\n    \"\"\"\n    builder = Bf2RawBuilder(\n        dest,\n        ome_xml=ome_xml,\n        writer=writer,\n        chunks=chunks,\n        shards=shards,\n        overwrite=overwrite,\n        compression=compression,\n    )\n\n    for series_name, (image_model, datasets) in images.items():\n        builder.write_image(series_name, image_model, datasets, progress=progress)\n\n    return builder.root_path\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05.prepare_image","title":"<code>prepare_image(dest, image, datasets, *, chunks='auto', shards=None, writer='auto', overwrite=False, compression='blosc-zstd')</code>","text":"<p>Create OME-Zarr v0.5 Image structure and return array handles for writing.</p> <p>This is a lower-level function that creates the Zarr group hierarchy and empty arrays, but does not write data. Use this when you need custom control over how data is written (e.g., chunk-by-chunk streaming, parallel writes).</p> <p>To write data immediately, use <code>write_image</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>dest</code> <code>str | PathLike</code> <p>Destination path for the Zarr group.</p> required <code>image</code> <code>Image</code> <p>OME-Zarr Image metadata model.</p> required <code>datasets</code> <code>ShapeAndDType | Sequence[ShapeAndDType]</code> <p>Shape and dtype specification(s) for each dataset, as <code>(shape, dtype)</code> tuples. Can be:</p> <ul> <li>Single <code>(shape, dtype)</code>: For one dataset, no wrapping needed</li> <li>Sequence of <code>(shape, dtype)</code>: For multiple datasets (multiscale pyramid)</li> </ul> <p>Must match the number and order of <code>image.multiscales[0].datasets</code>.</p> required <code>chunks</code> <code>tuple[int, ...] | 'auto' | None</code> <p>Chunk shape. See <code>write_image</code> for details.</p> <code>'auto'</code> <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding. Default is None (no sharding). When present, shard_shape must be divisible by chunk shape.</p> <code>None</code> <code>writer</code> <code>'zarr' | 'tensorstore' | 'auto' | CreateArrayFunc</code> <p>Backend for creating arrays. When you specify \"zarr\" or \"tensorstore\", the return type is narrowed to the specific array type.</p> <code>'auto'</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing Zarr group. Default is False.</p> <code>False</code> <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec. Default is \"blosc-zstd\".</p> <code>'blosc-zstd'</code> <p>Returns:</p> Type Description <code>tuple[Path, dict[str, Array]]</code> <p>A tuple of (path, arrays) where <code>arrays</code> maps dataset paths (e.g., \"0\") to array objects. The array type depends on the writer:</p> <ul> <li><code>writer=\"zarr\"</code>: Returns <code>dict[str, zarr.Array]</code></li> <li><code>writer=\"tensorstore\"</code>: Returns <code>dict[str, tensorstore.TensorStore]</code></li> <li><code>writer=\"auto\"</code>: Returns whichever is available</li> </ul> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the Image model has multiple multiscales.</p> <code>ValueError</code> <p>If the number of dataset specs doesn't match the metadata.</p> <code>FileExistsError</code> <p>If <code>dest</code> exists and <code>overwrite</code> is False.</p> <code>ImportError</code> <p>If no suitable writer backend is installed.</p> <p>Examples:</p> <p>Create arrays and write data in chunks - single dataset, no list needed:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from yaozarrs import v05\n&gt;&gt;&gt; from yaozarrs.write.v05 import prepare_image\n&gt;&gt;&gt; image = v05.Image(\n...     multiscales=[\n...         v05.Multiscale(\n...             axes=[\n...                 v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n...                 v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n...             ],\n...             datasets=[\n...                 v05.Dataset(\n...                     path=\"0\",\n...                     coordinateTransformations=[\n...                         v05.ScaleTransformation(scale=[0.5, 0.5])\n...                     ],\n...                 )\n...             ],\n...         )\n...     ]\n... )\n&gt;&gt;&gt; # Prepare with just shape/dtype (no data yet) - no list wrapping!\n&gt;&gt;&gt; path, arrays = prepare_image(\"prepared.zarr\", image, ((64, 64), \"uint16\"))\n&gt;&gt;&gt; arrays[\"0\"][:] = np.zeros((64, 64), dtype=np.uint16)\n&gt;&gt;&gt; assert path.exists()\n</code></pre> See Also <p>write_image : High-level function that writes data immediately. Bf2RawBuilder.prepare : Prepare multiple series at once.</p> Source code in <code>src/yaozarrs/write/v05/_write.py</code> <pre><code>def prepare_image(\n    dest: str | PathLike,\n    image: Image,\n    datasets: ShapeAndDTypeOrPyramid,\n    *,\n    chunks: tuple[int, ...] | Literal[\"auto\"] | None = \"auto\",\n    shards: tuple[int, ...] | None = None,\n    writer: ZarrWriter = \"auto\",\n    overwrite: bool = False,\n    compression: CompressionName = \"blosc-zstd\",\n) -&gt; tuple[Path, dict[str, Any]]:\n    \"\"\"Create OME-Zarr v0.5 Image structure and return array handles for writing.\n\n    This is a lower-level function that creates the Zarr group hierarchy and\n    empty arrays, but does not write data. Use this when you need custom control\n    over how data is written (e.g., chunk-by-chunk streaming, parallel writes).\n\n    To write data immediately, use `write_image` instead.\n\n    Parameters\n    ----------\n    dest : str | PathLike\n        Destination path for the Zarr group.\n    image : Image\n        OME-Zarr Image metadata model.\n    datasets : ShapeAndDType | Sequence[ShapeAndDType]\n        Shape and dtype specification(s) for each dataset, as `(shape, dtype)`\n        tuples. Can be:\n\n        - Single `(shape, dtype)`: For one dataset, no wrapping needed\n        - Sequence of `(shape, dtype)`: For multiple datasets (multiscale pyramid)\n\n        Must match the number and order of `image.multiscales[0].datasets`.\n    chunks : tuple[int, ...] | \"auto\" | None, optional\n        Chunk shape. See `write_image` for details.\n    shards : tuple[int, ...] | None, optional\n        Shard shape for Zarr v3 sharding. Default is None (no sharding).\n        When present, shard_shape must be divisible by chunk shape.\n    writer : \"zarr\" | \"tensorstore\" | \"auto\" | CreateArrayFunc, optional\n        Backend for creating arrays. When you specify \"zarr\" or \"tensorstore\",\n        the return type is narrowed to the specific array type.\n    overwrite : bool, optional\n        If True, overwrite existing Zarr group. Default is False.\n    compression : \"blosc-zstd\" | \"blosc-lz4\" | \"zstd\" | \"none\", optional\n        Compression codec. Default is \"blosc-zstd\".\n\n    Returns\n    -------\n    tuple[Path, dict[str, Array]]\n        A tuple of (path, arrays) where `arrays` maps dataset paths (e.g., \"0\")\n        to array objects. The array type depends on the writer:\n\n        - `writer=\"zarr\"`: Returns `dict[str, zarr.Array]`\n        - `writer=\"tensorstore\"`: Returns `dict[str, tensorstore.TensorStore]`\n        - `writer=\"auto\"`: Returns whichever is available\n\n    Raises\n    ------\n    NotImplementedError\n        If the Image model has multiple multiscales.\n    ValueError\n        If the number of dataset specs doesn't match the metadata.\n    FileExistsError\n        If `dest` exists and `overwrite` is False.\n    ImportError\n        If no suitable writer backend is installed.\n\n    Examples\n    --------\n    Create arrays and write data in chunks - single dataset, no list needed:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from yaozarrs import v05\n    &gt;&gt;&gt; from yaozarrs.write.v05 import prepare_image\n    &gt;&gt;&gt; image = v05.Image(\n    ...     multiscales=[\n    ...         v05.Multiscale(\n    ...             axes=[\n    ...                 v05.SpaceAxis(name=\"y\", unit=\"micrometer\"),\n    ...                 v05.SpaceAxis(name=\"x\", unit=\"micrometer\"),\n    ...             ],\n    ...             datasets=[\n    ...                 v05.Dataset(\n    ...                     path=\"0\",\n    ...                     coordinateTransformations=[\n    ...                         v05.ScaleTransformation(scale=[0.5, 0.5])\n    ...                     ],\n    ...                 )\n    ...             ],\n    ...         )\n    ...     ]\n    ... )\n    &gt;&gt;&gt; # Prepare with just shape/dtype (no data yet) - no list wrapping!\n    &gt;&gt;&gt; path, arrays = prepare_image(\"prepared.zarr\", image, ((64, 64), \"uint16\"))\n    &gt;&gt;&gt; arrays[\"0\"][:] = np.zeros((64, 64), dtype=np.uint16)\n    &gt;&gt;&gt; assert path.exists()\n\n    See Also\n    --------\n    write_image : High-level function that writes data immediately.\n    Bf2RawBuilder.prepare : Prepare multiple series at once.\n    \"\"\"\n    if len(image.multiscales) != 1:\n        raise NotImplementedError(\"Image must have exactly one multiscale\")\n\n    multiscale = image.multiscales[0]\n\n    # Normalize to sequence: single (shape, dtype) tuple -&gt; list\n    datasets_seq: Sequence[ShapeAndDType]\n    if (\n        isinstance(datasets, tuple)\n        and len(datasets) == 2\n        and isinstance(datasets[0], tuple)  # shape is first element\n    ):\n        datasets_seq = [datasets]  # type: ignore[list-item]\n    else:\n        datasets_seq = datasets  # type: ignore[assignment]\n\n    if len(datasets_seq) != len(multiscale.datasets):\n        raise ValueError(\n            f\"Number of dataset specs ({len(datasets_seq)}) must match \"\n            f\"number of datasets in metadata ({len(multiscale.datasets)})\"\n        )\n\n    # Get create function\n    create_func = _get_create_func(writer)\n\n    # Create zarr group with Image metadata\n    dest_path = Path(dest)\n    _create_zarr3_group(dest_path, image, overwrite)\n\n    dimension_names = [ax.name for ax in multiscale.axes]\n\n    # Create arrays for each dataset\n    arrays = {}\n    for (shape, dtype_spec), dataset_meta in zip(datasets_seq, multiscale.datasets):\n        # Convert dtype to np.dtype to ensure compatibility with all backends\n        import numpy as np\n\n        dtype = np.dtype(dtype_spec)\n        arrays[dataset_meta.path] = create_func(\n            path=dest_path / dataset_meta.path,\n            shape=shape,\n            dtype=dtype,\n            chunks=_resolve_chunks(shape, dtype, chunks),\n            shards=shards,\n            dimension_names=dimension_names,\n            overwrite=overwrite,\n            compression=compression,\n        )\n\n    return dest_path, arrays\n</code></pre>"},{"location":"API_Reference/yaozarrs.write.v05/#custom-writers","title":"Custom Writers","text":"<p>Advanced</p> <p>This is an advanced feature, not needed for most users.  You can skip this section if you are happy using the built-in zarr or tensorstore implementations.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05._write.CreateArrayFunc","title":"CreateArrayFunc","text":"<p>Protocol for custom array creation functions.</p> <p>This is the type signature for functions that can be passed as the <code>writer</code> parameter to many functions in this module.  Use this if you'd like to completely customize how arrays are created, e.g., using a different backend, or custom storage options.  See <code>_create_array_zarr</code> and <code>_create_array_tensorstore</code> for reference implementations.</p>"},{"location":"API_Reference/yaozarrs.write.v05/#yaozarrs.write.v05._write.CreateArrayFunc.__call__","title":"<code>__call__(path, shape, dtype, chunks, *, shards, overwrite, compression, dimension_names)</code>","text":"<p>Create array structure without writing data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to create array</p> required <code>shape</code> <code>tuple[int, ...]</code> <p>Array shape</p> required <code>dtype</code> <code>dtype</code> <p>Data type</p> required <code>chunks</code> <code>tuple[int, ...]</code> <p>Chunk shape (already resolved by yaozarrs)</p> required <code>shards</code> <code>tuple[int, ...] | None</code> <p>Shard shape for Zarr v3 sharding, or None</p> required <code>dimension_names</code> <code>list[str] | None</code> <p>Names for each dimension</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing array</p> required <code>compression</code> <code>'blosc-zstd' | 'blosc-lz4' | 'zstd' | 'none'</code> <p>Compression codec to use</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Array object that supports numpy-style indexing for writing (e.g., <code>zarr.Array</code> or <code>tensorstore.TensorStore</code>).</p>"}]}